{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6be0128",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1823b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a000e39",
   "metadata": {},
   "source": [
    "## Part 0: Get to Know the Data\n",
    "\n",
    "There are four data files associated with this project:\n",
    "\n",
    "- `Udacity_AZDIAS_052018.csv`: Demographics data for the general population of Germany; 891 211 persons (rows) x 366 features (columns).\n",
    "- `Udacity_CUSTOMERS_052018.csv`: Demographics data for customers of a mail-order company; 191 652 persons (rows) x 369 features (columns).\n",
    "- `Udacity_MAILOUT_052018_TRAIN.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 982 persons (rows) x 367 (columns).\n",
    "- `Udacity_MAILOUT_052018_TEST.csv`: Demographics data for individuals who were targets of a marketing campaign; 42 833 persons (rows) x 366 (columns).\n",
    "\n",
    "Each row of the demographics files represents a single person, but also includes information outside of individuals, including information about their household, building, and neighborhood. Use the information from the first two files to figure out how customers (\"CUSTOMERS\") are similar to or differ from the general population at large (\"AZDIAS\"), then use your analysis to make predictions on the other two files (\"MAILOUT\"), predicting which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "The \"CUSTOMERS\" file contains three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'), which provide broad information about the customers depicted in the file. The original \"MAILOUT\" file included one additional column, \"RESPONSE\", which indicated whether or not each recipient became a customer of the company. For the \"TRAIN\" subset, this column has been retained, but in the \"TEST\" subset it has been removed; it is against that withheld column that your final predictions will be assessed in the Kaggle competition.\n",
    "\n",
    "Otherwise, all of the remaining columns are the same between the three data files. For more information about the columns depicted in the files, you can refer to two Excel spreadsheets provided in the workspace. [One of them](./DIAS Information Levels - Attributes 2017.xlsx) is a top-level list of attributes and descriptions, organized by informational category. [The other](./DIAS Attributes - Values 2017.xlsx) is a detailed mapping of data values for each feature in alphabetical order.\n",
    "\n",
    "In the below cell, we've provided some initial code to load in the first two datasets. Note for all of the `.csv` data files in this project that they're semicolon (`;`) delimited, so an additional argument in the [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) call has been included to read in the data properly. Also, considering the size of the datasets, it may take some time for them to load completely.\n",
    "\n",
    "You'll notice when the data is loaded in that a warning message will immediately pop up. Before you really start digging into the modeling and analysis, you're going to need to perform some cleaning. Take some time to browse the structure of the data and look over the informational spreadsheets to understand the data values. Make some decisions on which features to keep, which features to drop, and if any revisions need to be made on data formats. It'll be a good idea to create a function with pre-processing steps, since you'll need to clean all of the datasets before you work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4cc88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "azdias = pd.read_csv('Data/Udacity_AZDIAS_052018.csv', sep=';')\n",
    "customers = pd.read_csv('Data/Udacity_CUSTOMERS_052018.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea0f6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>910215</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>910220</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>910225</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910226</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>910241</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  \\\n",
       "0  910215        -1         NaN       NaN          NaN          NaN   \n",
       "1  910220        -1         9.0       0.0          NaN          NaN   \n",
       "2  910225        -1         9.0      17.0          NaN          NaN   \n",
       "3  910226         2         1.0      13.0          NaN          NaN   \n",
       "4  910241        -1         1.0      20.0          NaN          NaN   \n",
       "\n",
       "   ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  ...  \\\n",
       "0          NaN          NaN                   NaN                  NaN  ...   \n",
       "1          NaN          NaN                  21.0                 11.0  ...   \n",
       "2          NaN          NaN                  17.0                 10.0  ...   \n",
       "3          NaN          NaN                  13.0                  1.0  ...   \n",
       "4          NaN          NaN                  14.0                  3.0  ...   \n",
       "\n",
       "   VHN  VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  \\\n",
       "0  NaN       NaN         NaN      NaN             NaN             NaN   \n",
       "1  4.0       8.0        11.0     10.0             3.0             9.0   \n",
       "2  2.0       9.0         9.0      6.0             3.0             9.0   \n",
       "3  0.0       7.0        10.0     11.0             NaN             9.0   \n",
       "4  2.0       3.0         5.0      4.0             2.0             9.0   \n",
       "\n",
       "   WOHNLAGE ZABEOTYP ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0       NaN        3         1                    2  \n",
       "1       4.0        5         2                    1  \n",
       "2       2.0        5         2                    3  \n",
       "3       7.0        3         2                    4  \n",
       "4       3.0        4         1                    3  \n",
       "\n",
       "[5 rows x 366 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get to know the features of azdias\n",
    "azdias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4127fdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891221 entries, 0 to 891220\n",
      "Columns: 366 entries, LNR to ALTERSKATEGORIE_GROB\n",
      "dtypes: float64(267), int64(93), object(6)\n",
      "memory usage: 2.4+ GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891221, 366)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias.info()\n",
    "azdias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb1f8c",
   "metadata": {},
   "source": [
    "According to the shape information, there are 891,221 rows/individuals in the dataset. Each individual has 366 features. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dd3c64",
   "metadata": {},
   "source": [
    "## Part 1: Customer Segmentation Report\n",
    "\n",
    "The main bulk of your analysis will come in this part of the project. Here, you should use unsupervised learning techniques to describe the relationship between the demographics of the company's existing customers and the general population of Germany. By the end of this part, you should be able to describe parts of the general population that are more likely to be part of the mail-order company's main customer base, and which parts of the general population are less so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e34c3",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ae51fe",
   "metadata": {},
   "source": [
    "1.1 From the DIAS Attributes excel sheet, I created a csv file called Data_NaN that denotes values that mean unknown cases in each column. From Data_NaN I create a corresponding dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4669a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGER_TYP</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALTERSKATEGORIE_GROB</td>\n",
       "      <td>-1, 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALTER_HH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANREDE_KZ</td>\n",
       "      <td>-1, 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BALLRAUM</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Attribute  Value\n",
       "0              AGER_TYP     -1\n",
       "1  ALTERSKATEGORIE_GROB  -1, 0\n",
       "2              ALTER_HH      0\n",
       "3             ANREDE_KZ  -1, 0\n",
       "4              BALLRAUM     -1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_NaN = pd.read_csv('Data/Data_NaN.csv', sep=',', header=0)\n",
    "pd_NaN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e74485a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_NaN['Value'] = pd_NaN['Value'].apply(lambda x: x.split(\",\"))\n",
    "pd_NaN['Value'] = pd_NaN['Value'].apply(lambda x: list(map(int,x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a44bf21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AGER_TYP': [-1], 'ALTERSKATEGORIE_GROB': [-1, 0], 'ALTER_HH': [0], 'ANREDE_KZ': [-1, 0], 'BALLRAUM': [-1], 'CAMEO_DEUG_2015': [-1], 'CAMEO_INTL_2015': [-1], 'CJT_GESAMTTYP': [0], 'EWDICHTE': [-1], 'FINANZTYP': [-1], 'FINANZ_ANLEGER': [-1], 'FINANZ_HAUSBAUER': [-1], 'FINANZ_MINIMALIST': [-1], 'FINANZ_SPARER': [-1], 'FINANZ_UNAUFFAELLIGER': [-1], 'FINANZ_VORSORGER': [-1], 'GEBAEUDETYP': [-1, 0], 'HEALTH_TYP': [-1], 'HH_EINKOMMEN_SCORE': [-1, 0], 'INNENSTADT': [-1], 'KBA05_ALTER1': [-1, 9], 'KBA05_ALTER2': [-1, 9], 'KBA05_ALTER3': [-1, 9], 'KBA05_ALTER4': [-1, 9], 'KBA05_ANHANG': [-1, 9], 'KBA05_ANTG1': [-1], 'KBA05_ANTG2': [-1], 'KBA05_ANTG3': [-1], 'KBA05_ANTG4': [-1], 'KBA05_AUTOQUOT': [-1, 9], 'KBA05_BAUMAX': [-1, 0], 'KBA05_CCM1': [-1, 9], 'KBA05_CCM2': [-1, 9], 'KBA05_CCM3': [-1, 9], 'KBA05_CCM4': [-1, 9], 'KBA05_DIESEL': [-1, 9], 'KBA05_FRAU': [-1, 9], 'KBA05_GBZ': [-1, 0], 'KBA05_HERST1': [-1, 9], 'KBA05_HERST2': [-1, 9], 'KBA05_HERST3': [-1, 9], 'KBA05_HERST4': [-1, 9], 'KBA05_HERST5': [-1, 9], 'KBA05_HERSTTEMP': [-1, 9], 'KBA05_KRSAQUOT': [-1, 9], 'KBA05_KRSHERST1': [-1, 9], 'KBA05_KRSHERST2': [-1, 9], 'KBA05_KRSHERST3': [-1, 9], 'KBA05_KRSKLEIN': [-1, 9], 'KBA05_KRSOBER': [-1, 9], 'KBA05_KRSVAN': [-1, 9], 'KBA05_KRSZUL': [-1, 9], 'KBA05_KW1': [-1, 9], 'KBA05_KW2': [-1, 9], 'KBA05_KW3': [-1, 9], 'KBA05_MAXAH': [-1, 9], 'KBA05_MAXBJ': [-1, 9], 'KBA05_MAXHERST': [-1, 9], 'KBA05_MAXSEG': [-1, 9], 'KBA05_MAXVORB': [-1, 9], 'KBA05_MOD1': [-1, 9], 'KBA05_MOD2': [-1, 9], 'KBA05_MOD3': [-1, 9], 'KBA05_MOD4': [-1, 9], 'KBA05_MOD8': [-1, 9], 'KBA05_MODTEMP': [-1, 9], 'KBA05_MOTOR': [-1, 9], 'KBA05_MOTRAD': [-1, 9], 'KBA05_SEG1': [-1, 9], 'KBA05_SEG10': [-1, 9], 'KBA05_SEG2': [-1, 9], 'KBA05_SEG3': [-1, 9], 'KBA05_SEG4': [-1, 9], 'KBA05_SEG5': [-1, 9], 'KBA05_SEG6': [-1, 9], 'KBA05_SEG7': [-1, 9], 'KBA05_SEG8': [-1, 9], 'KBA05_SEG9': [-1, 9], 'KBA05_VORB0': [-1, 9], 'KBA05_VORB1': [-1, 9], 'KBA05_VORB2': [-1, 9], 'KBA05_ZUL1': [-1, 9], 'KBA05_ZUL2': [-1, 9], 'KBA05_ZUL3': [-1, 9], 'KBA05_ZUL4': [-1, 9], 'KBA13_ALTERHALTER_30': [-1], 'KBA13_ALTERHALTER_45': [-1], 'KBA13_ALTERHALTER_60': [-1], 'KBA13_ALTERHALTER_61': [-1], 'KBA13_AUDI': [-1], 'KBA13_AUTOQUOTE': [-1], 'KBA13_BJ_1999': [-1], 'KBA13_BJ_2000': [-1], 'KBA13_BJ_2004': [-1], 'KBA13_BJ_2006': [-1], 'KBA13_BJ_2008': [-1], 'KBA13_BJ_2009': [-1], 'KBA13_BMW': [-1], 'KBA13_CCM_1000': [-1], 'KBA13_CCM_1200': [-1], 'KBA13_CCM_1400': [-1], 'KBA13_CCM_0_1400': [-1], 'KBA13_CCM_1500': [-1], 'KBA13_CCM_1401_2500': [-1], 'KBA13_CCM_1600': [-1], 'KBA13_CCM_1800': [-1], 'KBA13_CCM_2000': [-1], 'KBA13_CCM_2500': [-1], 'KBA13_CCM_2501': [-1], 'KBA13_CCM_3000': [-1], 'KBA13_CCM_3001': [-1], 'KBA13_FAB_ASIEN': [-1], 'KBA13_FAB_SONSTIGE': [-1], 'KBA13_FIAT': [-1], 'KBA13_FORD': [-1], 'KBA13_HALTER_20': [-1], 'KBA13_HALTER_25': [-1], 'KBA13_HALTER_30': [-1], 'KBA13_HALTER_35': [-1], 'KBA13_HALTER_40': [-1], 'KBA13_HALTER_45': [-1], 'KBA13_HALTER_50': [-1], 'KBA13_HALTER_55': [-1], 'KBA13_HALTER_60': [-1], 'KBA13_HALTER_65': [-1], 'KBA13_HALTER_66': [-1], 'KBA13_HERST_ASIEN': [-1], 'KBA13_HERST_AUDI_VW': [-1], 'KBA13_HERST_BMW_BENZ': [-1], 'KBA13_HERST_EUROPA': [-1], 'KBA13_HERST_FORD_OPEL': [-1], 'KBA13_HERST_SONST': [-1], 'KBA13_KMH_110': [-1], 'KBA13_KMH_140': [-1], 'KBA13_KMH_180': [-1], 'KBA13_KMH_0_140': [-1], 'KBA13_KMH_140_210': [-1], 'KBA13_KMH_211': [-1], 'KBA13_KMH_250': [-1], 'KBA13_KMH_251': [-1], 'KBA13_KRSAQUOT': [-1], 'KBA13_KRSHERST_AUDI_VW': [-1], 'KBA13_KRSHERST_BMW_BENZ': [-1], 'KBA13_KRSHERST_FORD_OPEL': [-1], 'KBA13_KRSSEG_KLEIN': [-1], 'KBA13_KRSSEG_OBER': [-1], 'KBA13_KRSSEG_VAN': [-1], 'KBA13_KRSZUL_NEU': [-1], 'KBA13_KW_30': [-1], 'KBA13_KW_40': [-1], 'KBA13_KW_50': [-1], 'KBA13_KW_60': [-1], 'KBA13_KW_0_60': [-1], 'KBA13_KW_70': [-1], 'KBA13_KW_61_120': [-1], 'KBA13_KW_80': [-1], 'KBA13_KW_90': [-1], 'KBA13_KW_110': [-1], 'KBA13_KW_120': [-1], 'KBA13_KW_121': [-1], 'KBA13_MAZDA': [-1], 'KBA13_MERCEDES': [-1], 'KBA13_MOTOR': [-1], 'KBA13_NISSAN': [-1], 'KBA13_OPEL': [-1], 'KBA13_PEUGEOT': [-1], 'KBA13_RENAULT': [-1], 'KBA13_SEG_GELAENDEWAGEN': [-1], 'KBA13_SEG_GROSSRAUMVANS': [-1], 'KBA13_SEG_KLEINST': [-1], 'KBA13_SEG_KLEINWAGEN': [-1], 'KBA13_SEG_KOMPAKTKLASSE': [-1], 'KBA13_SEG_MINIVANS': [-1], 'KBA13_SEG_MINIWAGEN': [-1], 'KBA13_SEG_MITTELKLASSE': [-1], 'KBA13_SEG_OBEREMITTELKLASSE': [-1], 'KBA13_SEG_OBERKLASSE': [-1], 'KBA13_SEG_SONSTIGE': [-1], 'KBA13_SEG_SPORTWAGEN': [-1], 'KBA13_SEG_UTILITIES': [-1], 'KBA13_SEG_VAN': [-1], 'KBA13_SEG_WOHNMOBILE': [-1], 'KBA13_SITZE_4': [-1], 'KBA13_SITZE_5': [-1], 'KBA13_SITZE_6': [-1], 'KBA13_TOYOTA': [-1], 'KBA13_VORB_0': [-1], 'KBA13_VORB_1': [-1], 'KBA13_VORB_1_2': [-1], 'KBA13_VORB_2': [-1], 'KBA13_VORB_3': [-1], 'KBA13_VW': [-1], 'KKK': [-1, 0], 'NATIONALITAET_KZ': [-1, 0], 'ORTSGR_KLS9': [-1], 'OST_WEST_KZ': [-1], 'PLZ8_ANTG1': [-1], 'PLZ8_ANTG2': [-1], 'PLZ8_ANTG3': [-1], 'PLZ8_ANTG4': [-1], 'PLZ8_GBZ': [-1], 'PLZ8_HHZ': [-1], 'PRAEGENDE_JUGENDJAHRE': [-1, 0], 'REGIOTYP': [-1, 0], 'RELAT_AB': [-1, 9], 'RETOURTYP_BK_S': [0], 'SEMIO_DOM': [-1, 9], 'SEMIO_ERL': [-1, 9], 'SEMIO_FAM': [-1, 9], 'SEMIO_KAEM': [-1, 9], 'SEMIO_KRIT': [-1, 9], 'SEMIO_KULT': [-1, 9], 'SEMIO_LUST': [-1, 9], 'SEMIO_MAT': [-1, 9], 'SEMIO_PFLICHT': [-1, 9], 'SEMIO_RAT': [-1, 9], 'SEMIO_REL': [-1, 9], 'SEMIO_SOZ': [-1, 9], 'SEMIO_TRADV': [-1, 9], 'SEMIO_VERT': [-1, 9], 'SHOPPER_TYP': [-1], 'TITEL_KZ': [-1, 0], 'VERS_TYP': [-1], 'WOHNDAUER_2008': [-1, 0], 'WOHNLAGE': [-1], 'W_KEIT_KIND_HH': [-1, 0], 'ZABEOTYP': [-1, 9]}\n"
     ]
    }
   ],
   "source": [
    "dict_NaN = dict(zip(pd_NaN['Attribute'], pd_NaN['Value']))\n",
    "print(dict_NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54523a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#double check whether any item in dictionary keys is not in the column names \n",
    "list_1 = list(dict_NaN.keys())\n",
    "list_2 = list(azdias.columns.values)\n",
    "diff_list = np.setdiff1d(list_1,list_2)\n",
    "print(diff_list)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1446ad1d",
   "metadata": {},
   "source": [
    "1.2 Convert the unknown values in azdias into NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fba0878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "azdias_1 = azdias[:10000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24163f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_unknown_to_NaN(df, unknown = dict_NaN):\n",
    "    '''\n",
    "    It maps unknown values by column and transform them to nan values.\n",
    "    \n",
    "    Input:\n",
    "    df: original dataframe;\n",
    "    unkown: dictionary mapping columns and their respective unknown values.\n",
    "    \n",
    "    Output:Processed dataframe that maps unknown values to NaN   \n",
    "    '''\n",
    "    df_1 = df.copy()\n",
    "    for col in list(unknown.keys()):\n",
    "        df_1.loc[:, col] = df_1.loc[:, col].apply(lambda x: np.nan if x in unknown[col] else x)\n",
    "    return df_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33dc01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_NaN = convert_unknown_to_NaN(df=azdias_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78a4f130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>910215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>910220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>910225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910226</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>910241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  \\\n",
       "0  910215       NaN         NaN       NaN          NaN          NaN   \n",
       "1  910220       NaN         9.0       NaN          NaN          NaN   \n",
       "2  910225       NaN         9.0      17.0          NaN          NaN   \n",
       "3  910226       2.0         1.0      13.0          NaN          NaN   \n",
       "4  910241       NaN         1.0      20.0          NaN          NaN   \n",
       "\n",
       "   ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  ...  \\\n",
       "0          NaN          NaN                   NaN                  NaN  ...   \n",
       "1          NaN          NaN                  21.0                 11.0  ...   \n",
       "2          NaN          NaN                  17.0                 10.0  ...   \n",
       "3          NaN          NaN                  13.0                  1.0  ...   \n",
       "4          NaN          NaN                  14.0                  3.0  ...   \n",
       "\n",
       "   VHN  VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  \\\n",
       "0  NaN       NaN         NaN      NaN             NaN             NaN   \n",
       "1  4.0       8.0        11.0     10.0             3.0             9.0   \n",
       "2  2.0       9.0         9.0      6.0             3.0             9.0   \n",
       "3  0.0       7.0        10.0     11.0             NaN             9.0   \n",
       "4  2.0       3.0         5.0      4.0             2.0             9.0   \n",
       "\n",
       "   WOHNLAGE ZABEOTYP ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0       NaN        3         1                    2  \n",
       "1       4.0        5         2                    1  \n",
       "2       2.0        5         2                    3  \n",
       "3       7.0        3         2                    4  \n",
       "4       3.0        4         1                    3  \n",
       "\n",
       "[5 rows x 366 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_NaN.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a6cf86",
   "metadata": {},
   "source": [
    "1.3 Find the features that have NaN above 15% and delete the features. Here due to the constraint of memory, I chose first 10,000 data to decide the NaN percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcbe9a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>BALLRAUM</th>\n",
       "      <th>...</th>\n",
       "      <th>VERS_TYP</th>\n",
       "      <th>VHA</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>910215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>910220</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>910225</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910226</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>910241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LNR  AKT_DAT_KL  ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  ANZ_KINDER  \\\n",
       "0  910215         NaN                  NaN           NaN         NaN   \n",
       "1  910220         9.0                 11.0           0.0         0.0   \n",
       "2  910225         9.0                 10.0           0.0         0.0   \n",
       "3  910226         1.0                  1.0           0.0         0.0   \n",
       "4  910241         1.0                  3.0           0.0         0.0   \n",
       "\n",
       "   ANZ_PERSONEN  ANZ_STATISTISCHE_HAUSHALTE  ANZ_TITEL  ARBEIT  BALLRAUM  ...  \\\n",
       "0           NaN                         NaN        NaN     NaN       NaN  ...   \n",
       "1           2.0                        12.0        0.0     3.0       6.0  ...   \n",
       "2           1.0                         7.0        0.0     3.0       2.0  ...   \n",
       "3           0.0                         2.0        0.0     2.0       4.0  ...   \n",
       "4           4.0                         3.0        0.0     4.0       2.0  ...   \n",
       "\n",
       "  VERS_TYP  VHA VK_DHT4A  VK_DISTANZ  VK_ZG11  WOHNDAUER_2008  WOHNLAGE  \\\n",
       "0      NaN  NaN      NaN         NaN      NaN             NaN       NaN   \n",
       "1      2.0  0.0      8.0        11.0     10.0             9.0       4.0   \n",
       "2      1.0  0.0      9.0         9.0      6.0             9.0       2.0   \n",
       "3      1.0  1.0      7.0        10.0     11.0             9.0       7.0   \n",
       "4      2.0  0.0      3.0         5.0      4.0             9.0       3.0   \n",
       "\n",
       "   ZABEOTYP  ANREDE_KZ  ALTERSKATEGORIE_GROB  \n",
       "0         3          1                     2  \n",
       "1         5          2                     1  \n",
       "2         5          2                     3  \n",
       "3         3          2                     4  \n",
       "4         4          1                     3  \n",
       "\n",
       "[5 rows x 279 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresh = int(0.85*10000)\n",
    "azdias_NaN_drop = azdias_NaN.dropna(axis=1, thresh=thresh, inplace=False)\n",
    "azdias_NaN_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89945ae4",
   "metadata": {},
   "source": [
    "Find the columns that were dropped due to high NaN percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fac84d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AGER_TYP', 'ALTERSKATEGORIE_FEIN', 'ALTER_HH', 'ALTER_KIND1', 'ALTER_KIND2', 'ALTER_KIND3', 'ALTER_KIND4', 'D19_BANKEN_ONLINE_QUOTE_12', 'D19_GESAMT_ONLINE_QUOTE_12', 'D19_KONSUMTYP', 'D19_LETZTER_KAUF_BRANCHE', 'D19_LOTTO', 'D19_SOZIALES', 'D19_TELKO_ONLINE_QUOTE_12', 'D19_VERSAND_ONLINE_QUOTE_12', 'D19_VERSI_ONLINE_QUOTE_12', 'EXTSEL992', 'KBA05_ALTER1', 'KBA05_ALTER2', 'KBA05_ALTER3', 'KBA05_ALTER4', 'KBA05_ANHANG', 'KBA05_ANTG1', 'KBA05_ANTG2', 'KBA05_ANTG3', 'KBA05_ANTG4', 'KBA05_AUTOQUOT', 'KBA05_BAUMAX', 'KBA05_CCM1', 'KBA05_CCM2', 'KBA05_CCM3', 'KBA05_CCM4', 'KBA05_DIESEL', 'KBA05_FRAU', 'KBA05_GBZ', 'KBA05_HERST1', 'KBA05_HERST2', 'KBA05_HERST3', 'KBA05_HERST4', 'KBA05_HERST5', 'KBA05_KRSAQUOT', 'KBA05_KRSHERST1', 'KBA05_KRSHERST2', 'KBA05_KRSHERST3', 'KBA05_KRSKLEIN', 'KBA05_KRSOBER', 'KBA05_KRSVAN', 'KBA05_KRSZUL', 'KBA05_KW1', 'KBA05_KW2', 'KBA05_KW3', 'KBA05_MAXAH', 'KBA05_MAXBJ', 'KBA05_MAXHERST', 'KBA05_MAXSEG', 'KBA05_MAXVORB', 'KBA05_MOD1', 'KBA05_MOD2', 'KBA05_MOD3', 'KBA05_MOD4', 'KBA05_MOD8', 'KBA05_MOTOR', 'KBA05_MOTRAD', 'KBA05_SEG1', 'KBA05_SEG10', 'KBA05_SEG2', 'KBA05_SEG3', 'KBA05_SEG4', 'KBA05_SEG5', 'KBA05_SEG6', 'KBA05_SEG7', 'KBA05_SEG8', 'KBA05_SEG9', 'KBA05_VORB0', 'KBA05_VORB1', 'KBA05_VORB2', 'KBA05_ZUL1', 'KBA05_ZUL2', 'KBA05_ZUL3', 'KBA05_ZUL4', 'KKK', 'KK_KUNDENTYP', 'MOBI_REGIO', 'REGIOTYP', 'TITEL_KZ', 'VHN', 'W_KEIT_KIND_HH']\n"
     ]
    }
   ],
   "source": [
    "list_1 = list(azdias_NaN_drop.columns.values)\n",
    "list_2 = list(azdias_NaN.columns.values)\n",
    "column_NaN = np.setdiff1d(list_2,list_1).tolist()\n",
    "print(column_NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56b9e3",
   "metadata": {},
   "source": [
    "1.4 Find the columns of object dtypes: either convert the column into int/float dtypes, or drop the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "764a8a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAMEO_DEU_2015</th>\n",
       "      <th>CAMEO_DEUG_2015</th>\n",
       "      <th>CAMEO_INTL_2015</th>\n",
       "      <th>EINGEFUEGT_AM</th>\n",
       "      <th>OST_WEST_KZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8A</td>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>1992-02-10 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4C</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>1992-02-12 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2A</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1997-04-21 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6B</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>1992-02-12 00:00:00</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CAMEO_DEU_2015 CAMEO_DEUG_2015 CAMEO_INTL_2015        EINGEFUEGT_AM  \\\n",
       "0            NaN             NaN             NaN                  NaN   \n",
       "1             8A               8              51  1992-02-10 00:00:00   \n",
       "2             4C               4              24  1992-02-12 00:00:00   \n",
       "3             2A               2              12  1997-04-21 00:00:00   \n",
       "4             6B               6              43  1992-02-12 00:00:00   \n",
       "\n",
       "  OST_WEST_KZ  \n",
       "0         NaN  \n",
       "1           W  \n",
       "2           W  \n",
       "3           W  \n",
       "4           W  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_object = azdias_NaN_drop.select_dtypes(include='object')\n",
    "\n",
    "azdias_object.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2d8bc6",
   "metadata": {},
   "source": [
    "CAMEO_DEU_2015 is categorical information. It is hard to use dummy variables as it has a large number of categories. Meanwhile, the major information about social class is also documented in CAMEO_DEUG_2015. Therefore, I decided to drop it. \n",
    "\n",
    "CAMEO_DEUG_2015 is ordinal information. I decided to convert it into integer. Notice that CAMEO_DEUG_2015 has 'X' for unknown. \n",
    "\n",
    "CAMEO_INTL_2015 has two information: the first number denotes family wealth, the second number denotes family composition. So I decided to split it into two columns. Notice that CAMEO_INTL_2015 has 'XX' for unknown. \n",
    "\n",
    "EINGEFUEGT_AM not much information as to what it is, so I decided to drop it. \n",
    "\n",
    "OST_WEST_KZ is converted to a dummy variable, as there is only West(W) and Other(O). If it's West, the value is 1; else 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3a1653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ob_col(df):\n",
    "    '''\n",
    "    It does data processing on the columns that have object as dtypes\n",
    "    \n",
    "    Input:\n",
    "    df: original Dataframe;\n",
    "    \n",
    "    Output:\n",
    "    processed DataFrame with only float/int values \n",
    "    '''\n",
    "    #convert some remaining unknown cases into NaN \n",
    "    object_NaN_dict = {'CAMEO_DEUG_2015':['X'], 'CAMEO_INTL_2015': ['XX']}\n",
    "    for col in list(object_NaN_dict.keys()):\n",
    "        df.loc[:, col] = df.loc[:, col].apply(lambda x: np.nan if x in object_NaN_dict[col] else x)\n",
    "        \n",
    "    #drop two columns that do not have much additional information\n",
    "    df_1 = df.drop(axis=1, columns=['CAMEO_DEU_2015', 'EINGEFUEGT_AM'], inplace=False)\n",
    "    \n",
    "    #convert Cameo_Deug_2015 into integers\n",
    "    df_1.loc[:,'CAMEO_DEUG_2015'] = df_1.loc[:,'CAMEO_DEUG_2015'].apply(lambda x: float(x))\n",
    "    \n",
    "    #split CAMEO_INTL_2015 into two columns \n",
    "    df_1.loc[:,'CAMEO_INTL_2015'] = df_1.loc[:,'CAMEO_INTL_2015'].apply(lambda x: str(x))\n",
    "    df_1.loc[:,'CAMEO_INTL_FAM_Wealth'] = [int(df_1['CAMEO_INTL_2015'].iloc[i][0]) if df_1['CAMEO_INTL_2015'].iloc[i] != 'nan' else np.nan for i in range(df_1.shape[0])]\n",
    "    df_1.loc[:, 'CAMEO_INTL_FAM_COMPOSITION'] = [int(df_1['CAMEO_INTL_2015'].iloc[i][1]) if str(df_1['CAMEO_INTL_2015'].iloc[i]) != 'nan' else np.nan for i in range(df_1.shape[0])]\n",
    "\n",
    "    #convert OST_WEST_KZ into a dummy variable\n",
    "    OST_dict = {'W': 1, 'E':0}\n",
    "    df_1['OST_WEST_KZ'] = df_1['OST_WEST_KZ'].map(OST_dict)\n",
    "    \n",
    "    df_2 = df_1.drop(axis=1, columns = 'CAMEO_INTL_2015', inplace = False)\n",
    "    return df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7d07d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "azdias_process = process_ob_col(azdias_NaN_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60defccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 278 entries, LNR to CAMEO_INTL_FAM_COMPOSITION\n",
      "dtypes: float64(191), int64(87)\n",
      "memory usage: 21.2 MB\n"
     ]
    }
   ],
   "source": [
    "azdias_process.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725dab2c",
   "metadata": {},
   "source": [
    "1.5 Delete the rows with high percentage of NaN. Fill all NaN with column mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47022a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_row(df):\n",
    "    \"\"\"Drop the rows of the DataFrame that has over 15% NaN\n",
    "       \n",
    "       Input:original DataFrame; \n",
    "       \n",
    "       Output:a transformed DataFrame that dropped high NaN rows\"\"\"\n",
    "       \n",
    "    thresh = int(0.85*df.shape[1])\n",
    "    df_1 = df.dropna(axis=0, thresh=thresh, inplace=False)\n",
    "    \n",
    "    return df_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50dfb13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_drop_row = drop_row(azdias_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a22303ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>BALLRAUM</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "      <th>CAMEO_INTL_FAM_Wealth</th>\n",
       "      <th>CAMEO_INTL_FAM_COMPOSITION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>910220</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>910225</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910226</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>910241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>910244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LNR  AKT_DAT_KL  ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  ANZ_KINDER  \\\n",
       "1  910220         9.0                 11.0           0.0         0.0   \n",
       "2  910225         9.0                 10.0           0.0         0.0   \n",
       "3  910226         1.0                  1.0           0.0         0.0   \n",
       "4  910241         1.0                  3.0           0.0         0.0   \n",
       "5  910244         1.0                  5.0           0.0         0.0   \n",
       "\n",
       "   ANZ_PERSONEN  ANZ_STATISTISCHE_HAUSHALTE  ANZ_TITEL  ARBEIT  BALLRAUM  ...  \\\n",
       "1           2.0                        12.0        0.0     3.0       6.0  ...   \n",
       "2           1.0                         7.0        0.0     3.0       2.0  ...   \n",
       "3           0.0                         2.0        0.0     2.0       4.0  ...   \n",
       "4           4.0                         3.0        0.0     4.0       2.0  ...   \n",
       "5           1.0                         2.0        0.0     2.0       6.0  ...   \n",
       "\n",
       "   VK_DHT4A  VK_DISTANZ  VK_ZG11  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  \\\n",
       "1       8.0        11.0     10.0             9.0       4.0         5   \n",
       "2       9.0         9.0      6.0             9.0       2.0         5   \n",
       "3       7.0        10.0     11.0             9.0       7.0         3   \n",
       "4       3.0         5.0      4.0             9.0       3.0         4   \n",
       "5      10.0         7.0      4.0             9.0       7.0         4   \n",
       "\n",
       "   ANREDE_KZ  ALTERSKATEGORIE_GROB  CAMEO_INTL_FAM_Wealth  \\\n",
       "1          2                     1                    5.0   \n",
       "2          2                     3                    2.0   \n",
       "3          2                     4                    1.0   \n",
       "4          1                     3                    4.0   \n",
       "5          2                     1                    5.0   \n",
       "\n",
       "   CAMEO_INTL_FAM_COMPOSITION  \n",
       "1                         1.0  \n",
       "2                         4.0  \n",
       "3                         2.0  \n",
       "4                         3.0  \n",
       "5                         4.0  \n",
       "\n",
       "[5 rows x 278 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_drop_row.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f30ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_col_mean(df):\n",
    "    \"\"\"Fill the NaN with column mean\n",
    "       \n",
    "       Input: original DataFrame\n",
    "       \n",
    "       Output: transformed DataFrame that fills all NaN\"\"\"\n",
    "    \n",
    "    col_mean = df.mean()\n",
    "    df_1 = df.fillna(col_mean, inplace=False)\n",
    "    \n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e058c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_finished = fill_col_mean(azdias_drop_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f717cce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_finished.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d543bd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1 in azdias_finished #make sure there is no unknown cases, which tend to be denoted by -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f042cec4",
   "metadata": {},
   "source": [
    "1.6 Final Step for Data Cleaning: I created a function that collects all previous data cleaning procedures. So that for all the rest of DataFrames, I will just need to run this function on them for all preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e243f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(df):\n",
    "    \"\"\"All data cleaning process for the raw DataFrame from csv file \n",
    "       input: original dataframe \n",
    "       return: processed dataframe that has only integer/float as its values and no NaN\"\"\"\n",
    "    df_1 = convert_unknown_to_NaN(df) #convert the unknown values to NaN\n",
    "    df_2 = df_1.drop(axis=1, columns=column_NaN, inplace=False) #drop the columns that have high percentage of NaN\n",
    "    df_3 = process_ob_col(df_2) #process the columns that have object dtypes \n",
    "    df_4 = drop_row(df_3) #drop the rows that have a high percentage of NaN \n",
    "    df_5 = fill_col_mean(df_4) #fill the remaining NaN with column means\n",
    "    \n",
    "    return df_5 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4905967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del azdias_1, azdias_NaN, azdias_NaN_drop, azdias_object, azdias_process, azdias_drop_row, azdias_finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20296982",
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_processed = data_process(azdias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf5d03fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>BALLRAUM</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "      <th>CAMEO_INTL_FAM_Wealth</th>\n",
       "      <th>CAMEO_INTL_FAM_COMPOSITION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>910220</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>910225</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>910226</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>910241</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>910244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LNR  AKT_DAT_KL  ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  ANZ_KINDER  \\\n",
       "1  910220         9.0                 11.0           0.0         0.0   \n",
       "2  910225         9.0                 10.0           0.0         0.0   \n",
       "3  910226         1.0                  1.0           0.0         0.0   \n",
       "4  910241         1.0                  3.0           0.0         0.0   \n",
       "5  910244         1.0                  5.0           0.0         0.0   \n",
       "\n",
       "   ANZ_PERSONEN  ANZ_STATISTISCHE_HAUSHALTE  ANZ_TITEL  ARBEIT  BALLRAUM  ...  \\\n",
       "1           2.0                        12.0        0.0     3.0       6.0  ...   \n",
       "2           1.0                         7.0        0.0     3.0       2.0  ...   \n",
       "3           0.0                         2.0        0.0     2.0       4.0  ...   \n",
       "4           4.0                         3.0        0.0     4.0       2.0  ...   \n",
       "5           1.0                         2.0        0.0     2.0       6.0  ...   \n",
       "\n",
       "   VK_DHT4A  VK_DISTANZ  VK_ZG11  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  \\\n",
       "1       8.0        11.0     10.0             9.0       4.0         5   \n",
       "2       9.0         9.0      6.0             9.0       2.0         5   \n",
       "3       7.0        10.0     11.0             9.0       7.0         3   \n",
       "4       3.0         5.0      4.0             9.0       3.0         4   \n",
       "5      10.0         7.0      4.0             9.0       7.0         4   \n",
       "\n",
       "   ANREDE_KZ  ALTERSKATEGORIE_GROB  CAMEO_INTL_FAM_Wealth  \\\n",
       "1          2                     1                    5.0   \n",
       "2          2                     3                    2.0   \n",
       "3          2                     4                    1.0   \n",
       "4          1                     3                    4.0   \n",
       "5          2                     1                    5.0   \n",
       "\n",
       "   CAMEO_INTL_FAM_COMPOSITION  \n",
       "1                         1.0  \n",
       "2                         4.0  \n",
       "3                         2.0  \n",
       "4                         3.0  \n",
       "5                         4.0  \n",
       "\n",
       "[5 rows x 278 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7e40e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_processed.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ae0b2",
   "metadata": {},
   "source": [
    "## PCA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96547fa6",
   "metadata": {},
   "source": [
    "2.1 Final minor adjustment to the data to facilitate the PCA model training. First I noticed that LNR is unique for each row and functions as an identifier for each individual. So I decided to drop it. Meanwhile, I want to normalize the data using a MinMaxScaler, so that the model can be trained faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ae2bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_processed.drop(axis=1, columns = 'LNR', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ead7a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>BALLRAUM</th>\n",
       "      <th>CAMEO_DEUG_2015</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "      <th>CAMEO_INTL_FAM_Wealth</th>\n",
       "      <th>CAMEO_INTL_FAM_COMPOSITION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.015590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AKT_DAT_KL  ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  ANZ_KINDER  ANZ_PERSONEN  \\\n",
       "1         1.0             0.018487           0.0         0.0      0.044444   \n",
       "2         1.0             0.016807           0.0         0.0      0.022222   \n",
       "3         0.0             0.001681           0.0         0.0      0.000000   \n",
       "4         0.0             0.005042           0.0         0.0      0.088889   \n",
       "5         0.0             0.008403           0.0         0.0      0.022222   \n",
       "\n",
       "   ANZ_STATISTISCHE_HAUSHALTE  ANZ_TITEL  ARBEIT  BALLRAUM  CAMEO_DEUG_2015  \\\n",
       "1                    0.026726        0.0   0.250  0.833333            0.875   \n",
       "2                    0.015590        0.0   0.250  0.166667            0.375   \n",
       "3                    0.004454        0.0   0.125  0.500000            0.125   \n",
       "4                    0.006682        0.0   0.375  0.166667            0.625   \n",
       "5                    0.004454        0.0   0.125  0.833333            0.875   \n",
       "\n",
       "   ...  VK_DHT4A  VK_DISTANZ  VK_ZG11  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  \\\n",
       "1  ...       0.7    0.833333      0.9             1.0     0.500       0.8   \n",
       "2  ...       0.8    0.666667      0.5             1.0     0.250       0.8   \n",
       "3  ...       0.6    0.750000      1.0             1.0     0.875       0.4   \n",
       "4  ...       0.2    0.333333      0.3             1.0     0.375       0.6   \n",
       "5  ...       0.9    0.500000      0.3             1.0     0.875       0.6   \n",
       "\n",
       "   ANREDE_KZ  ALTERSKATEGORIE_GROB  CAMEO_INTL_FAM_Wealth  \\\n",
       "1        1.0                 0.000                   1.00   \n",
       "2        1.0                 0.250                   0.25   \n",
       "3        1.0                 0.375                   0.00   \n",
       "4        0.0                 0.250                   0.75   \n",
       "5        1.0                 0.000                   1.00   \n",
       "\n",
       "   CAMEO_INTL_FAM_COMPOSITION  \n",
       "1                        0.00  \n",
       "2                        0.75  \n",
       "3                        0.25  \n",
       "4                        0.50  \n",
       "5                        0.75  \n",
       "\n",
       "[5 rows x 277 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range= (0, 1)) #set the range to be between 0 and 1 for all values in the dataframe \n",
    "\n",
    "azdias_scaled= pd.DataFrame(scaler.fit_transform(azdias_processed.astype(float)))\n",
    "azdias_scaled.index = azdias_processed.index\n",
    "azdias_scaled.columns = azdias_processed.columns\n",
    "azdias_scaled.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d03c0add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 785421 entries, 1 to 891220\n",
      "Columns: 277 entries, AKT_DAT_KL to CAMEO_INTL_FAM_COMPOSITION\n",
      "dtypes: float64(277)\n",
      "memory usage: 1.6 GB\n"
     ]
    }
   ],
   "source": [
    "azdias_scaled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adaae6d",
   "metadata": {},
   "source": [
    "2.2 Define a PCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5dea17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker \n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket_name = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7511a6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training artifacts will be uploaded to: s3://sagemaker-us-west-1-178050996200/Arvato_Project/\n"
     ]
    }
   ],
   "source": [
    "prefix = 'Arvato_Project'\n",
    "\n",
    "output_path='s3://{}/{}/'.format(bucket_name, prefix)\n",
    "\n",
    "print('Training artifacts will be uploaded to: {}'.format(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "73a9c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a PCA model\n",
    "from sagemaker import PCA\n",
    "\n",
    "N_COMPONENTS=276  #This is a rule of thumb: n-1, for starting the PCA model \n",
    "\n",
    "pca_SM = PCA(role=role,\n",
    "             instance_count=1,\n",
    "             instance_type='ml.m5.2xlarge',\n",
    "             output_path=output_path,\n",
    "             num_components=N_COMPONENTS, \n",
    "             sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23939aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_np = azdias_scaled.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb802241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to RecordSet format\n",
    "formatted_train_data = pca_SM.record_set(train_data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe03902",
   "metadata": {},
   "source": [
    "2.3 Train the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3027c9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-07 00:32:44 Starting - Starting the training job...\n",
      "2021-06-07 00:32:47 Starting - Launching requested ML instancesProfilerReport-1623025964: InProgress\n",
      "......\n",
      "2021-06-07 00:34:13 Starting - Preparing the instances for training.........\n",
      "2021-06-07 00:35:39 Downloading - Downloading input data\n",
      "2021-06-07 00:35:39 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:56 INFO 139699241162560] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-conf.json: {'algorithm_mode': 'regular', 'subtract_mean': 'true', 'extra_components': '-1', 'force_dense': 'true', 'epochs': 1, '_log_level': 'info', '_kvstore': 'dist_sync', '_num_kv_servers': 'auto', '_num_gpus': 'auto'}\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:56 INFO 139699241162560] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '277', 'num_components': '276', 'mini_batch_size': '500'}\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:56 INFO 139699241162560] Final configuration: {'algorithm_mode': 'regular', 'subtract_mean': 'true', 'extra_components': '-1', 'force_dense': 'true', 'epochs': 1, '_log_level': 'info', '_kvstore': 'dist_sync', '_num_kv_servers': 'auto', '_num_gpus': 'auto', 'feature_dim': '277', 'num_components': '276', 'mini_batch_size': '500'}\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:56 WARNING 139699241162560] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-136-113.us-west-1.compute.internal', 'TRAINING_JOB_NAME': 'pca-2021-06-07-00-32-44-462', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-1:178050996200:training-job/pca-2021-06-07-00-32-44-462', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/9b8e26e7-02e9-41af-9f00-d93034f1b666', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'void', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-west-1', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '4', 'DMLC_INTERFACE': 'eth0', 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/d1d0fa5d-bcaa-48ba-a192-cd33d0c7947a', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/d1d0fa5d-bcaa-48ba-a192-cd33d0c7947a', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml'}\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] envs={'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-136-113.us-west-1.compute.internal', 'TRAINING_JOB_NAME': 'pca-2021-06-07-00-32-44-462', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-1:178050996200:training-job/pca-2021-06-07-00-32-44-462', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/9b8e26e7-02e9-41af-9f00-d93034f1b666', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'void', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-west-1', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '4', 'DMLC_INTERFACE': 'eth0', 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/d1d0fa5d-bcaa-48ba-a192-cd33d0c7947a', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/d1d0fa5d-bcaa-48ba-a192-cd33d0c7947a', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'DMLC_ROLE': 'scheduler', 'DMLC_PS_ROOT_URI': '10.0.136.113', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-136-113.us-west-1.compute.internal', 'TRAINING_JOB_NAME': 'pca-2021-06-07-00-32-44-462', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-1:178050996200:training-job/pca-2021-06-07-00-32-44-462', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/9b8e26e7-02e9-41af-9f00-d93034f1b666', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'void', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-west-1', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '4', 'DMLC_INTERFACE': 'eth0', 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/d1d0fa5d-bcaa-48ba-a192-cd33d0c7947a', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/d1d0fa5d-bcaa-48ba-a192-cd33d0c7947a', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml'}\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] envs={'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-136-113.us-west-1.compute.internal', 'TRAINING_JOB_NAME': 'pca-2021-06-07-00-32-44-462', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-1:178050996200:training-job/pca-2021-06-07-00-32-44-462', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/9b8e26e7-02e9-41af-9f00-d93034f1b666', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'void', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-west-1', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '4', 'DMLC_INTERFACE': 'eth0', 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/d1d0fa5d-bcaa-48ba-a192-cd33d0c7947a', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/d1d0fa5d-bcaa-48ba-a192-cd33d0c7947a', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'DMLC_ROLE': 'server', 'DMLC_PS_ROOT_URI': '10.0.136.113', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] Environment: {'ENVROOT': '/opt/amazon', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'HOSTNAME': 'ip-10-0-136-113.us-west-1.compute.internal', 'TRAINING_JOB_NAME': 'pca-2021-06-07-00-32-44-462', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-west-1:178050996200:training-job/pca-2021-06-07-00-32-44-462', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/9b8e26e7-02e9-41af-9f00-d93034f1b666', 'CANONICAL_ENVROOT': '/opt/amazon', 'PYTHONUNBUFFERED': 'TRUE', 'NVIDIA_VISIBLE_DEVICES': 'void', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python3.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PWD': '/', 'LANG': 'en_US.utf8', 'AWS_REGION': 'us-west-1', 'HOME': '/root', 'SHLVL': '1', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'OMP_NUM_THREADS': '4', 'DMLC_INTERFACE': 'eth0', 'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/d1d0fa5d-bcaa-48ba-a192-cd33d0c7947a', 'ECS_CONTAINER_METADATA_URI_V4': 'http://169.254.170.2/v4/d1d0fa5d-bcaa-48ba-a192-cd33d0c7947a', 'SAGEMAKER_HTTP_PORT': '8080', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'DMLC_ROLE': 'worker', 'DMLC_PS_ROOT_URI': '10.0.136.113', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_SERVER': '1', 'DMLC_NUM_WORKER': '1'}\u001b[0m\n",
      "\u001b[34mProcess 40 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 49 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] Using default worker.\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] Create Store: dist_sync\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] nvidia-smi: took 0.059 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] The default executor is <PCAExecutor on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] 277 feature(s) found in 'data'.\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:35:57 INFO 139699241162560] <PCAExecutor on cpu(0)> is assigned to batch slice from 0 to 499.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623026157.1436365, \"EndTime\": 1623026157.98258, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 809.0195655822754, \"count\": 1, \"min\": 809.0195655822754, \"max\": 809.0195655822754}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623026157.9827645, \"EndTime\": 1623026157.9827995, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[2021-06-07 00:35:57.989] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 845, \"num_examples\": 1, \"num_bytes\": 568000}\u001b[0m\n",
      "\u001b[34m[2021-06-07 00:36:00.844] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 2847, \"num_examples\": 1571, \"num_bytes\": 892238256}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623026157.982719, \"EndTime\": 1623026160.8451474, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"update.time\": {\"sum\": 2855.8576107025146, \"count\": 1, \"min\": 2855.8576107025146, \"max\": 2855.8576107025146}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:36:00 INFO 139699241162560] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623026157.9892554, \"EndTime\": 1623026160.8455093, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 785421.0, \"count\": 1, \"min\": 785421, \"max\": 785421}, \"Total Batches Seen\": {\"sum\": 1571.0, \"count\": 1, \"min\": 1571, \"max\": 1571}, \"Max Records Seen Between Resets\": {\"sum\": 785421.0, \"count\": 1, \"min\": 785421, \"max\": 785421}, \"Max Batches Seen Between Resets\": {\"sum\": 1571.0, \"count\": 1, \"min\": 1571, \"max\": 1571}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 785421.0, \"count\": 1, \"min\": 785421, \"max\": 785421}, \"Number of Batches Since Last Reset\": {\"sum\": 1571.0, \"count\": 1, \"min\": 1571, \"max\": 1571}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:36:00 INFO 139699241162560] #throughput_metric: host=algo-1, train throughput=274972.9719203735 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623026160.8452394, \"EndTime\": 1623026160.8815503, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 35.742998123168945, \"count\": 1, \"min\": 35.742998123168945, \"max\": 35.742998123168945}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 00:36:00 INFO 139699241162560] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623026160.8816519, \"EndTime\": 1623026160.8831575, \"Dimensions\": {\"Algorithm\": \"PCA\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 528.7818908691406, \"count\": 1, \"min\": 528.7818908691406, \"max\": 528.7818908691406}, \"totaltime\": {\"sum\": 4397.158145904541, \"count\": 1, \"min\": 4397.158145904541, \"max\": 4397.158145904541}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-06-07 00:36:14 Uploading - Uploading generated training model\n",
      "2021-06-07 00:36:14 Completed - Training job completed\n",
      "Training seconds: 49\n",
      "Billable seconds: 49\n",
      "CPU times: user 461 ms, sys: 23.1 ms, total: 484 ms\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train the PCA mode on the formatted data\n",
    "pca_SM.fit(formatted_train_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0849e6c",
   "metadata": {},
   "source": [
    "2.4 Access Model Attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ebc2d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_name= 'pca-2021-06-07-00-32-44-462'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8634f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "model_key = os.path.join(prefix, training_job_name, 'output/model.tar.gz')\n",
    "#download and unzip the model \n",
    "boto3.resource('s3').Bucket(bucket_name).download_file(model_key, 'model.tar.gz')\n",
    "os.system('tar -zxvf model.tar.gz')\n",
    "os.system('unzip model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "152478d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "43f33c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model_params = mx.ndarray.load('model_algo-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994b4092",
   "metadata": {},
   "source": [
    "2.5 Pick the top n components that explain 80% variance in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cad5d84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0\n",
      "0            NaN\n",
      "1       3.780533\n",
      "2      11.522208\n",
      "3      12.418921\n",
      "4      15.376204\n",
      "..           ...\n",
      "271   815.508240\n",
      "272   919.391479\n",
      "273   963.828003\n",
      "274  1116.289307\n",
      "275  1366.424927\n",
      "\n",
      "[276 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "s=pd.DataFrame(pca_model_params['s'].asnumpy()) #get the s value for each component\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68b30bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explained_variance(s, n_top_components):\n",
    "    '''Calculates the approx. data variance that n_top_components captures.\n",
    "       :param s: A dataframe of singular values for top components; \n",
    "           the top value is in the last row.\n",
    "       :param n_top_components: An integer, the number of top components to use.\n",
    "       :return: The expected data variance covered by the n_top_components.'''\n",
    "    start_idx = N_COMPONENTS - n_top_components \n",
    "    sum = 0\n",
    "    for i in range(start_idx, N_COMPONENTS):\n",
    "        sum = sum + np.square(s.iloc[i, 0])\n",
    "    exp_variance = sum / np.square(s).sum()\n",
    "    \n",
    "    #alternative: exp_variance = np.square(s.iloc[start_idx:,:]).sum()/np.square(s).sum()\n",
    "    return exp_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7df7b33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:  0.8061778\n"
     ]
    }
   ],
   "source": [
    "#test how many components can capture 80% variance of the data\n",
    "\n",
    "n_top_components = 80 # select a value for the number of top components\n",
    "\n",
    "# calculate the explained variance\n",
    "exp_variance = explained_variance(s, n_top_components)\n",
    "print('Explained variance: ', exp_variance[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f901e",
   "metadata": {},
   "source": [
    "Top 80 components can explain 80.6% data variance, which I think is sufficient. So I decided to reduce the features to top 80 components. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86bab41",
   "metadata": {},
   "source": [
    "2.5 Transform the dataframe to top 80 components to prepare for the K-Means Model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4c6950",
   "metadata": {},
   "source": [
    "Upload train_data_np to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2c941088",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fcb0444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train_data_np)\n",
    "df.to_csv(os.path.join(data_dir, 'population.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b129f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'Arvato_Project'\n",
    "\n",
    "population_location = session.upload_data(os.path.join(data_dir, 'population.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb4ba33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    }
   ],
   "source": [
    "pca_transformer = pca_SM.transformer(instance_count = 1, instance_type = 'ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dc716592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:30 INFO 140359184901952] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] nvidia-smi: took 0.033 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loading entry points\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] Number of server workers: 4\u001b[0m\n",
      "\u001b[34m[2021-06-07 03:17:31 +0000] [1] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-06-07 03:17:31 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-06-07 03:17:31 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2021-06-07 03:17:31 +0000] [54] [INFO] Booting worker with pid: 54\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-07 03:17:31 +0000] [65] [INFO] Booting worker with pid: 65\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-07 03:17:31 +0000] [76] [INFO] Booting worker with pid: 76\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-07 03:17:31 +0000] [86] [INFO] Booting worker with pid: 86\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035851.1515226, \"EndTime\": 1623035852.7877607, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[32m2021-06-07T03:17:32.792:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4427.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4427.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035851.2674649, \"EndTime\": 1623035857.7874928, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035851.2674649, \"EndTime\": 1623035857.7874928, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035851.230175, \"EndTime\": 1623035857.890562, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035852.7878902, \"EndTime\": 1623035858.1163647, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035851.2761068, \"EndTime\": 1623035858.1381347, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035851.230175, \"EndTime\": 1623035857.890562, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035852.7878902, \"EndTime\": 1623035858.1163647, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035851.2761068, \"EndTime\": 1623035858.1381347, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:39 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:39 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:39 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:39 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:39 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:39 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:39 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:39 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035857.890702, \"EndTime\": 1623035861.0487454, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035857.7882085, \"EndTime\": 1623035861.1706297, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035858.1382763, \"EndTime\": 1623035861.5267463, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035857.890702, \"EndTime\": 1623035861.0487454, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035857.7882085, \"EndTime\": 1623035861.1706297, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035858.1382763, \"EndTime\": 1623035861.5267463, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035858.1164637, \"EndTime\": 1623035861.80557, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035858.1164637, \"EndTime\": 1623035861.80557, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035861.1707234, \"EndTime\": 1623035864.4982955, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035861.0488336, \"EndTime\": 1623035864.661615, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035861.1707234, \"EndTime\": 1623035864.4982955, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035861.0488336, \"EndTime\": 1623035864.661615, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035861.5268445, \"EndTime\": 1623035864.951109, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035861.8056693, \"EndTime\": 1623035865.2025626, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035861.5268445, \"EndTime\": 1623035864.951109, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035861.8056693, \"EndTime\": 1623035865.2025626, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:48 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035865.2027228, \"EndTime\": 1623035868.9949987, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:48 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035865.2027228, \"EndTime\": 1623035868.9949987, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035868.153258, \"EndTime\": 1623035871.375228, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035868.2633464, \"EndTime\": 1623035871.5617528, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035868.153258, \"EndTime\": 1623035871.375228, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035868.2633464, \"EndTime\": 1623035871.5617528, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035868.0707295, \"EndTime\": 1623035871.9015641, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035868.9950871, \"EndTime\": 1623035872.683151, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035868.0707295, \"EndTime\": 1623035871.9015641, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035868.9950871, \"EndTime\": 1623035872.683151, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035871.561844, \"EndTime\": 1623035875.0437598, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035871.375331, \"EndTime\": 1623035875.399551, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035871.9016573, \"EndTime\": 1623035875.7245078, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035871.561844, \"EndTime\": 1623035875.0437598, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035871.375331, \"EndTime\": 1623035875.399551, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035871.9016573, \"EndTime\": 1623035875.7245078, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:55 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4428.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035872.683236, \"EndTime\": 1623035876.464324, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:55 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4428.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035872.683236, \"EndTime\": 1623035876.464324, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:57 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:57 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:57 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:57 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:57 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:57 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:57 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:57 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035875.3996549, \"EndTime\": 1623035878.6255257, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035875.3996549, \"EndTime\": 1623035878.6255257, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035875.0438523, \"EndTime\": 1623035879.099772, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035875.724596, \"EndTime\": 1623035879.470683, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:59 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:59 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:59 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:59 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035875.0438523, \"EndTime\": 1623035879.099772, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035875.724596, \"EndTime\": 1623035879.470683, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:59 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:59 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:59 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:59 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035876.4644115, \"EndTime\": 1623035880.0952036, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035876.4644115, \"EndTime\": 1623035880.0952036, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035878.625613, \"EndTime\": 1623035882.1203306, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:02 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:02 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:02 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:02 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035879.0998592, \"EndTime\": 1623035882.8543766, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035878.625613, \"EndTime\": 1623035882.1203306, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:02 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:02 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:02 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:02 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035879.0998592, \"EndTime\": 1623035882.8543766, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035879.4708178, \"EndTime\": 1623035883.1546223, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035880.0952885, \"EndTime\": 1623035883.474887, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:03 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:03 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:03 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:03 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4412.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035879.4708178, \"EndTime\": 1623035883.1546223, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035880.0952885, \"EndTime\": 1623035883.474887, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:03 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:03 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:03 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:03 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4412.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035882.1204228, \"EndTime\": 1623035885.5232804, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035882.1204228, \"EndTime\": 1623035885.5232804, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:06 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:06 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:06 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:06 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:06 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:06 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035883.1547143, \"EndTime\": 1623035886.4094589, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035882.8544652, \"EndTime\": 1623035886.7464564, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:06 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:06 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035883.1547143, \"EndTime\": 1623035886.4094589, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035882.8544652, \"EndTime\": 1623035886.7464564, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035885.5238318, \"EndTime\": 1623035888.9666476, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:09 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:09 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:09 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:09 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035885.5238318, \"EndTime\": 1623035888.9666476, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:09 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:09 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:09 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:09 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035886.4095545, \"EndTime\": 1623035889.988562, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035886.7465594, \"EndTime\": 1623035890.088338, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:10 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:10 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:10 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:10 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035886.972171, \"EndTime\": 1623035890.8303304, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035886.4095545, \"EndTime\": 1623035889.988562, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035886.7465594, \"EndTime\": 1623035890.088338, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:10 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:10 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:10 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:10 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035886.972171, \"EndTime\": 1623035890.8303304, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035888.9667387, \"EndTime\": 1623035892.5316057, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035888.9667387, \"EndTime\": 1623035892.5316057, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:13 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:13 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:13 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:13 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:13 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:13 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:13 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:13 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035889.9890952, \"EndTime\": 1623035893.5244088, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035890.0884333, \"EndTime\": 1623035893.8582773, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035889.9890952, \"EndTime\": 1623035893.5244088, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035890.0884333, \"EndTime\": 1623035893.8582773, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035890.830424, \"EndTime\": 1623035894.4277978, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035890.830424, \"EndTime\": 1623035894.4277978, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:15 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:15 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:15 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:15 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035892.5316958, \"EndTime\": 1623035895.8543248, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:15 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:15 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:15 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:15 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035892.5316958, \"EndTime\": 1623035895.8543248, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:16 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:16 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:16 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:16 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:16 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:16 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:16 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:16 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:17 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:17 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035894.4283412, \"EndTime\": 1623035897.893737, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:17 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:17 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035894.4283412, \"EndTime\": 1623035897.893737, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035895.8544128, \"EndTime\": 1623035899.2718308, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:19 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:19 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:19 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:19 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4410.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035895.8544128, \"EndTime\": 1623035899.2718308, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:19 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:19 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:19 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:19 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4410.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035896.9409394, \"EndTime\": 1623035900.488993, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035896.9409394, \"EndTime\": 1623035900.488993, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035897.7625375, \"EndTime\": 1623035901.0557606, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035897.8943112, \"EndTime\": 1623035901.3121095, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035897.7625375, \"EndTime\": 1623035901.0557606, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035897.8943112, \"EndTime\": 1623035901.3121095, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:22 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:22 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:22 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:22 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:22 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:22 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:22 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:22 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035899.2719204, \"EndTime\": 1623035902.4627533, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035899.2719204, \"EndTime\": 1623035902.4627533, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:23 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:23 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:23 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:23 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035900.4890857, \"EndTime\": 1623035903.9066362, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:23 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:23 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:23 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:23 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035900.4890857, \"EndTime\": 1623035903.9066362, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035901.3122065, \"EndTime\": 1623035904.5928016, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:24 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035901.3122065, \"EndTime\": 1623035904.5928016, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:24 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:24 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:24 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:24 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:24 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:24 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:24 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035901.0558515, \"EndTime\": 1623035904.985024, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4412.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035901.0558515, \"EndTime\": 1623035904.985024, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4412.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035902.4628425, \"EndTime\": 1623035905.9744477, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:26 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:26 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:26 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:26 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035902.4628425, \"EndTime\": 1623035905.9744477, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:26 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:26 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:26 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:26 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:28 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:28 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:28 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:28 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:28 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:28 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:28 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:28 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035905.9745374, \"EndTime\": 1623035909.353544, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:29 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:29 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:29 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:29 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:28 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:28 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:28 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:28 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035905.9745374, \"EndTime\": 1623035909.353544, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:29 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:29 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:29 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:29 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:30 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:30 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:30 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:30 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:30 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:30 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:30 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:30 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035907.533234, \"EndTime\": 1623035911.305101, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035908.0177495, \"EndTime\": 1623035911.7570846, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035907.533234, \"EndTime\": 1623035911.305101, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035908.0177495, \"EndTime\": 1623035911.7570846, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035908.5028174, \"EndTime\": 1623035912.6733508, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035909.3537605, \"EndTime\": 1623035912.7246027, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035908.5028174, \"EndTime\": 1623035912.6733508, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035909.3537605, \"EndTime\": 1623035912.7246027, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035911.3055608, \"EndTime\": 1623035914.6772003, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035911.3055608, \"EndTime\": 1623035914.6772003, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035911.757173, \"EndTime\": 1623035915.334533, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035911.757173, \"EndTime\": 1623035915.334533, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035912.7246912, \"EndTime\": 1623035915.9987218, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035912.6734376, \"EndTime\": 1623035916.2372367, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035912.7246912, \"EndTime\": 1623035915.9987218, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035912.6734376, \"EndTime\": 1623035916.2372367, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035916.238108, \"EndTime\": 1623035919.3657017, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:39 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:39 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:39 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:39 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035915.9988122, \"EndTime\": 1623035919.7603807, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035916.238108, \"EndTime\": 1623035919.3657017, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:39 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:39 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:39 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:39 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035915.9988122, \"EndTime\": 1623035919.7603807, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035918.0718403, \"EndTime\": 1623035921.5056002, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035918.0718403, \"EndTime\": 1623035921.5056002, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035918.949545, \"EndTime\": 1623035922.1623645, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035918.949545, \"EndTime\": 1623035922.1623645, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035919.3657913, \"EndTime\": 1623035923.037622, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035919.7609036, \"EndTime\": 1623035923.4809644, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035919.3657913, \"EndTime\": 1623035923.037622, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035919.7609036, \"EndTime\": 1623035923.4809644, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4431.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035921.5056927, \"EndTime\": 1623035924.9116423, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4431.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035921.5056927, \"EndTime\": 1623035924.9116423, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035922.162457, \"EndTime\": 1623035925.6072357, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035922.162457, \"EndTime\": 1623035925.6072357, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035923.0377223, \"EndTime\": 1623035926.8563263, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035923.0377223, \"EndTime\": 1623035926.8563263, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035924.9117322, \"EndTime\": 1623035928.7214317, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035924.9117322, \"EndTime\": 1623035928.7214317, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035925.6073332, \"EndTime\": 1623035929.110883, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:49 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035925.6073332, \"EndTime\": 1623035929.110883, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:49 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:50 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:50 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:50 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:50 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:50 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:50 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:50 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:50 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035926.8564162, \"EndTime\": 1623035930.326787, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035926.983164, \"EndTime\": 1623035930.7651997, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035926.8564162, \"EndTime\": 1623035930.326787, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035926.983164, \"EndTime\": 1623035930.7651997, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4429.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4429.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035929.1115355, \"EndTime\": 1623035932.465665, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035928.721519, \"EndTime\": 1623035932.6889493, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035929.1115355, \"EndTime\": 1623035932.465665, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035928.721519, \"EndTime\": 1623035932.6889493, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035930.3268821, \"EndTime\": 1623035934.011702, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035930.7658598, \"EndTime\": 1623035934.430224, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:54 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:54 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:54 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:54 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035930.3268821, \"EndTime\": 1623035934.011702, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035930.7658598, \"EndTime\": 1623035934.430224, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:54 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:54 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:54 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:54 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:55 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:55 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:55 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:55 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:55 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:55 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:55 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:55 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035932.6890383, \"EndTime\": 1623035936.0602582, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035932.4657562, \"EndTime\": 1623035936.4230666, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4428.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035932.6890383, \"EndTime\": 1623035936.0602582, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035932.4657562, \"EndTime\": 1623035936.4230666, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4428.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:58 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:58 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:58 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035934.4303508, \"EndTime\": 1623035938.1595018, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:58 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:58 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:58 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035934.4303508, \"EndTime\": 1623035938.1595018, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:58 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:58 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:58 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:58 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:58 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035936.0608165, \"EndTime\": 1623035939.6673815, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035936.4231684, \"EndTime\": 1623035939.8294735, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:58 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:58 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:58 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035936.0608165, \"EndTime\": 1623035939.6673815, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035936.4231684, \"EndTime\": 1623035939.8294735, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035937.4299173, \"EndTime\": 1623035940.7907515, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035937.4299173, \"EndTime\": 1623035940.7907515, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:01 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:01 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:01 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:01 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4409.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035938.1600082, \"EndTime\": 1623035941.7067819, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:01 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:01 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:01 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:01 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4409.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035938.1600082, \"EndTime\": 1623035941.7067819, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:02 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:02 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:02 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:02 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:02 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:02 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:02 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:02 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035939.6679873, \"EndTime\": 1623035943.1349854, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035939.8295658, \"EndTime\": 1623035943.5018358, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035939.6679873, \"EndTime\": 1623035943.1349854, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035939.8295658, \"EndTime\": 1623035943.5018358, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:03 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:03 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:03 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:03 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035940.7908525, \"EndTime\": 1623035944.1847763, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:03 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:03 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:03 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:03 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035940.7908525, \"EndTime\": 1623035944.1847763, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035941.7068741, \"EndTime\": 1623035944.9273748, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035941.7068741, \"EndTime\": 1623035944.9273748, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:05 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:05 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:05 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:05 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:05 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:05 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:05 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:05 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035943.135559, \"EndTime\": 1623035946.6249387, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035943.135559, \"EndTime\": 1623035946.6249387, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035944.1848674, \"EndTime\": 1623035947.4988637, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035944.1848674, \"EndTime\": 1623035947.4988637, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035944.927465, \"EndTime\": 1623035948.1515796, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035944.927465, \"EndTime\": 1623035948.1515796, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035946.625551, \"EndTime\": 1623035950.0997233, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035946.9877558, \"EndTime\": 1623035950.516319, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035947.498963, \"EndTime\": 1623035950.7361922, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035946.625551, \"EndTime\": 1623035950.0997233, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035946.9877558, \"EndTime\": 1623035950.516319, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035947.498963, \"EndTime\": 1623035950.7361922, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:10 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:10 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:10 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:10 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:10 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:10 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:10 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:10 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035948.1521325, \"EndTime\": 1623035951.6436627, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035948.1521325, \"EndTime\": 1623035951.6436627, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:12 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:12 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:12 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:12 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:12 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:12 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:12 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:12 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035950.100349, \"EndTime\": 1623035953.6763449, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035950.100349, \"EndTime\": 1623035953.6763449, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035950.51641, \"EndTime\": 1623035954.0881028, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035950.7362893, \"EndTime\": 1623035954.4970782, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035951.643753, \"EndTime\": 1623035954.8520427, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035950.51641, \"EndTime\": 1623035954.0881028, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035950.7362893, \"EndTime\": 1623035954.4970782, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035951.643753, \"EndTime\": 1623035954.8520427, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035953.6764371, \"EndTime\": 1623035956.8630896, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035953.6764371, \"EndTime\": 1623035956.8630896, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:17 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:17 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:17 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:17 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035954.4976335, \"EndTime\": 1623035958.1245122, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:17 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:17 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:17 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:17 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035954.4976335, \"EndTime\": 1623035958.1245122, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035954.8525157, \"EndTime\": 1623035958.635055, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035954.8525157, \"EndTime\": 1623035958.635055, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:19 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:19 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:19 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:19 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:19 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:19 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:19 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:19 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035956.8631938, \"EndTime\": 1623035960.6847084, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035957.3311367, \"EndTime\": 1623035960.9091604, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035956.8631938, \"EndTime\": 1623035960.6847084, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035957.3311367, \"EndTime\": 1623035960.9091604, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035958.124603, \"EndTime\": 1623035961.564362, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035958.124603, \"EndTime\": 1623035961.564362, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035958.6355972, \"EndTime\": 1623035962.2535422, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:22 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:22 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:22 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:22 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035958.6355972, \"EndTime\": 1623035962.2535422, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:22 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:22 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:22 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:22 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:23 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:23 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:23 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:23 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:23 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:23 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:23 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:23 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035960.6852527, \"EndTime\": 1623035964.3901625, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035960.9092538, \"EndTime\": 1623035964.7172258, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035960.6852527, \"EndTime\": 1623035964.3901625, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035960.9092538, \"EndTime\": 1623035964.7172258, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035961.5644546, \"EndTime\": 1623035965.1727545, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035961.5644546, \"EndTime\": 1623035965.1727545, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035962.253639, \"EndTime\": 1623035965.902164, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035962.253639, \"EndTime\": 1623035965.902164, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:30 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:30 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:30 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:30 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:30 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:30 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:30 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:30 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035967.875272, \"EndTime\": 1623035971.5841236, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035967.875272, \"EndTime\": 1623035971.5841236, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035968.6648967, \"EndTime\": 1623035972.0910418, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035968.326417, \"EndTime\": 1623035972.2710464, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035968.6648967, \"EndTime\": 1623035972.0910418, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035968.326417, \"EndTime\": 1623035972.2710464, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035969.142392, \"EndTime\": 1623035972.8401666, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035969.142392, \"EndTime\": 1623035972.8401666, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4411.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4411.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035971.5842822, \"EndTime\": 1623035974.873307, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035971.5842822, \"EndTime\": 1623035974.873307, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035972.2711663, \"EndTime\": 1623035975.712194, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035972.2711663, \"EndTime\": 1623035975.712194, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035972.0911455, \"EndTime\": 1623035976.0766604, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035972.8406765, \"EndTime\": 1623035976.4780235, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035972.0911455, \"EndTime\": 1623035976.0766604, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035972.8406765, \"EndTime\": 1623035976.4780235, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035976.0768223, \"EndTime\": 1623035979.5080566, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035976.4781063, \"EndTime\": 1623035979.7510476, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035976.0768223, \"EndTime\": 1623035979.5080566, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035976.4781063, \"EndTime\": 1623035979.7510476, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:39 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:39 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:39 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:39 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:39 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:39 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:39 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:39 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035978.2224176, \"EndTime\": 1623035981.8778608, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035978.2224176, \"EndTime\": 1623035981.8778608, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035979.1679614, \"EndTime\": 1623035982.6388059, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035979.508143, \"EndTime\": 1623035982.719607, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035979.1679614, \"EndTime\": 1623035982.6388059, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035979.508143, \"EndTime\": 1623035982.719607, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035979.7511697, \"EndTime\": 1623035983.2015364, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035979.7511697, \"EndTime\": 1623035983.2015364, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:44 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:44 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:44 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:44 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:44 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:44 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:44 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:44 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035981.8784225, \"EndTime\": 1623035985.0793874, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035982.6389148, \"EndTime\": 1623035985.816052, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035981.8784225, \"EndTime\": 1623035985.0793874, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035982.6389148, \"EndTime\": 1623035985.816052, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035982.719692, \"EndTime\": 1623035986.220706, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035982.719692, \"EndTime\": 1623035986.220706, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035983.2017014, \"EndTime\": 1623035986.8399754, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035983.2017014, \"EndTime\": 1623035986.8399754, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4428.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035985.816143, \"EndTime\": 1623035989.5385714, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4428.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035985.816143, \"EndTime\": 1623035989.5385714, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035986.840065, \"EndTime\": 1623035990.4968061, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035986.840065, \"EndTime\": 1623035990.4968061, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:51 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:51 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:51 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:51 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:51 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:51 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:51 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:51 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035988.7242703, \"EndTime\": 1623035992.3850794, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035989.5386617, \"EndTime\": 1623035992.7260883, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:52 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:52 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:52 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035988.7242703, \"EndTime\": 1623035992.3850794, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035989.5386617, \"EndTime\": 1623035992.7260883, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:52 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:52 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:52 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035989.4119635, \"EndTime\": 1623035993.2181256, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035989.4119635, \"EndTime\": 1623035993.2181256, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035990.496906, \"EndTime\": 1623035994.327545, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035990.496906, \"EndTime\": 1623035994.327545, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:55 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:55 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:55 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:55 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035992.385622, \"EndTime\": 1623035995.5963986, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035992.726178, \"EndTime\": 1623035995.9201238, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:55 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:55 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:55 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:55 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035992.385622, \"EndTime\": 1623035995.5963986, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035992.726178, \"EndTime\": 1623035995.9201238, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035993.2182174, \"EndTime\": 1623035996.4767652, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035993.2182174, \"EndTime\": 1623035996.4767652, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:57 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:57 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:57 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035994.3276305, \"EndTime\": 1623035997.7648315, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:57 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:57 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:57 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035994.3276305, \"EndTime\": 1623035997.7648315, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:58 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:58 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:58 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:58 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:58 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:58 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:58 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:58 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035995.5967977, \"EndTime\": 1623035999.083497, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:59 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:59 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:59 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:59 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035995.9202125, \"EndTime\": 1623035999.870723, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035995.5967977, \"EndTime\": 1623035999.083497, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:59 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:59 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:59 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:59 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035995.9202125, \"EndTime\": 1623035999.870723, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035996.4768639, \"EndTime\": 1623036000.009583, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035996.4768639, \"EndTime\": 1623036000.009583, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035997.764922, \"EndTime\": 1623036001.1070733, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:01 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:01 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:01 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:01 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4427.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035997.764922, \"EndTime\": 1623036001.1070733, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:01 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:01 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:01 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:01 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4427.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035999.0835881, \"EndTime\": 1623036002.5485356, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035999.0835881, \"EndTime\": 1623036002.5485356, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:03 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:03 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:03 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:03 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035999.8711965, \"EndTime\": 1623036003.4026682, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036000.0096762, \"EndTime\": 1623036003.469295, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:03 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:03 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:03 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:03 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035999.8711965, \"EndTime\": 1623036003.4026682, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036000.0096762, \"EndTime\": 1623036003.469295, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036001.1071892, \"EndTime\": 1623036004.52347, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036001.1071892, \"EndTime\": 1623036004.52347, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:05 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:05 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:05 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:05 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4427.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:05 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:05 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:05 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:05 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4427.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036002.5489218, \"EndTime\": 1623036006.004409, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:06 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:06 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:06 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:06 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036002.5489218, \"EndTime\": 1623036006.004409, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:06 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:06 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:06 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:06 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036004.5235612, \"EndTime\": 1623036007.8216863, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036004.5235612, \"EndTime\": 1623036007.8216863, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036006.0045016, \"EndTime\": 1623036009.409349, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:09 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:09 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:09 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:09 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2964.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036006.0045016, \"EndTime\": 1623036009.409349, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:09 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:09 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:09 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:09 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2964.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036006.980324, \"EndTime\": 1623036010.429557, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036007.275039, \"EndTime\": 1623036010.4491146, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036006.980324, \"EndTime\": 1623036010.429557, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036007.275039, \"EndTime\": 1623036010.4491146, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036007.8217797, \"EndTime\": 1623036011.121326, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036009.4094381, \"EndTime\": 1623036011.8352046, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036007.8217797, \"EndTime\": 1623036011.121326, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036009.4094381, \"EndTime\": 1623036011.8352046, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca_transformer.transform(population_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0f7f7830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[35mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[35mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:30 INFO 140359184901952] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] nvidia-smi: took 0.033 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:30 INFO 140359184901952] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] nvidia-smi: took 0.033 seconds to run.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loading entry points\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] Number of server workers: 4\u001b[0m\n",
      "\u001b[34m[2021-06-07 03:17:31 +0000] [1] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-06-07 03:17:31 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-06-07 03:17:31 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2021-06-07 03:17:31 +0000] [54] [INFO] Booting worker with pid: 54\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-07 03:17:31 +0000] [65] [INFO] Booting worker with pid: 65\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-07 03:17:31 +0000] [76] [INFO] Booting worker with pid: 76\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-07 03:17:31 +0000] [86] [INFO] Booting worker with pid: 86\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] loading model...\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] loading entry points\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] loaded request iterator application/json\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] loaded response encoder application/json\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] Number of server workers: 4\u001b[0m\n",
      "\u001b[35m[2021-06-07 03:17:31 +0000] [1] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2021-06-07 03:17:31 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2021-06-07 03:17:31 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2021-06-07 03:17:31 +0000] [54] [INFO] Booting worker with pid: 54\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] loading model...\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2021-06-07 03:17:31 +0000] [65] [INFO] Booting worker with pid: 65\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] loading model...\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2021-06-07 03:17:31 +0000] [76] [INFO] Booting worker with pid: 76\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] loading model...\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2021-06-07 03:17:31 +0000] [86] [INFO] Booting worker with pid: 86\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:31 INFO 140359184901952] ...model loaded.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:31 INFO 140359184901952] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035851.1515226, \"EndTime\": 1623035852.7877607, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035851.1515226, \"EndTime\": 1623035852.7877607, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[32m2021-06-07T03:17:32.792:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4427.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4427.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035851.2674649, \"EndTime\": 1623035857.7874928, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035851.2674649, \"EndTime\": 1623035857.7874928, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035851.230175, \"EndTime\": 1623035857.890562, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035852.7878902, \"EndTime\": 1623035858.1163647, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035851.2761068, \"EndTime\": 1623035858.1381347, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035851.230175, \"EndTime\": 1623035857.890562, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035852.7878902, \"EndTime\": 1623035858.1163647, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035851.2761068, \"EndTime\": 1623035858.1381347, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:38 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:39 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:39 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:39 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:39 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:38 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:39 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:39 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:39 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:39 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035857.890702, \"EndTime\": 1623035861.0487454, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035857.7882085, \"EndTime\": 1623035861.1706297, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035858.1382763, \"EndTime\": 1623035861.5267463, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035857.890702, \"EndTime\": 1623035861.0487454, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035857.7882085, \"EndTime\": 1623035861.1706297, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035858.1382763, \"EndTime\": 1623035861.5267463, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035858.1164637, \"EndTime\": 1623035861.80557, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035858.1164637, \"EndTime\": 1623035861.80557, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:41 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:41 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035861.1707234, \"EndTime\": 1623035864.4982955, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035861.0488336, \"EndTime\": 1623035864.661615, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035861.1707234, \"EndTime\": 1623035864.4982955, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035861.0488336, \"EndTime\": 1623035864.661615, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035861.5268445, \"EndTime\": 1623035864.951109, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035861.8056693, \"EndTime\": 1623035865.2025626, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:45 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035861.5268445, \"EndTime\": 1623035864.951109, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035861.8056693, \"EndTime\": 1623035865.2025626, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:45 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035864.4983895, \"EndTime\": 1623035868.0706363, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035864.9512246, \"EndTime\": 1623035868.1531022, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035864.6617084, \"EndTime\": 1623035868.2632596, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:48 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035864.4983895, \"EndTime\": 1623035868.0706363, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035864.9512246, \"EndTime\": 1623035868.1531022, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035864.6617084, \"EndTime\": 1623035868.2632596, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:48 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:48 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:48 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:48 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:48 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:48 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:48 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:48 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:48 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:48 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:48 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035865.2027228, \"EndTime\": 1623035868.9949987, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:48 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:48 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:48 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:48 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035865.2027228, \"EndTime\": 1623035868.9949987, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035868.153258, \"EndTime\": 1623035871.375228, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035868.2633464, \"EndTime\": 1623035871.5617528, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035868.153258, \"EndTime\": 1623035871.375228, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035868.2633464, \"EndTime\": 1623035871.5617528, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035868.0707295, \"EndTime\": 1623035871.9015641, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035868.9950871, \"EndTime\": 1623035872.683151, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035868.0707295, \"EndTime\": 1623035871.9015641, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035868.9950871, \"EndTime\": 1623035872.683151, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035871.561844, \"EndTime\": 1623035875.0437598, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035871.375331, \"EndTime\": 1623035875.399551, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035871.9016573, \"EndTime\": 1623035875.7245078, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035871.561844, \"EndTime\": 1623035875.0437598, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035871.375331, \"EndTime\": 1623035875.399551, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035871.9016573, \"EndTime\": 1623035875.7245078, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:55 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:55 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:55 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:55 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4428.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035872.683236, \"EndTime\": 1623035876.464324, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:55 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:55 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:55 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:55 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4428.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035872.683236, \"EndTime\": 1623035876.464324, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:57 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:57 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:57 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:57 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:57 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:57 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:57 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:57 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035875.3996549, \"EndTime\": 1623035878.6255257, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035875.3996549, \"EndTime\": 1623035878.6255257, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035875.0438523, \"EndTime\": 1623035879.099772, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035875.724596, \"EndTime\": 1623035879.470683, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:59 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:59 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:59 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:17:59 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035875.0438523, \"EndTime\": 1623035879.099772, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035875.724596, \"EndTime\": 1623035879.470683, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:59 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:59 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:59 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:17:59 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035876.4644115, \"EndTime\": 1623035880.0952036, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035876.4644115, \"EndTime\": 1623035880.0952036, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035878.625613, \"EndTime\": 1623035882.1203306, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:02 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:02 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:02 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:02 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035879.0998592, \"EndTime\": 1623035882.8543766, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035878.625613, \"EndTime\": 1623035882.1203306, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:02 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:02 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:02 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:02 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035879.0998592, \"EndTime\": 1623035882.8543766, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035879.4708178, \"EndTime\": 1623035883.1546223, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035880.0952885, \"EndTime\": 1623035883.474887, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:03 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:03 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:03 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:03 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4412.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035879.4708178, \"EndTime\": 1623035883.1546223, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035880.0952885, \"EndTime\": 1623035883.474887, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:03 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:03 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:03 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:03 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4412.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035882.1204228, \"EndTime\": 1623035885.5232804, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035882.1204228, \"EndTime\": 1623035885.5232804, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:06 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:06 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:06 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:06 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:06 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:06 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035883.1547143, \"EndTime\": 1623035886.4094589, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035882.8544652, \"EndTime\": 1623035886.7464564, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:06 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:06 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035883.1547143, \"EndTime\": 1623035886.4094589, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035882.8544652, \"EndTime\": 1623035886.7464564, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035883.4749782, \"EndTime\": 1623035886.9720812, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035883.4749782, \"EndTime\": 1623035886.9720812, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035885.5238318, \"EndTime\": 1623035888.9666476, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:09 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:09 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:09 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:09 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035885.5238318, \"EndTime\": 1623035888.9666476, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:09 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:09 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:09 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:09 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035886.4095545, \"EndTime\": 1623035889.988562, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035886.7465594, \"EndTime\": 1623035890.088338, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:10 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:10 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:10 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:10 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035886.972171, \"EndTime\": 1623035890.8303304, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035886.4095545, \"EndTime\": 1623035889.988562, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035886.7465594, \"EndTime\": 1623035890.088338, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:10 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:10 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:10 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:10 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035886.972171, \"EndTime\": 1623035890.8303304, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035888.9667387, \"EndTime\": 1623035892.5316057, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035888.9667387, \"EndTime\": 1623035892.5316057, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:13 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:13 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:13 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:13 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:13 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:13 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:13 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:13 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035889.9890952, \"EndTime\": 1623035893.5244088, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035890.0884333, \"EndTime\": 1623035893.8582773, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035889.9890952, \"EndTime\": 1623035893.5244088, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035890.0884333, \"EndTime\": 1623035893.8582773, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035890.830424, \"EndTime\": 1623035894.4277978, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035890.830424, \"EndTime\": 1623035894.4277978, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:15 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:15 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:15 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:15 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035892.5316958, \"EndTime\": 1623035895.8543248, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:15 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:15 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:15 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:15 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035892.5316958, \"EndTime\": 1623035895.8543248, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:16 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:16 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:16 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:16 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:16 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:16 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:16 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:16 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035893.5244958, \"EndTime\": 1623035896.9408486, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035893.5244958, \"EndTime\": 1623035896.9408486, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035893.8587923, \"EndTime\": 1623035897.7624443, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:17 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:17 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:17 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:17 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035894.4283412, \"EndTime\": 1623035897.893737, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035893.8587923, \"EndTime\": 1623035897.7624443, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:17 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:17 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:17 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:17 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035894.4283412, \"EndTime\": 1623035897.893737, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035895.8544128, \"EndTime\": 1623035899.2718308, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:19 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:19 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:19 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:19 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4410.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035895.8544128, \"EndTime\": 1623035899.2718308, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:19 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:19 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:19 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:19 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4410.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035896.9409394, \"EndTime\": 1623035900.488993, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035896.9409394, \"EndTime\": 1623035900.488993, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035897.7625375, \"EndTime\": 1623035901.0557606, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035897.8943112, \"EndTime\": 1623035901.3121095, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035897.7625375, \"EndTime\": 1623035901.0557606, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035897.8943112, \"EndTime\": 1623035901.3121095, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:22 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:22 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:22 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:22 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:22 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:22 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:22 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:22 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035899.2719204, \"EndTime\": 1623035902.4627533, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035899.2719204, \"EndTime\": 1623035902.4627533, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:23 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:23 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:23 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:23 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035900.4890857, \"EndTime\": 1623035903.9066362, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:23 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:23 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:23 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:23 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035900.4890857, \"EndTime\": 1623035903.9066362, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035901.3122065, \"EndTime\": 1623035904.5928016, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:24 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035901.3122065, \"EndTime\": 1623035904.5928016, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:24 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:24 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:24 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:24 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:24 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:24 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:24 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035901.0558515, \"EndTime\": 1623035904.985024, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4412.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035901.0558515, \"EndTime\": 1623035904.985024, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4412.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035902.4628425, \"EndTime\": 1623035905.9744477, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:26 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:26 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:26 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:26 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035902.4628425, \"EndTime\": 1623035905.9744477, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:26 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:26 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:26 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:26 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035903.9067295, \"EndTime\": 1623035907.5331433, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035903.9067295, \"EndTime\": 1623035907.5331433, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035904.592893, \"EndTime\": 1623035908.0176587, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035904.985652, \"EndTime\": 1623035908.5026484, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:28 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:28 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:28 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:28 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035904.592893, \"EndTime\": 1623035908.0176587, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035904.985652, \"EndTime\": 1623035908.5026484, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:28 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:28 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:28 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:28 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:28 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:28 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:28 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:28 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035905.9745374, \"EndTime\": 1623035909.353544, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:29 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:29 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:29 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:29 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:28 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:28 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:28 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:28 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035905.9745374, \"EndTime\": 1623035909.353544, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:29 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:29 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:29 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:29 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:30 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:30 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:30 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:30 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:30 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:30 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:30 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:30 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035907.533234, \"EndTime\": 1623035911.305101, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035908.0177495, \"EndTime\": 1623035911.7570846, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035907.533234, \"EndTime\": 1623035911.305101, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035908.0177495, \"EndTime\": 1623035911.7570846, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035908.5028174, \"EndTime\": 1623035912.6733508, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035909.3537605, \"EndTime\": 1623035912.7246027, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035908.5028174, \"EndTime\": 1623035912.6733508, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035909.3537605, \"EndTime\": 1623035912.7246027, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035911.3055608, \"EndTime\": 1623035914.6772003, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035911.3055608, \"EndTime\": 1623035914.6772003, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035911.757173, \"EndTime\": 1623035915.334533, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035911.757173, \"EndTime\": 1623035915.334533, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035912.7246912, \"EndTime\": 1623035915.9987218, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035912.6734376, \"EndTime\": 1623035916.2372367, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035912.7246912, \"EndTime\": 1623035915.9987218, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035912.6734376, \"EndTime\": 1623035916.2372367, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:37 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:37 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:37 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:37 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:37 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:37 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:37 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:37 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035914.6772888, \"EndTime\": 1623035918.0717494, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:38 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:38 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:38 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:38 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035914.6772888, \"EndTime\": 1623035918.0717494, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:38 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:38 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:38 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:38 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035915.334619, \"EndTime\": 1623035918.949453, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035916.238108, \"EndTime\": 1623035919.3657017, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:39 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:39 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:39 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:39 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035915.9988122, \"EndTime\": 1623035919.7603807, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035915.334619, \"EndTime\": 1623035918.949453, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035916.238108, \"EndTime\": 1623035919.3657017, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:39 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:39 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:39 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:39 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035915.9988122, \"EndTime\": 1623035919.7603807, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035918.0718403, \"EndTime\": 1623035921.5056002, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035918.0718403, \"EndTime\": 1623035921.5056002, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035918.949545, \"EndTime\": 1623035922.1623645, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035918.949545, \"EndTime\": 1623035922.1623645, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035919.3657913, \"EndTime\": 1623035923.037622, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035919.7609036, \"EndTime\": 1623035923.4809644, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035919.3657913, \"EndTime\": 1623035923.037622, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035919.7609036, \"EndTime\": 1623035923.4809644, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4431.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:44 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035921.5056927, \"EndTime\": 1623035924.9116423, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4431.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:44 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035921.5056927, \"EndTime\": 1623035924.9116423, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035922.162457, \"EndTime\": 1623035925.6072357, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035922.162457, \"EndTime\": 1623035925.6072357, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035923.0377223, \"EndTime\": 1623035926.8563263, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035923.0377223, \"EndTime\": 1623035926.8563263, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035923.481604, \"EndTime\": 1623035926.9830651, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:47 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:47 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:47 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:47 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035923.481604, \"EndTime\": 1623035926.9830651, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:47 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:47 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:47 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:47 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:47 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:47 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:47 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:47 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035924.9117322, \"EndTime\": 1623035928.7214317, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:47 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:47 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:47 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:47 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035924.9117322, \"EndTime\": 1623035928.7214317, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035925.6073332, \"EndTime\": 1623035929.110883, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:49 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035925.6073332, \"EndTime\": 1623035929.110883, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:49 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:50 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:50 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:50 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:50 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:50 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:50 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:50 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:50 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035926.8564162, \"EndTime\": 1623035930.326787, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035926.983164, \"EndTime\": 1623035930.7651997, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035926.8564162, \"EndTime\": 1623035930.326787, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035926.983164, \"EndTime\": 1623035930.7651997, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:51 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4429.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:51 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4429.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035929.1115355, \"EndTime\": 1623035932.465665, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035928.721519, \"EndTime\": 1623035932.6889493, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035929.1115355, \"EndTime\": 1623035932.465665, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035928.721519, \"EndTime\": 1623035932.6889493, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035930.3268821, \"EndTime\": 1623035934.011702, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035930.7658598, \"EndTime\": 1623035934.430224, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:54 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:54 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:54 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:54 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035930.3268821, \"EndTime\": 1623035934.011702, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035930.7658598, \"EndTime\": 1623035934.430224, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:54 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:54 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:54 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:54 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:55 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:55 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:55 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:55 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:55 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:55 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:55 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:55 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035932.6890383, \"EndTime\": 1623035936.0602582, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035932.4657562, \"EndTime\": 1623035936.4230666, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4428.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035932.6890383, \"EndTime\": 1623035936.0602582, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035932.4657562, \"EndTime\": 1623035936.4230666, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4428.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:57 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:57 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:57 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:57 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4432.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:57 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:57 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:57 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:57 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4432.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035934.0117924, \"EndTime\": 1623035937.4298263, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035934.0117924, \"EndTime\": 1623035937.4298263, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:58 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:58 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:58 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:58 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035934.4303508, \"EndTime\": 1623035938.1595018, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:58 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:58 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:58 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:58 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035934.4303508, \"EndTime\": 1623035938.1595018, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:58 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:58 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:58 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:58 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:18:58 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035936.0608165, \"EndTime\": 1623035939.6673815, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035936.4231684, \"EndTime\": 1623035939.8294735, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:58 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:58 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:18:58 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035936.0608165, \"EndTime\": 1623035939.6673815, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035936.4231684, \"EndTime\": 1623035939.8294735, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035937.4299173, \"EndTime\": 1623035940.7907515, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035937.4299173, \"EndTime\": 1623035940.7907515, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:01 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:01 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:01 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:01 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4409.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035938.1600082, \"EndTime\": 1623035941.7067819, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:01 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:01 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:01 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:01 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4409.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035938.1600082, \"EndTime\": 1623035941.7067819, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:02 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:02 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:02 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:02 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:02 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:02 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:02 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:02 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035939.6679873, \"EndTime\": 1623035943.1349854, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035939.8295658, \"EndTime\": 1623035943.5018358, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035939.6679873, \"EndTime\": 1623035943.1349854, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035939.8295658, \"EndTime\": 1623035943.5018358, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:03 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:03 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:03 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:03 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035940.7908525, \"EndTime\": 1623035944.1847763, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:03 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:03 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:03 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:03 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035940.7908525, \"EndTime\": 1623035944.1847763, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035941.7068741, \"EndTime\": 1623035944.9273748, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035941.7068741, \"EndTime\": 1623035944.9273748, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:05 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:05 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:05 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:05 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:05 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:05 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:05 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:05 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035943.135559, \"EndTime\": 1623035946.6249387, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035943.135559, \"EndTime\": 1623035946.6249387, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035943.5019202, \"EndTime\": 1623035946.9876657, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035944.1848674, \"EndTime\": 1623035947.4988637, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035943.5019202, \"EndTime\": 1623035946.9876657, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035944.1848674, \"EndTime\": 1623035947.4988637, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035944.927465, \"EndTime\": 1623035948.1515796, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035944.927465, \"EndTime\": 1623035948.1515796, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035946.625551, \"EndTime\": 1623035950.0997233, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035946.9877558, \"EndTime\": 1623035950.516319, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035947.498963, \"EndTime\": 1623035950.7361922, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035946.625551, \"EndTime\": 1623035950.0997233, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035946.9877558, \"EndTime\": 1623035950.516319, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035947.498963, \"EndTime\": 1623035950.7361922, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:10 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:10 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:10 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:10 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:10 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:10 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:10 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:10 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035948.1521325, \"EndTime\": 1623035951.6436627, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035948.1521325, \"EndTime\": 1623035951.6436627, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:11 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:12 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:12 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:12 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:12 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:12 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:12 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:12 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:12 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035950.100349, \"EndTime\": 1623035953.6763449, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035950.100349, \"EndTime\": 1623035953.6763449, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035950.51641, \"EndTime\": 1623035954.0881028, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035950.7362893, \"EndTime\": 1623035954.4970782, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035951.643753, \"EndTime\": 1623035954.8520427, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035950.51641, \"EndTime\": 1623035954.0881028, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035950.7362893, \"EndTime\": 1623035954.4970782, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:14 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035951.643753, \"EndTime\": 1623035954.8520427, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:15 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:15 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035953.6764371, \"EndTime\": 1623035956.8630896, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035953.6764371, \"EndTime\": 1623035956.8630896, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035954.0886867, \"EndTime\": 1623035957.3310342, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035954.0886867, \"EndTime\": 1623035957.3310342, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:17 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:17 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:17 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:17 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035954.4976335, \"EndTime\": 1623035958.1245122, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:17 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:17 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:17 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:17 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035954.4976335, \"EndTime\": 1623035958.1245122, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035954.8525157, \"EndTime\": 1623035958.635055, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035954.8525157, \"EndTime\": 1623035958.635055, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:18 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:19 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:19 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:19 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:19 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:19 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:19 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:19 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:19 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035956.8631938, \"EndTime\": 1623035960.6847084, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035957.3311367, \"EndTime\": 1623035960.9091604, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035956.8631938, \"EndTime\": 1623035960.6847084, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035957.3311367, \"EndTime\": 1623035960.9091604, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035958.124603, \"EndTime\": 1623035961.564362, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035958.124603, \"EndTime\": 1623035961.564362, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035958.6355972, \"EndTime\": 1623035962.2535422, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:22 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:22 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:22 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:22 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:21 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035958.6355972, \"EndTime\": 1623035962.2535422, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:22 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:22 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:22 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:22 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:23 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:23 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:23 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:23 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:23 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:23 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:23 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:23 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035960.6852527, \"EndTime\": 1623035964.3901625, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035960.9092538, \"EndTime\": 1623035964.7172258, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035960.6852527, \"EndTime\": 1623035964.3901625, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035960.9092538, \"EndTime\": 1623035964.7172258, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035961.5644546, \"EndTime\": 1623035965.1727545, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035961.5644546, \"EndTime\": 1623035965.1727545, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035962.253639, \"EndTime\": 1623035965.902164, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:25 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035962.253639, \"EndTime\": 1623035965.902164, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:26 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:26 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035964.3902643, \"EndTime\": 1623035967.8748357, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035964.3902643, \"EndTime\": 1623035967.8748357, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035964.7173266, \"EndTime\": 1623035968.3263273, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035965.172937, \"EndTime\": 1623035968.6647205, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:28 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:28 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:28 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:28 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035964.7173266, \"EndTime\": 1623035968.3263273, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035965.172937, \"EndTime\": 1623035968.6647205, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:28 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:28 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:28 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:28 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4414.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035965.902257, \"EndTime\": 1623035969.1422973, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:29 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035965.902257, \"EndTime\": 1623035969.1422973, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:29 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:30 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:30 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:30 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:30 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:30 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:30 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:30 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:30 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035967.875272, \"EndTime\": 1623035971.5841236, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035967.875272, \"EndTime\": 1623035971.5841236, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035968.6648967, \"EndTime\": 1623035972.0910418, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035968.326417, \"EndTime\": 1623035972.2710464, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035968.6648967, \"EndTime\": 1623035972.0910418, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035968.326417, \"EndTime\": 1623035972.2710464, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035969.142392, \"EndTime\": 1623035972.8401666, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035969.142392, \"EndTime\": 1623035972.8401666, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4411.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:32 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4411.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:33 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035971.5842822, \"EndTime\": 1623035974.873307, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035971.5842822, \"EndTime\": 1623035974.873307, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035972.2711663, \"EndTime\": 1623035975.712194, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:35 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:35 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:35 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:35 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035972.2711663, \"EndTime\": 1623035975.712194, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035972.0911455, \"EndTime\": 1623035976.0766604, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035972.8406765, \"EndTime\": 1623035976.4780235, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035972.0911455, \"EndTime\": 1623035976.0766604, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035972.8406765, \"EndTime\": 1623035976.4780235, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4428.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:36 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4428.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035974.8733974, \"EndTime\": 1623035978.2223222, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035974.8733974, \"EndTime\": 1623035978.2223222, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035975.7122862, \"EndTime\": 1623035979.1678724, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:39 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:39 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:39 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:39 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035976.0768223, \"EndTime\": 1623035979.5080566, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035976.4781063, \"EndTime\": 1623035979.7510476, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035975.7122862, \"EndTime\": 1623035979.1678724, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:39 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:39 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:39 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:39 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035976.0768223, \"EndTime\": 1623035979.5080566, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035976.4781063, \"EndTime\": 1623035979.7510476, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:39 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:39 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:39 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:39 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:39 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:39 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:39 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:39 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:40 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035978.2224176, \"EndTime\": 1623035981.8778608, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035978.2224176, \"EndTime\": 1623035981.8778608, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035979.1679614, \"EndTime\": 1623035982.6388059, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035979.508143, \"EndTime\": 1623035982.719607, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:42 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:42 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:42 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:42 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035979.1679614, \"EndTime\": 1623035982.6388059, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035979.508143, \"EndTime\": 1623035982.719607, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035979.7511697, \"EndTime\": 1623035983.2015364, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:43 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4416.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035979.7511697, \"EndTime\": 1623035983.2015364, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:43 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:44 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:44 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:44 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:44 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:44 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:44 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:44 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:44 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4421.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035981.8784225, \"EndTime\": 1623035985.0793874, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035982.6389148, \"EndTime\": 1623035985.816052, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035981.8784225, \"EndTime\": 1623035985.0793874, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035982.6389148, \"EndTime\": 1623035985.816052, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035982.719692, \"EndTime\": 1623035986.220706, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035982.719692, \"EndTime\": 1623035986.220706, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035983.2017014, \"EndTime\": 1623035986.8399754, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:46 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035983.2017014, \"EndTime\": 1623035986.8399754, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:47 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:47 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:47 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:47 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:47 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:47 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:47 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:47 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4417.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035985.0794783, \"EndTime\": 1623035988.7241688, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035985.0794783, \"EndTime\": 1623035988.7241688, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035986.220801, \"EndTime\": 1623035989.4110136, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:49 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4428.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035985.816143, \"EndTime\": 1623035989.5385714, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035986.220801, \"EndTime\": 1623035989.4110136, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:49 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:49 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:49 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:49 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4428.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035985.816143, \"EndTime\": 1623035989.5385714, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:50 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035986.840065, \"EndTime\": 1623035990.4968061, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:50 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4426.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035986.840065, \"EndTime\": 1623035990.4968061, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:51 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:51 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:51 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:51 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:51 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:51 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:51 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:51 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035988.7242703, \"EndTime\": 1623035992.3850794, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035989.5386617, \"EndTime\": 1623035992.7260883, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:52 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:52 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:52 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035988.7242703, \"EndTime\": 1623035992.3850794, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035989.5386617, \"EndTime\": 1623035992.7260883, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:52 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:52 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:52 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:52 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035989.4119635, \"EndTime\": 1623035993.2181256, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035989.4119635, \"EndTime\": 1623035993.2181256, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:53 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035990.496906, \"EndTime\": 1623035994.327545, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035990.496906, \"EndTime\": 1623035994.327545, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:55 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:55 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:55 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:55 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035992.385622, \"EndTime\": 1623035995.5963986, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035992.726178, \"EndTime\": 1623035995.9201238, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:55 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:55 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:55 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:55 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035992.385622, \"EndTime\": 1623035995.5963986, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035992.726178, \"EndTime\": 1623035995.9201238, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035993.2182174, \"EndTime\": 1623035996.4767652, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:56 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:56 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:56 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:56 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4425.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035993.2182174, \"EndTime\": 1623035996.4767652, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:57 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:57 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:57 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:57 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:57 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:57 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:57 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:57 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035994.3276305, \"EndTime\": 1623035997.7648315, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:57 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:57 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:57 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:57 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4413.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:57 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:57 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:57 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:57 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035994.3276305, \"EndTime\": 1623035997.7648315, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:58 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:58 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:58 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:58 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:58 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:58 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:58 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:58 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035995.5967977, \"EndTime\": 1623035999.083497, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:59 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:59 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:59 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:19:59 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035995.9202125, \"EndTime\": 1623035999.870723, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035995.5967977, \"EndTime\": 1623035999.083497, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:59 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:59 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:59 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:19:59 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035995.9202125, \"EndTime\": 1623035999.870723, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035996.4768639, \"EndTime\": 1623036000.009583, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035996.4768639, \"EndTime\": 1623036000.009583, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4422.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:00 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4415.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035997.764922, \"EndTime\": 1623036001.1070733, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:01 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:01 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:01 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:01 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4427.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035997.764922, \"EndTime\": 1623036001.1070733, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:01 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:01 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:01 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:01 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4427.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035999.0835881, \"EndTime\": 1623036002.5485356, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035999.0835881, \"EndTime\": 1623036002.5485356, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:03 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:03 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:03 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:03 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623035999.8711965, \"EndTime\": 1623036003.4026682, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036000.0096762, \"EndTime\": 1623036003.469295, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:03 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:03 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:03 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:03 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623035999.8711965, \"EndTime\": 1623036003.4026682, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036000.0096762, \"EndTime\": 1623036003.469295, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036001.1071892, \"EndTime\": 1623036004.52347, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4423.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036001.1071892, \"EndTime\": 1623036004.52347, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:04 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:05 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:05 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:05 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:05 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4427.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:05 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:05 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:05 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:05 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4427.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036002.5489218, \"EndTime\": 1623036006.004409, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:06 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:06 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:06 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:06 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036002.5489218, \"EndTime\": 1623036006.004409, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:06 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:06 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:06 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:06 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4424.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036003.4693832, \"EndTime\": 1623036006.9802322, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036003.4693832, \"EndTime\": 1623036006.9802322, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036003.4032028, \"EndTime\": 1623036007.2749512, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036004.5235612, \"EndTime\": 1623036007.8216863, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036003.4032028, \"EndTime\": 1623036007.2749512, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4418.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:07 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:07 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:07 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:07 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4420.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036004.5235612, \"EndTime\": 1623036007.8216863, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:08 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:08 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:08 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:08 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 4419.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036006.0045016, \"EndTime\": 1623036009.409349, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:09 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:09 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:09 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 03:20:09 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2964.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036006.0045016, \"EndTime\": 1623036009.409349, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:09 WARNING 140359184901952] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:09 INFO 140359184901952] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:09 INFO 140359184901952] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 03:20:09 INFO 140359184901952] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2964.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036006.980324, \"EndTime\": 1623036010.429557, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036007.275039, \"EndTime\": 1623036010.4491146, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036006.980324, \"EndTime\": 1623036010.429557, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036007.275039, \"EndTime\": 1623036010.4491146, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036007.8217797, \"EndTime\": 1623036011.121326, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623036009.4094381, \"EndTime\": 1623036011.8352046, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036007.8217797, \"EndTime\": 1623036011.121326, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623036009.4094381, \"EndTime\": 1623036011.8352046, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pca_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b2372a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-1-178050996200/pca-2021-06-07-03-13-37-419/population.csv.out to ../data/population.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $pca_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f1f91fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_azdias = pd.read_csv(os.path.join(data_dir, 'population.csv.out'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "56a5c4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"projection\":[0.0</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>-0.009814</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>-0.041419</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>-0.002356</td>\n",
       "      <td>-0.002631</td>\n",
       "      <td>...</td>\n",
       "      <td>1.010599</td>\n",
       "      <td>-0.013584</td>\n",
       "      <td>0.143470</td>\n",
       "      <td>0.412984</td>\n",
       "      <td>-0.238003</td>\n",
       "      <td>0.805062</td>\n",
       "      <td>-1.091954</td>\n",
       "      <td>1.098113</td>\n",
       "      <td>-1.369603</td>\n",
       "      <td>1.647016286849975]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"projection\":[-0.0</td>\n",
       "      <td>-0.004227</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>-0.004696</td>\n",
       "      <td>-0.001938</td>\n",
       "      <td>0.009331</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.015348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037286</td>\n",
       "      <td>-0.344759</td>\n",
       "      <td>-0.197108</td>\n",
       "      <td>-0.498630</td>\n",
       "      <td>-0.850720</td>\n",
       "      <td>1.104947</td>\n",
       "      <td>-1.635980</td>\n",
       "      <td>0.710835</td>\n",
       "      <td>-0.276317</td>\n",
       "      <td>0.007751166820526]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"projection\":[-0.0</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>-0.018144</td>\n",
       "      <td>-0.004146</td>\n",
       "      <td>-0.001604</td>\n",
       "      <td>-0.008281</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306400</td>\n",
       "      <td>-0.500380</td>\n",
       "      <td>-0.020077</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.575298</td>\n",
       "      <td>0.533876</td>\n",
       "      <td>-0.637406</td>\n",
       "      <td>0.852452</td>\n",
       "      <td>1.328577</td>\n",
       "      <td>-1.270629405975341]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"projection\":[0.0</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>-0.001195</td>\n",
       "      <td>0.009304</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>-0.056253</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>0.085912</td>\n",
       "      <td>-0.035176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132282</td>\n",
       "      <td>-0.385286</td>\n",
       "      <td>-0.962280</td>\n",
       "      <td>0.527872</td>\n",
       "      <td>0.869326</td>\n",
       "      <td>-1.042782</td>\n",
       "      <td>0.067069</td>\n",
       "      <td>-2.146102</td>\n",
       "      <td>-1.237431</td>\n",
       "      <td>-1.113250732421875]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"projection\":[-0.0</td>\n",
       "      <td>-0.003910</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>-0.003612</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>-0.021549</td>\n",
       "      <td>-0.016386</td>\n",
       "      <td>-0.023148</td>\n",
       "      <td>0.006358</td>\n",
       "      <td>0.051482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212654</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>-1.003430</td>\n",
       "      <td>0.764915</td>\n",
       "      <td>-0.116067</td>\n",
       "      <td>0.096514</td>\n",
       "      <td>-0.648185</td>\n",
       "      <td>0.573537</td>\n",
       "      <td>0.475229</td>\n",
       "      <td>-0.505623340606689]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 276 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5    \\\n",
       "0   {\"projection\":[0.0  0.002962  0.003644 -0.009814 -0.000183  0.000558   \n",
       "1  {\"projection\":[-0.0 -0.004227  0.000597  0.002544 -0.004696 -0.001938   \n",
       "2  {\"projection\":[-0.0  0.001334  0.002924 -0.018144 -0.004146 -0.001604   \n",
       "3   {\"projection\":[0.0  0.000383 -0.001195  0.009304  0.004494 -0.056253   \n",
       "4  {\"projection\":[-0.0 -0.003910  0.000094 -0.003612  0.000411 -0.021549   \n",
       "\n",
       "        6         7         8         9    ...       266       267       268  \\\n",
       "0 -0.041419 -0.000217 -0.002356 -0.002631  ...  1.010599 -0.013584  0.143470   \n",
       "1  0.009331  0.001769  0.000555  0.015348  ... -0.037286 -0.344759 -0.197108   \n",
       "2 -0.008281 -0.000027  0.001746  0.016393  ... -0.306400 -0.500380 -0.020077   \n",
       "3  0.006406  0.007586  0.085912 -0.035176  ...  0.132282 -0.385286 -0.962280   \n",
       "4 -0.016386 -0.023148  0.006358  0.051482  ...  0.212654  0.444882 -1.003430   \n",
       "\n",
       "        269       270       271       272       273       274  \\\n",
       "0  0.412984 -0.238003  0.805062 -1.091954  1.098113 -1.369603   \n",
       "1 -0.498630 -0.850720  1.104947 -1.635980  0.710835 -0.276317   \n",
       "2  0.819936  0.575298  0.533876 -0.637406  0.852452  1.328577   \n",
       "3  0.527872  0.869326 -1.042782  0.067069 -2.146102 -1.237431   \n",
       "4  0.764915 -0.116067  0.096514 -0.648185  0.573537  0.475229   \n",
       "\n",
       "                    275  \n",
       "0   1.647016286849975]}  \n",
       "1   0.007751166820526]}  \n",
       "2  -1.270629405975341]}  \n",
       "3  -1.113250732421875]}  \n",
       "4  -0.505623340606689]}  \n",
       "\n",
       "[5 rows x 276 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_azdias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0e7407de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_out(df):\n",
    "    \"\"\"Clean the DataFrame that directly reads from model output, as column 0 and column 275 are messy\n",
    "       input: the original DataFrame. \n",
    "       The function cleaned the original DataFrame so that the transformed DataFrame has output all in the type of float\n",
    "       Return: None, as the cleaning is on the original DataFrame directly\"\"\"\n",
    "    df.iloc[:,0] = df.iloc[:, 0].apply(lambda x: x.split(\"[\"))\n",
    "    df.iloc[:,0] = df.iloc[:, 0].apply(lambda x: float(x[1]))\n",
    "    df.iloc[:, 275] = df.iloc[:, 275].apply(lambda x: x.split(\"]\"))\n",
    "    df.iloc[:, 275] = df.iloc[:, 275].apply(lambda x: float(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b3d035a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_out(pca_azdias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f70c464e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785421 entries, 0 to 785420\n",
      "Columns: 276 entries, 0 to 275\n",
      "dtypes: float64(276)\n",
      "memory usage: 1.6 GB\n"
     ]
    }
   ],
   "source": [
    "pca_azdias.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dd779041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dimensionality-reduced data\n",
    "\n",
    "def create_transformed_df(pca_azdias, n_top_components):\n",
    "    ''' Return a dataframe of data points with component features. \n",
    "        The dataframe should contain component values.\n",
    "        :param pca_azdias: A DataFrame of values for all pca components, returned by a PCA model.\n",
    "        :param n_top_components: An integer, the number of top components to use.\n",
    "        :return: A DataFrame with top n component as columns. The order is listed from most significant to least significant.      \n",
    "     '''\n",
    "    end=pca_azdias.shape[1]\n",
    "    start=end - n_top_components\n",
    "    \n",
    "    pca_selected = pca_azdias.iloc[:, start:end]\n",
    "    transformed_azdias= pca_selected.iloc[:, ::-1]\n",
    "    \n",
    "    return transformed_azdias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "306924c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 80 \n",
    "transformed_pca_azdias = create_transformed_df(pca_azdias, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4b292dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>275</th>\n",
       "      <th>274</th>\n",
       "      <th>273</th>\n",
       "      <th>272</th>\n",
       "      <th>271</th>\n",
       "      <th>270</th>\n",
       "      <th>269</th>\n",
       "      <th>268</th>\n",
       "      <th>267</th>\n",
       "      <th>266</th>\n",
       "      <th>...</th>\n",
       "      <th>205</th>\n",
       "      <th>204</th>\n",
       "      <th>203</th>\n",
       "      <th>202</th>\n",
       "      <th>201</th>\n",
       "      <th>200</th>\n",
       "      <th>199</th>\n",
       "      <th>198</th>\n",
       "      <th>197</th>\n",
       "      <th>196</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.647016</td>\n",
       "      <td>-1.369603</td>\n",
       "      <td>1.098113</td>\n",
       "      <td>-1.091954</td>\n",
       "      <td>0.805062</td>\n",
       "      <td>-0.238003</td>\n",
       "      <td>0.412984</td>\n",
       "      <td>0.143470</td>\n",
       "      <td>-0.013584</td>\n",
       "      <td>1.010599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186213</td>\n",
       "      <td>-0.083994</td>\n",
       "      <td>-0.027546</td>\n",
       "      <td>0.158789</td>\n",
       "      <td>-0.144220</td>\n",
       "      <td>0.426835</td>\n",
       "      <td>-0.173856</td>\n",
       "      <td>-0.016744</td>\n",
       "      <td>-0.479797</td>\n",
       "      <td>-0.297700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007751</td>\n",
       "      <td>-0.276317</td>\n",
       "      <td>0.710835</td>\n",
       "      <td>-1.635980</td>\n",
       "      <td>1.104947</td>\n",
       "      <td>-0.850720</td>\n",
       "      <td>-0.498630</td>\n",
       "      <td>-0.197108</td>\n",
       "      <td>-0.344759</td>\n",
       "      <td>-0.037286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098447</td>\n",
       "      <td>-0.141517</td>\n",
       "      <td>-0.099606</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>0.187617</td>\n",
       "      <td>0.030561</td>\n",
       "      <td>-0.211164</td>\n",
       "      <td>0.098304</td>\n",
       "      <td>-0.175605</td>\n",
       "      <td>-0.125958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.270629</td>\n",
       "      <td>1.328577</td>\n",
       "      <td>0.852452</td>\n",
       "      <td>-0.637406</td>\n",
       "      <td>0.533876</td>\n",
       "      <td>0.575298</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>-0.020077</td>\n",
       "      <td>-0.500380</td>\n",
       "      <td>-0.306400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189295</td>\n",
       "      <td>-0.143599</td>\n",
       "      <td>-0.204862</td>\n",
       "      <td>-0.299902</td>\n",
       "      <td>-0.403524</td>\n",
       "      <td>0.187218</td>\n",
       "      <td>-0.676447</td>\n",
       "      <td>-0.122719</td>\n",
       "      <td>-0.398483</td>\n",
       "      <td>0.259492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.113251</td>\n",
       "      <td>-1.237431</td>\n",
       "      <td>-2.146102</td>\n",
       "      <td>0.067069</td>\n",
       "      <td>-1.042782</td>\n",
       "      <td>0.869326</td>\n",
       "      <td>0.527872</td>\n",
       "      <td>-0.962280</td>\n",
       "      <td>-0.385286</td>\n",
       "      <td>0.132282</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191818</td>\n",
       "      <td>-0.225572</td>\n",
       "      <td>0.295389</td>\n",
       "      <td>-0.428186</td>\n",
       "      <td>-0.030430</td>\n",
       "      <td>-0.034004</td>\n",
       "      <td>-0.022518</td>\n",
       "      <td>-0.079278</td>\n",
       "      <td>-0.107772</td>\n",
       "      <td>-0.522634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.505623</td>\n",
       "      <td>0.475229</td>\n",
       "      <td>0.573537</td>\n",
       "      <td>-0.648185</td>\n",
       "      <td>0.096514</td>\n",
       "      <td>-0.116067</td>\n",
       "      <td>0.764915</td>\n",
       "      <td>-1.003430</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.212654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054639</td>\n",
       "      <td>-0.026198</td>\n",
       "      <td>-0.014021</td>\n",
       "      <td>0.226206</td>\n",
       "      <td>0.159745</td>\n",
       "      <td>0.228327</td>\n",
       "      <td>0.320978</td>\n",
       "      <td>0.129235</td>\n",
       "      <td>-0.178949</td>\n",
       "      <td>-0.031519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        275       274       273       272       271       270       269  \\\n",
       "0  1.647016 -1.369603  1.098113 -1.091954  0.805062 -0.238003  0.412984   \n",
       "1  0.007751 -0.276317  0.710835 -1.635980  1.104947 -0.850720 -0.498630   \n",
       "2 -1.270629  1.328577  0.852452 -0.637406  0.533876  0.575298  0.819936   \n",
       "3 -1.113251 -1.237431 -2.146102  0.067069 -1.042782  0.869326  0.527872   \n",
       "4 -0.505623  0.475229  0.573537 -0.648185  0.096514 -0.116067  0.764915   \n",
       "\n",
       "        268       267       266  ...       205       204       203       202  \\\n",
       "0  0.143470 -0.013584  1.010599  ... -0.186213 -0.083994 -0.027546  0.158789   \n",
       "1 -0.197108 -0.344759 -0.037286  ... -0.098447 -0.141517 -0.099606  0.010261   \n",
       "2 -0.020077 -0.500380 -0.306400  ... -0.189295 -0.143599 -0.204862 -0.299902   \n",
       "3 -0.962280 -0.385286  0.132282  ... -0.191818 -0.225572  0.295389 -0.428186   \n",
       "4 -1.003430  0.444882  0.212654  ...  0.054639 -0.026198 -0.014021  0.226206   \n",
       "\n",
       "        201       200       199       198       197       196  \n",
       "0 -0.144220  0.426835 -0.173856 -0.016744 -0.479797 -0.297700  \n",
       "1  0.187617  0.030561 -0.211164  0.098304 -0.175605 -0.125958  \n",
       "2 -0.403524  0.187218 -0.676447 -0.122719 -0.398483  0.259492  \n",
       "3 -0.030430 -0.034004 -0.022518 -0.079278 -0.107772 -0.522634  \n",
       "4  0.159745  0.228327  0.320978  0.129235 -0.178949 -0.031519  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_pca_azdias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7a22cd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>c_9</th>\n",
       "      <th>c_10</th>\n",
       "      <th>...</th>\n",
       "      <th>c_71</th>\n",
       "      <th>c_72</th>\n",
       "      <th>c_73</th>\n",
       "      <th>c_74</th>\n",
       "      <th>c_75</th>\n",
       "      <th>c_76</th>\n",
       "      <th>c_77</th>\n",
       "      <th>c_78</th>\n",
       "      <th>c_79</th>\n",
       "      <th>c_80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.647016</td>\n",
       "      <td>-1.369603</td>\n",
       "      <td>1.098113</td>\n",
       "      <td>-1.091954</td>\n",
       "      <td>0.805062</td>\n",
       "      <td>-0.238003</td>\n",
       "      <td>0.412984</td>\n",
       "      <td>0.143470</td>\n",
       "      <td>-0.013584</td>\n",
       "      <td>1.010599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.186213</td>\n",
       "      <td>-0.083994</td>\n",
       "      <td>-0.027546</td>\n",
       "      <td>0.158789</td>\n",
       "      <td>-0.144220</td>\n",
       "      <td>0.426835</td>\n",
       "      <td>-0.173856</td>\n",
       "      <td>-0.016744</td>\n",
       "      <td>-0.479797</td>\n",
       "      <td>-0.297700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007751</td>\n",
       "      <td>-0.276317</td>\n",
       "      <td>0.710835</td>\n",
       "      <td>-1.635980</td>\n",
       "      <td>1.104947</td>\n",
       "      <td>-0.850720</td>\n",
       "      <td>-0.498630</td>\n",
       "      <td>-0.197108</td>\n",
       "      <td>-0.344759</td>\n",
       "      <td>-0.037286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098447</td>\n",
       "      <td>-0.141517</td>\n",
       "      <td>-0.099606</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>0.187617</td>\n",
       "      <td>0.030561</td>\n",
       "      <td>-0.211164</td>\n",
       "      <td>0.098304</td>\n",
       "      <td>-0.175605</td>\n",
       "      <td>-0.125958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.270629</td>\n",
       "      <td>1.328577</td>\n",
       "      <td>0.852452</td>\n",
       "      <td>-0.637406</td>\n",
       "      <td>0.533876</td>\n",
       "      <td>0.575298</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>-0.020077</td>\n",
       "      <td>-0.500380</td>\n",
       "      <td>-0.306400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189295</td>\n",
       "      <td>-0.143599</td>\n",
       "      <td>-0.204862</td>\n",
       "      <td>-0.299902</td>\n",
       "      <td>-0.403524</td>\n",
       "      <td>0.187218</td>\n",
       "      <td>-0.676447</td>\n",
       "      <td>-0.122719</td>\n",
       "      <td>-0.398483</td>\n",
       "      <td>0.259492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.113251</td>\n",
       "      <td>-1.237431</td>\n",
       "      <td>-2.146102</td>\n",
       "      <td>0.067069</td>\n",
       "      <td>-1.042782</td>\n",
       "      <td>0.869326</td>\n",
       "      <td>0.527872</td>\n",
       "      <td>-0.962280</td>\n",
       "      <td>-0.385286</td>\n",
       "      <td>0.132282</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191818</td>\n",
       "      <td>-0.225572</td>\n",
       "      <td>0.295389</td>\n",
       "      <td>-0.428186</td>\n",
       "      <td>-0.030430</td>\n",
       "      <td>-0.034004</td>\n",
       "      <td>-0.022518</td>\n",
       "      <td>-0.079278</td>\n",
       "      <td>-0.107772</td>\n",
       "      <td>-0.522634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.505623</td>\n",
       "      <td>0.475229</td>\n",
       "      <td>0.573537</td>\n",
       "      <td>-0.648185</td>\n",
       "      <td>0.096514</td>\n",
       "      <td>-0.116067</td>\n",
       "      <td>0.764915</td>\n",
       "      <td>-1.003430</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.212654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054639</td>\n",
       "      <td>-0.026198</td>\n",
       "      <td>-0.014021</td>\n",
       "      <td>0.226206</td>\n",
       "      <td>0.159745</td>\n",
       "      <td>0.228327</td>\n",
       "      <td>0.320978</td>\n",
       "      <td>0.129235</td>\n",
       "      <td>-0.178949</td>\n",
       "      <td>-0.031519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        c_1       c_2       c_3       c_4       c_5       c_6       c_7  \\\n",
       "0  1.647016 -1.369603  1.098113 -1.091954  0.805062 -0.238003  0.412984   \n",
       "1  0.007751 -0.276317  0.710835 -1.635980  1.104947 -0.850720 -0.498630   \n",
       "2 -1.270629  1.328577  0.852452 -0.637406  0.533876  0.575298  0.819936   \n",
       "3 -1.113251 -1.237431 -2.146102  0.067069 -1.042782  0.869326  0.527872   \n",
       "4 -0.505623  0.475229  0.573537 -0.648185  0.096514 -0.116067  0.764915   \n",
       "\n",
       "        c_8       c_9      c_10  ...      c_71      c_72      c_73      c_74  \\\n",
       "0  0.143470 -0.013584  1.010599  ... -0.186213 -0.083994 -0.027546  0.158789   \n",
       "1 -0.197108 -0.344759 -0.037286  ... -0.098447 -0.141517 -0.099606  0.010261   \n",
       "2 -0.020077 -0.500380 -0.306400  ... -0.189295 -0.143599 -0.204862 -0.299902   \n",
       "3 -0.962280 -0.385286  0.132282  ... -0.191818 -0.225572  0.295389 -0.428186   \n",
       "4 -1.003430  0.444882  0.212654  ...  0.054639 -0.026198 -0.014021  0.226206   \n",
       "\n",
       "       c_75      c_76      c_77      c_78      c_79      c_80  \n",
       "0 -0.144220  0.426835 -0.173856 -0.016744 -0.479797 -0.297700  \n",
       "1  0.187617  0.030561 -0.211164  0.098304 -0.175605 -0.125958  \n",
       "2 -0.403524  0.187218 -0.676447 -0.122719 -0.398483  0.259492  \n",
       "3 -0.030430 -0.034004 -0.022518 -0.079278 -0.107772 -0.522634  \n",
       "4  0.159745  0.228327  0.320978  0.129235 -0.178949 -0.031519  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = []\n",
    "for i in range(1, n+1):\n",
    "    column_names.append('c_'+str(i)) \n",
    "\n",
    "transformed_pca_azdias.columns = column_names\n",
    "\n",
    "transformed_pca_azdias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "27e5161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785421 entries, 0 to 785420\n",
      "Data columns (total 80 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   c_1     785421 non-null  float64\n",
      " 1   c_2     785421 non-null  float64\n",
      " 2   c_3     785421 non-null  float64\n",
      " 3   c_4     785421 non-null  float64\n",
      " 4   c_5     785421 non-null  float64\n",
      " 5   c_6     785421 non-null  float64\n",
      " 6   c_7     785421 non-null  float64\n",
      " 7   c_8     785421 non-null  float64\n",
      " 8   c_9     785421 non-null  float64\n",
      " 9   c_10    785421 non-null  float64\n",
      " 10  c_11    785421 non-null  float64\n",
      " 11  c_12    785421 non-null  float64\n",
      " 12  c_13    785421 non-null  float64\n",
      " 13  c_14    785421 non-null  float64\n",
      " 14  c_15    785421 non-null  float64\n",
      " 15  c_16    785421 non-null  float64\n",
      " 16  c_17    785421 non-null  float64\n",
      " 17  c_18    785421 non-null  float64\n",
      " 18  c_19    785421 non-null  float64\n",
      " 19  c_20    785421 non-null  float64\n",
      " 20  c_21    785421 non-null  float64\n",
      " 21  c_22    785421 non-null  float64\n",
      " 22  c_23    785421 non-null  float64\n",
      " 23  c_24    785421 non-null  float64\n",
      " 24  c_25    785421 non-null  float64\n",
      " 25  c_26    785421 non-null  float64\n",
      " 26  c_27    785421 non-null  float64\n",
      " 27  c_28    785421 non-null  float64\n",
      " 28  c_29    785421 non-null  float64\n",
      " 29  c_30    785421 non-null  float64\n",
      " 30  c_31    785421 non-null  float64\n",
      " 31  c_32    785421 non-null  float64\n",
      " 32  c_33    785421 non-null  float64\n",
      " 33  c_34    785421 non-null  float64\n",
      " 34  c_35    785421 non-null  float64\n",
      " 35  c_36    785421 non-null  float64\n",
      " 36  c_37    785421 non-null  float64\n",
      " 37  c_38    785421 non-null  float64\n",
      " 38  c_39    785421 non-null  float64\n",
      " 39  c_40    785421 non-null  float64\n",
      " 40  c_41    785421 non-null  float64\n",
      " 41  c_42    785421 non-null  float64\n",
      " 42  c_43    785421 non-null  float64\n",
      " 43  c_44    785421 non-null  float64\n",
      " 44  c_45    785421 non-null  float64\n",
      " 45  c_46    785421 non-null  float64\n",
      " 46  c_47    785421 non-null  float64\n",
      " 47  c_48    785421 non-null  float64\n",
      " 48  c_49    785421 non-null  float64\n",
      " 49  c_50    785421 non-null  float64\n",
      " 50  c_51    785421 non-null  float64\n",
      " 51  c_52    785421 non-null  float64\n",
      " 52  c_53    785421 non-null  float64\n",
      " 53  c_54    785421 non-null  float64\n",
      " 54  c_55    785421 non-null  float64\n",
      " 55  c_56    785421 non-null  float64\n",
      " 56  c_57    785421 non-null  float64\n",
      " 57  c_58    785421 non-null  float64\n",
      " 58  c_59    785421 non-null  float64\n",
      " 59  c_60    785421 non-null  float64\n",
      " 60  c_61    785421 non-null  float64\n",
      " 61  c_62    785421 non-null  float64\n",
      " 62  c_63    785421 non-null  float64\n",
      " 63  c_64    785421 non-null  float64\n",
      " 64  c_65    785421 non-null  float64\n",
      " 65  c_66    785421 non-null  float64\n",
      " 66  c_67    785421 non-null  float64\n",
      " 67  c_68    785421 non-null  float64\n",
      " 68  c_69    785421 non-null  float64\n",
      " 69  c_70    785421 non-null  float64\n",
      " 70  c_71    785421 non-null  float64\n",
      " 71  c_72    785421 non-null  float64\n",
      " 72  c_73    785421 non-null  float64\n",
      " 73  c_74    785421 non-null  float64\n",
      " 74  c_75    785421 non-null  float64\n",
      " 75  c_76    785421 non-null  float64\n",
      " 76  c_77    785421 non-null  float64\n",
      " 77  c_78    785421 non-null  float64\n",
      " 78  c_79    785421 non-null  float64\n",
      " 79  c_80    785421 non-null  float64\n",
      "dtypes: float64(80)\n",
      "memory usage: 479.4 MB\n"
     ]
    }
   ],
   "source": [
    "transformed_pca_azdias.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f197188",
   "metadata": {},
   "source": [
    "2.6 As we will eventually run the same K-Means on the customer data for the comparison. I decided to transform the customer data too to prepare for the K-Means Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dd4cdd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the additional three columns in customers DataFrame, as they do not have correspondents in the population dataframe\n",
    "customers.drop(axis=1, columns = ['CUSTOMER_GROUP', 'ONLINE_PURCHASE', 'PRODUCT_GROUP'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e635cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_processed = data_process(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "54f8fbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_processed.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4b2ee295",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_processed.drop(axis=1, columns = 'LNR', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2076c458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>BALLRAUM</th>\n",
       "      <th>CAMEO_DEUG_2015</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "      <th>CAMEO_INTL_FAM_Wealth</th>\n",
       "      <th>CAMEO_INTL_FAM_COMPOSITION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AKT_DAT_KL  ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  ANZ_KINDER  ANZ_PERSONEN  \\\n",
       "0         0.0             0.001912      0.000000         0.0      0.095238   \n",
       "2         0.0             0.001912      0.000000         0.0      0.047619   \n",
       "3         0.0             0.000000      0.003213         0.0      0.000000   \n",
       "4         0.0             0.013384      0.000000         0.0      0.190476   \n",
       "5         0.0             0.001912      0.000000         0.0      0.095238   \n",
       "\n",
       "   ANZ_STATISTISCHE_HAUSHALTE  ANZ_TITEL  ARBEIT  BALLRAUM  CAMEO_DEUG_2015  \\\n",
       "0                    0.002667        0.0    0.00  0.333333            0.000   \n",
       "2                    0.002667        0.0    0.25  1.000000            0.500   \n",
       "3                    0.002667        0.0    0.00  1.000000            0.375   \n",
       "4                    0.018667        0.0    0.25  0.333333            0.750   \n",
       "5                    0.002667        0.0    0.25  1.000000            0.500   \n",
       "\n",
       "   ...  VK_DHT4A  VK_DISTANZ  VK_ZG11  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  \\\n",
       "0  ...       0.4    0.166667      0.1             1.0     0.875       0.4   \n",
       "2  ...       0.9    1.000000      1.0             1.0     0.250       0.4   \n",
       "3  ...       0.5    0.250000      0.1             1.0     0.875       0.0   \n",
       "4  ...       0.2    0.333333      0.3             1.0     0.375       0.0   \n",
       "5  ...       0.0    0.083333      0.0             1.0     0.125       0.2   \n",
       "\n",
       "   ANREDE_KZ  ALTERSKATEGORIE_GROB  CAMEO_INTL_FAM_Wealth  \\\n",
       "0        0.0                 0.375                   0.00   \n",
       "2        1.0                 0.375                   0.50   \n",
       "3        0.0                 0.375                   0.25   \n",
       "4        0.0                 0.250                   0.75   \n",
       "5        0.0                 0.250                   0.50   \n",
       "\n",
       "   CAMEO_INTL_FAM_COMPOSITION  \n",
       "0                        0.50  \n",
       "2                        0.75  \n",
       "3                        0.75  \n",
       "4                        0.00  \n",
       "5                        0.75  \n",
       "\n",
       "[5 rows x 277 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_2 = MinMaxScaler(feature_range= (0, 1))\n",
    "\n",
    "customers_scaled= pd.DataFrame(scaler_2.fit_transform(customers_processed.astype(float)))\n",
    "customers_scaled.index = customers_processed.index\n",
    "customers_scaled.columns = customers_processed.columns\n",
    "customers_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5c1761b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 140371 entries, 0 to 191651\n",
      "Columns: 277 entries, AKT_DAT_KL to CAMEO_INTL_FAM_COMPOSITION\n",
      "dtypes: float64(277)\n",
      "memory usage: 297.7 MB\n"
     ]
    }
   ],
   "source": [
    "customers_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dec81b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_scaled.to_csv(os.path.join(data_dir, 'customers.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c1cb1eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_location = session.upload_data(os.path.join(data_dir, 'customers.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4700d3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[35mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[35mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] nvidia-smi: took 0.030 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] loading entry points\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] nvidia-smi: took 0.030 seconds to run.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] loading entry points\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] loaded request iterator application/json\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:32 INFO 140289434404672] Number of server workers: 4\u001b[0m\n",
      "\u001b[34m[2021-06-07 05:15:33 +0000] [1] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-06-07 05:15:33 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-06-07 05:15:33 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2021-06-07 05:15:33 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:33 INFO 140289434404672] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:33 INFO 140289434404672] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-07 05:15:33 +0000] [64] [INFO] Booting worker with pid: 64\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:33 INFO 140289434404672] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:33 INFO 140289434404672] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-07 05:15:33 +0000] [77] [INFO] Booting worker with pid: 77\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:33 INFO 140289434404672] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:33 INFO 140289434404672] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-07 05:15:33 +0000] [88] [INFO] Booting worker with pid: 88\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:33 INFO 140289434404672] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:33 INFO 140289434404672] ...model loaded.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] loaded response encoder application/json\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:32 INFO 140289434404672] Number of server workers: 4\u001b[0m\n",
      "\u001b[35m[2021-06-07 05:15:33 +0000] [1] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2021-06-07 05:15:33 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2021-06-07 05:15:33 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2021-06-07 05:15:33 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:33 INFO 140289434404672] loading model...\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:33 INFO 140289434404672] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2021-06-07 05:15:33 +0000] [64] [INFO] Booting worker with pid: 64\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:33 INFO 140289434404672] loading model...\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:33 INFO 140289434404672] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2021-06-07 05:15:33 +0000] [77] [INFO] Booting worker with pid: 77\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:33 INFO 140289434404672] loading model...\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:33 INFO 140289434404672] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2021-06-07 05:15:33 +0000] [88] [INFO] Booting worker with pid: 88\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:33 INFO 140289434404672] loading model...\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:33 INFO 140289434404672] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042933.0630753, \"EndTime\": 1623042934.815933, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042933.0630753, \"EndTime\": 1623042934.815933, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:36 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:36 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:36 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:36 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:36 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:36 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:36 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3094.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:36 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3094.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:36 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:36 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:36 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:36 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3087.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:36 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:36 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:36 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:36 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3096.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:37 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:36 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:36 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:36 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:36 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3087.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:36 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:36 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:36 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:36 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3096.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:37 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:37 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:37 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:37 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3084.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:37 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:37 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:37 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3084.\u001b[0m\n",
      "\u001b[32m2021-06-07T05:15:34.823:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042934.8160646, \"EndTime\": 1623042938.805725, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042934.8160646, \"EndTime\": 1623042938.805725, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042933.049088, \"EndTime\": 1623042938.842513, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042933.1444337, \"EndTime\": 1623042938.8690932, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042933.2117505, \"EndTime\": 1623042938.9094827, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042933.049088, \"EndTime\": 1623042938.842513, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042933.1444337, \"EndTime\": 1623042938.8690932, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042933.2117505, \"EndTime\": 1623042938.9094827, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3092.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3091.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3092.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:39 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3096.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3092.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3091.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3092.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:39 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3096.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042938.8430722, \"EndTime\": 1623042941.2449105, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042938.8058207, \"EndTime\": 1623042941.273713, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042938.869253, \"EndTime\": 1623042941.3643897, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042938.9096313, \"EndTime\": 1623042941.3952982, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042938.8430722, \"EndTime\": 1623042941.2449105, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042938.8058207, \"EndTime\": 1623042941.273713, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042938.869253, \"EndTime\": 1623042941.3643897, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042938.9096313, \"EndTime\": 1623042941.3952982, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:41 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:41 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:41 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:41 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3093.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:41 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:41 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:41 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:41 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3093.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:42 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:42 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:42 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:42 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3088.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:42 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:42 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:42 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:42 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3093.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:42 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:42 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:42 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:42 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3088.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:42 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:42 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:42 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:42 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3093.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042941.273804, \"EndTime\": 1623042943.7747304, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042941.2450056, \"EndTime\": 1623042943.843233, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042941.273804, \"EndTime\": 1623042943.7747304, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042941.2450056, \"EndTime\": 1623042943.843233, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042941.3953743, \"EndTime\": 1623042943.972041, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042941.3644655, \"EndTime\": 1623042944.0664861, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3083.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3090.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3092.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:44 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3090.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042941.3953743, \"EndTime\": 1623042943.972041, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042941.3644655, \"EndTime\": 1623042944.0664861, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3083.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3090.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3092.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:44 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3090.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042943.8433259, \"EndTime\": 1623042946.223928, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042944.0670538, \"EndTime\": 1623042946.449179, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042943.7749174, \"EndTime\": 1623042946.5911672, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042943.9721918, \"EndTime\": 1623042946.6750855, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042943.8433259, \"EndTime\": 1623042946.223928, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042944.0670538, \"EndTime\": 1623042946.449179, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042943.7749174, \"EndTime\": 1623042946.5911672, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042943.9721918, \"EndTime\": 1623042946.6750855, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3086.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3090.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3093.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:47 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3087.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3086.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3090.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3093.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:47 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3087.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042946.2240248, \"EndTime\": 1623042948.894358, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042946.6751754, \"EndTime\": 1623042949.0194933, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042946.4492817, \"EndTime\": 1623042949.1021292, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042946.5912585, \"EndTime\": 1623042949.347563, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:49 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:49 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:49 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:49 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3090.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:49 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:49 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:49 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:49 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3092.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042946.2240248, \"EndTime\": 1623042948.894358, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042946.6751754, \"EndTime\": 1623042949.0194933, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042946.4492817, \"EndTime\": 1623042949.1021292, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042946.5912585, \"EndTime\": 1623042949.347563, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:49 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:49 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:49 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:49 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3090.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:49 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:49 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:49 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:49 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3092.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:49 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:49 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:49 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:49 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3098.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:50 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:50 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:50 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:50 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3093.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:49 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:49 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:49 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:49 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3098.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:50 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:50 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:50 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:50 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3093.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042949.020071, \"EndTime\": 1623042951.518068, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042949.3476663, \"EndTime\": 1623042951.6804652, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042949.020071, \"EndTime\": 1623042951.518068, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042949.3476663, \"EndTime\": 1623042951.6804652, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042948.8944502, \"EndTime\": 1623042951.7603846, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042948.8944502, \"EndTime\": 1623042951.7603846, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3091.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3088.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3092.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3091.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3088.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3092.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:52 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3095.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:52 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3095.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042951.5186396, \"EndTime\": 1623042954.0740402, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042951.760477, \"EndTime\": 1623042954.2224474, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042951.9960263, \"EndTime\": 1623042954.3209512, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042951.6805608, \"EndTime\": 1623042954.4775584, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042951.5186396, \"EndTime\": 1623042954.0740402, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042951.760477, \"EndTime\": 1623042954.2224474, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042951.9960263, \"EndTime\": 1623042954.3209512, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042951.6805608, \"EndTime\": 1623042954.4775584, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:54 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:54 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:54 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:54 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3095.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:55 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:55 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:55 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:55 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3081.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:55 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:55 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:55 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:55 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3082.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:55 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:55 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:55 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:55 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3095.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:54 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:54 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:54 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:54 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3095.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:55 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:55 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:55 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:55 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3081.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:55 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:55 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:55 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:55 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3082.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:55 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:55 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:55 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:55 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3095.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042954.3210468, \"EndTime\": 1623042956.8357387, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042954.3210468, \"EndTime\": 1623042956.8357387, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042954.2225416, \"EndTime\": 1623042956.905804, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042954.4776688, \"EndTime\": 1623042957.1755302, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042954.0745342, \"EndTime\": 1623042957.191846, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3093.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3087.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3082.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042954.2225416, \"EndTime\": 1623042956.905804, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042954.4776688, \"EndTime\": 1623042957.1755302, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042954.0745342, \"EndTime\": 1623042957.191846, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3093.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3087.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3082.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:57 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3098.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:57 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3098.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042956.9058995, \"EndTime\": 1623042959.3418887, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042956.8359454, \"EndTime\": 1623042959.519501, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042957.191932, \"EndTime\": 1623042959.798318, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042956.9058995, \"EndTime\": 1623042959.3418887, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042956.8359454, \"EndTime\": 1623042959.519501, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042957.191932, \"EndTime\": 1623042959.798318, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:59 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:59 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:59 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:15:59 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3084.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042957.1760375, \"EndTime\": 1623042959.9235733, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:00 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:00 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:00 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:00 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3087.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:00 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:00 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:00 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:00 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3092.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:00 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:00 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:00 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:00 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3093.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:59 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:59 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:59 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:15:59 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3084.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042957.1760375, \"EndTime\": 1623042959.9235733, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:00 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:00 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:00 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:00 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3087.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:00 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:00 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:00 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:00 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3092.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:00 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:00 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:00 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:00 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3093.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042959.341978, \"EndTime\": 1623042961.7518277, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042959.341978, \"EndTime\": 1623042961.7518277, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042959.7984114, \"EndTime\": 1623042962.2366805, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042959.9237063, \"EndTime\": 1623042962.45925, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:02 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:02 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:02 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:02 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3087.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:02 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:02 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:02 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:02 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3087.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042959.7984114, \"EndTime\": 1623042962.2366805, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042959.9237063, \"EndTime\": 1623042962.45925, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:02 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:02 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:02 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:02 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3087.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:02 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:02 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:02 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:02 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3087.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:02 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:02 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:02 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:02 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3098.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:03 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:03 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:03 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:03 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3094.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:02 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:02 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:02 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:02 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3098.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:03 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:03 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:03 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:03 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3094.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042961.7519305, \"EndTime\": 1623042964.47651, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042961.7519305, \"EndTime\": 1623042964.47651, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042962.141285, \"EndTime\": 1623042964.5865293, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042962.4593413, \"EndTime\": 1623042964.742696, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042962.141285, \"EndTime\": 1623042964.5865293, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042962.4593413, \"EndTime\": 1623042964.742696, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:04 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:04 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:04 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:04 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1250.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042962.2372434, \"EndTime\": 1623042964.9839995, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:05 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:05 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:05 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/07/2021 05:16:05 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3090.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042964.4770532, \"EndTime\": 1623042965.579973, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:04 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:04 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:04 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:04 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1250.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042962.2372434, \"EndTime\": 1623042964.9839995, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:05 WARNING 140289434404672] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:05 INFO 140289434404672] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:05 INFO 140289434404672] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/07/2021 05:16:05 INFO 140289434404672] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 3090.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042964.4770532, \"EndTime\": 1623042965.579973, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623042964.5866196, \"EndTime\": 1623042966.398008, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623042964.5866196, \"EndTime\": 1623042966.398008, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca_transformer.transform(customers_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5de0ff40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-1-178050996200/pca-2021-06-07-05-10-53-190/customers.csv.out to ../data/customers.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $pca_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "12bbe61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_customers = pd.read_csv(os.path.join(data_dir, 'customers.csv.out'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "527db78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_out(pca_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "41ba85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 80 \n",
    "transformed_pca_customers = create_transformed_df(pca_customers, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4f4e30fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>c_9</th>\n",
       "      <th>c_10</th>\n",
       "      <th>...</th>\n",
       "      <th>c_71</th>\n",
       "      <th>c_72</th>\n",
       "      <th>c_73</th>\n",
       "      <th>c_74</th>\n",
       "      <th>c_75</th>\n",
       "      <th>c_76</th>\n",
       "      <th>c_77</th>\n",
       "      <th>c_78</th>\n",
       "      <th>c_79</th>\n",
       "      <th>c_80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.252123</td>\n",
       "      <td>1.753698</td>\n",
       "      <td>0.103065</td>\n",
       "      <td>-1.090806</td>\n",
       "      <td>-1.064244</td>\n",
       "      <td>0.632722</td>\n",
       "      <td>-0.057567</td>\n",
       "      <td>0.160269</td>\n",
       "      <td>-0.214497</td>\n",
       "      <td>0.117398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325230</td>\n",
       "      <td>-0.018300</td>\n",
       "      <td>-0.374028</td>\n",
       "      <td>-0.132821</td>\n",
       "      <td>0.324162</td>\n",
       "      <td>0.532375</td>\n",
       "      <td>-0.025256</td>\n",
       "      <td>-0.047940</td>\n",
       "      <td>0.020278</td>\n",
       "      <td>0.080819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.513018</td>\n",
       "      <td>2.112345</td>\n",
       "      <td>-1.026261</td>\n",
       "      <td>-0.264072</td>\n",
       "      <td>0.612925</td>\n",
       "      <td>1.245031</td>\n",
       "      <td>-0.092872</td>\n",
       "      <td>0.297801</td>\n",
       "      <td>-1.008559</td>\n",
       "      <td>-0.562731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261533</td>\n",
       "      <td>-0.246735</td>\n",
       "      <td>0.454559</td>\n",
       "      <td>-0.164980</td>\n",
       "      <td>-0.288754</td>\n",
       "      <td>0.086745</td>\n",
       "      <td>-0.026099</td>\n",
       "      <td>0.085968</td>\n",
       "      <td>-0.013625</td>\n",
       "      <td>0.107346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.654017</td>\n",
       "      <td>1.695449</td>\n",
       "      <td>0.534332</td>\n",
       "      <td>0.014496</td>\n",
       "      <td>-1.015586</td>\n",
       "      <td>-0.519252</td>\n",
       "      <td>1.286682</td>\n",
       "      <td>-0.367541</td>\n",
       "      <td>-0.005661</td>\n",
       "      <td>-0.568220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180873</td>\n",
       "      <td>-0.118214</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>0.168075</td>\n",
       "      <td>0.073534</td>\n",
       "      <td>0.160634</td>\n",
       "      <td>-0.164807</td>\n",
       "      <td>-0.394947</td>\n",
       "      <td>0.088519</td>\n",
       "      <td>0.071462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.745471</td>\n",
       "      <td>-1.496050</td>\n",
       "      <td>-1.596949</td>\n",
       "      <td>0.785237</td>\n",
       "      <td>-0.598720</td>\n",
       "      <td>1.134042</td>\n",
       "      <td>-0.452675</td>\n",
       "      <td>-0.631220</td>\n",
       "      <td>0.319046</td>\n",
       "      <td>0.595553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164907</td>\n",
       "      <td>-0.054612</td>\n",
       "      <td>-0.742969</td>\n",
       "      <td>-0.476534</td>\n",
       "      <td>0.353693</td>\n",
       "      <td>0.105524</td>\n",
       "      <td>-0.123342</td>\n",
       "      <td>-0.569170</td>\n",
       "      <td>0.389028</td>\n",
       "      <td>-0.307141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.194546</td>\n",
       "      <td>1.270095</td>\n",
       "      <td>-1.568836</td>\n",
       "      <td>-1.421759</td>\n",
       "      <td>-0.930147</td>\n",
       "      <td>-0.161934</td>\n",
       "      <td>0.206986</td>\n",
       "      <td>0.054010</td>\n",
       "      <td>-0.552936</td>\n",
       "      <td>-0.011217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315226</td>\n",
       "      <td>0.166110</td>\n",
       "      <td>0.384029</td>\n",
       "      <td>0.091580</td>\n",
       "      <td>0.098449</td>\n",
       "      <td>-0.146680</td>\n",
       "      <td>0.289756</td>\n",
       "      <td>-0.714226</td>\n",
       "      <td>-0.063649</td>\n",
       "      <td>-0.075566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        c_1       c_2       c_3       c_4       c_5       c_6       c_7  \\\n",
       "0 -2.252123  1.753698  0.103065 -1.090806 -1.064244  0.632722 -0.057567   \n",
       "1  0.513018  2.112345 -1.026261 -0.264072  0.612925  1.245031 -0.092872   \n",
       "2 -1.654017  1.695449  0.534332  0.014496 -1.015586 -0.519252  1.286682   \n",
       "3 -0.745471 -1.496050 -1.596949  0.785237 -0.598720  1.134042 -0.452675   \n",
       "4 -1.194546  1.270095 -1.568836 -1.421759 -0.930147 -0.161934  0.206986   \n",
       "\n",
       "        c_8       c_9      c_10  ...      c_71      c_72      c_73      c_74  \\\n",
       "0  0.160269 -0.214497  0.117398  ...  0.325230 -0.018300 -0.374028 -0.132821   \n",
       "1  0.297801 -1.008559 -0.562731  ... -0.261533 -0.246735  0.454559 -0.164980   \n",
       "2 -0.367541 -0.005661 -0.568220  ... -0.180873 -0.118214 -0.071836  0.168075   \n",
       "3 -0.631220  0.319046  0.595553  ... -0.164907 -0.054612 -0.742969 -0.476534   \n",
       "4  0.054010 -0.552936 -0.011217  ...  0.315226  0.166110  0.384029  0.091580   \n",
       "\n",
       "       c_75      c_76      c_77      c_78      c_79      c_80  \n",
       "0  0.324162  0.532375 -0.025256 -0.047940  0.020278  0.080819  \n",
       "1 -0.288754  0.086745 -0.026099  0.085968 -0.013625  0.107346  \n",
       "2  0.073534  0.160634 -0.164807 -0.394947  0.088519  0.071462  \n",
       "3  0.353693  0.105524 -0.123342 -0.569170  0.389028 -0.307141  \n",
       "4  0.098449 -0.146680  0.289756 -0.714226 -0.063649 -0.075566  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = []\n",
    "for i in range(1, n+1):\n",
    "    column_names.append('c_'+str(i)) \n",
    "\n",
    "transformed_pca_customers.columns = column_names\n",
    "\n",
    "transformed_pca_customers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27400e6",
   "metadata": {},
   "source": [
    "## K-Means "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40992f46",
   "metadata": {},
   "source": [
    "3.1 I used within-cluster sum-of-squares, i.e. inertia, as a metric to find the best number of clusters. I chose 8 as the number of clusters, as beyond 8, the decrease of inertia slows down significantly. Here I trained the whole population data on the K-Means model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "944ff647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4d805cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_num = 8\n",
    "kmeans = KMeans(role=role,\n",
    "                instance_count=1,\n",
    "                instance_type='ml.m5.2xlarge',\n",
    "                output_path=output_path, \n",
    "                k=cluster_num,\n",
    "                sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f311822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_np = transformed_pca_azdias.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a74057a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_azdias = kmeans.record_set(azdias_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cf51d4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-07 22:56:28 Starting - Starting the training job...\n",
      "2021-06-07 22:56:34 Starting - Launching requested ML instancesProfilerReport-1623106588: InProgress\n",
      ".........\n",
      "2021-06-07 22:58:00 Starting - Preparing the instances for training...\n",
      "2021-06-07 22:58:58 Downloading - Downloading input data...\n",
      "2021-06-07 22:59:26 Training - Training image download completed. Training in progress.\n",
      "2021-06-07 22:59:26 Uploading - Uploading generated training model.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'init_method': 'random', 'mini_batch_size': '5000', 'epochs': '1', 'extra_center_factor': 'auto', 'local_lloyd_max_iter': '300', 'local_lloyd_tol': '0.0001', 'local_lloyd_init_method': 'kmeans++', 'local_lloyd_num_trials': 'auto', 'half_life_time_size': '0', 'eval_metrics': '[\"msd\"]', 'force_dense': 'true', '_disable_wait_to_read': 'false', '_enable_profiler': 'false', '_kvstore': 'auto', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': '1', '_num_slices': '1', '_tuning_objective_metric': ''}\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'feature_dim': '80', 'k': '8', 'force_dense': 'True'}\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] Final configuration: {'init_method': 'random', 'mini_batch_size': '5000', 'epochs': '1', 'extra_center_factor': 'auto', 'local_lloyd_max_iter': '300', 'local_lloyd_tol': '0.0001', 'local_lloyd_init_method': 'kmeans++', 'local_lloyd_num_trials': 'auto', 'half_life_time_size': '0', 'eval_metrics': '[\"msd\"]', 'force_dense': 'True', '_disable_wait_to_read': 'false', '_enable_profiler': 'false', '_kvstore': 'auto', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': '1', '_num_slices': '1', '_tuning_objective_metric': '', 'feature_dim': '80', 'k': '8'}\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 WARNING 140127454623552] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] Using default worker.\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] Create Store: local\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] nvidia-smi: took 0.030 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] Setting up with params: {'init_method': 'random', 'mini_batch_size': '5000', 'epochs': '1', 'extra_center_factor': 'auto', 'local_lloyd_max_iter': '300', 'local_lloyd_tol': '0.0001', 'local_lloyd_init_method': 'kmeans++', 'local_lloyd_num_trials': 'auto', 'half_life_time_size': '0', 'eval_metrics': '[\"msd\"]', 'force_dense': 'True', '_disable_wait_to_read': 'false', '_enable_profiler': 'false', '_kvstore': 'auto', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': '1', '_num_slices': '1', '_tuning_objective_metric': '', 'feature_dim': '80', 'k': '8'}\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] number of center slices 1\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623106763.3736305, \"EndTime\": 1623106763.3736775, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5000.0, \"count\": 1, \"min\": 5000, \"max\": 5000}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 5000.0, \"count\": 1, \"min\": 5000, \"max\": 5000}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 5000.0, \"count\": 1, \"min\": 5000, \"max\": 5000}, \"Number of Batches Since Last Reset\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[2021-06-07 22:59:23.379] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 39, \"num_examples\": 1, \"num_bytes\": 1740000}\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] Iter 10: Short term msd 11.538974. Long term msd 12.105799\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] Iter 20: Short term msd 11.090379. Long term msd 11.315213\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] Iter 30: Short term msd 10.967139. Long term msd 11.069491\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] Iter 40: Short term msd 10.991948. Long term msd 11.015027\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:23 INFO 140127454623552] Iter 50: Short term msd 10.936822. Long term msd 10.964250\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] Iter 60: Short term msd 10.958074. Long term msd 10.960833\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] Iter 70: Short term msd 10.973631. Long term msd 10.970254\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] Iter 80: Short term msd 10.962814. Long term msd 10.966182\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] Iter 90: Short term msd 10.915947. Long term msd 10.930474\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] Iter 100: Short term msd 10.936150. Long term msd 10.936990\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] Iter 110: Short term msd 10.933794. Long term msd 10.935447\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] Iter 120: Short term msd 10.923423. Long term msd 10.926952\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] Iter 130: Short term msd 10.944639. Long term msd 10.941526\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] Iter 140: Short term msd 10.951862. Long term msd 10.950678\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] Iter 150: Short term msd 10.896532. Long term msd 10.919743\u001b[0m\n",
      "\u001b[34m[2021-06-07 22:59:24.863] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 1484, \"num_examples\": 158, \"num_bytes\": 273326508}\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] processed a total of 785421 examples\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623106763.3796113, \"EndTime\": 1623106764.8643546, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 790421.0, \"count\": 1, \"min\": 790421, \"max\": 790421}, \"Total Batches Seen\": {\"sum\": 159.0, \"count\": 1, \"min\": 159, \"max\": 159}, \"Max Records Seen Between Resets\": {\"sum\": 785421.0, \"count\": 1, \"min\": 785421, \"max\": 785421}, \"Max Batches Seen Between Resets\": {\"sum\": 158.0, \"count\": 1, \"min\": 158, \"max\": 158}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 785421.0, \"count\": 1, \"min\": 785421, \"max\": 785421}, \"Number of Batches Since Last Reset\": {\"sum\": 158.0, \"count\": 1, \"min\": 158, \"max\": 158}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] #throughput_metric: host=algo-1, train throughput=528952.5783545746 records/second\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 WARNING 140127454623552] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] shrinking 80 centers into 8\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] local kmeans attempt #0. Current mean square distance 2.929890\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] local kmeans attempt #1. Current mean square distance 3.210203\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] local kmeans attempt #2. Current mean square distance 2.980769\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] local kmeans attempt #3. Current mean square distance 2.898358\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:24 INFO 140127454623552] local kmeans attempt #4. Current mean square distance 2.888959\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] local kmeans attempt #5. Current mean square distance 3.059114\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] local kmeans attempt #6. Current mean square distance 3.079774\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] local kmeans attempt #7. Current mean square distance 2.889296\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] local kmeans attempt #8. Current mean square distance 2.916740\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] local kmeans attempt #9. Current mean square distance 2.966819\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] finished shrinking process. Mean Square Distance = 3\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] #quality_metric: host=algo-1, train msd <loss>=2.8889594078063965\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] predict compute msd took: 24.3315%, (0.361484 secs)\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] compute all data-center distances: inner product took: 19.1638%, (0.284709 secs)\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] compute all data-center distances: point norm took: 15.6642%, (0.232717 secs)\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] gradient: cluster size  took: 14.7199%, (0.218688 secs)\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] gradient: cluster center took: 7.3447%, (0.109118 secs)\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] batch data loading with context took: 4.8125%, (0.071498 secs)\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] update state and report convergance took: 4.3140%, (0.064091 secs)\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] collect from kv store took: 3.1875%, (0.047355 secs)\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] gradient: one_hot took: 2.4978%, (0.037109 secs)\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] splitting centers key-value pair took: 2.3186%, (0.034447 secs)\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] compute all data-center distances: center norm took: 1.4667%, (0.021790 secs)\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] predict minus dist took: 0.1653%, (0.002456 secs)\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] update set-up time took: 0.0133%, (0.000198 secs)\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] TOTAL took: 1.4856605529785156\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623106763.3399036, \"EndTime\": 1623106765.1137595, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 25.61664581298828, \"count\": 1, \"min\": 25.61664581298828, \"max\": 25.61664581298828}, \"epochs\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"update.time\": {\"sum\": 1484.5890998840332, \"count\": 1, \"min\": 1484.5890998840332, \"max\": 1484.5890998840332}, \"_shrink.time\": {\"sum\": 245.59259414672852, \"count\": 1, \"min\": 245.59259414672852, \"max\": 245.59259414672852}, \"finalize.time\": {\"sum\": 246.66547775268555, \"count\": 1, \"min\": 246.66547775268555, \"max\": 246.66547775268555}, \"model.serialize.time\": {\"sum\": 2.471446990966797, \"count\": 1, \"min\": 2.471446990966797, \"max\": 2.471446990966797}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/07/2021 22:59:25 INFO 140127454623552] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623106765.1138465, \"EndTime\": 1623106765.1237588, \"Dimensions\": {\"Algorithm\": \"AWS/KMeansWebscale\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 12.440681457519531, \"count\": 1, \"min\": 12.440681457519531, \"max\": 12.440681457519531}, \"totaltime\": {\"sum\": 1847.538709640503, \"count\": 1, \"min\": 1847.538709640503, \"max\": 1847.538709640503}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-06-07 22:59:58 Completed - Training job completed\n",
      "Training seconds: 39\n",
      "Billable seconds: 39\n"
     ]
    }
   ],
   "source": [
    "kmeans.fit(formatted_azdias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b00e901",
   "metadata": {},
   "source": [
    "3.2 Create a transformer based on the trained K-Means model. Batch transform both population data and customers data for comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bc2f9b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    }
   ],
   "source": [
    "kmeans_transformer = kmeans.transformer(instance_count = 1, instance_type = 'ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ceeb00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_pca_customers.to_csv(os.path.join(data_dir, 'pca_customers.csv'), header=False, index=False)\n",
    "transformed_pca_azdias.to_csv(os.path.join(data_dir, 'pca_azdias.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "576ed9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_azdias_location = session.upload_data(os.path.join(data_dir, 'pca_azdias.csv'), key_prefix=prefix)\n",
    "pca_customers_location = session.upload_data(os.path.join(data_dir, 'pca_customers.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8995605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] loading entry points\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] Number of server workers: 4\u001b[0m\n",
      "\u001b[34m[2021-06-07 23:35:47 +0000] [1] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-06-07 23:35:47 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-06-07 23:35:47 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2021-06-07 23:35:47 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 WARNING 139859105855296] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] nvidia-smi: took 0.035 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-07 23:35:47 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 WARNING 139859105855296] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] nvidia-smi: took 0.034 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-07 23:35:47 +0000] [84] [INFO] Booting worker with pid: 84\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 WARNING 139859105855296] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] nvidia-smi: took 0.030 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-07 23:35:47 +0000] [105] [INFO] Booting worker with pid: 105\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 WARNING 139859105855296] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] nvidia-smi: took 0.033 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:35:47 INFO 139859105855296] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108947.9778414, \"EndTime\": 1623108949.5207694, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108947.8391438, \"EndTime\": 1623108951.6955128, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02956390380859375, \"count\": 1, \"min\": 0.02956390380859375, \"max\": 0.02956390380859375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108949.5208669, \"EndTime\": 1623108951.7279713, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.04124641418457031, \"count\": 1, \"min\": 0.04124641418457031, \"max\": 0.04124641418457031}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108947.9209235, \"EndTime\": 1623108951.7879653, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.026226043701171875, \"count\": 1, \"min\": 0.026226043701171875, \"max\": 0.026226043701171875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108947.8846633, \"EndTime\": 1623108951.938768, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02956390380859375, \"count\": 1, \"min\": 0.02956390380859375, \"max\": 0.02956390380859375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108951.7280478, \"EndTime\": 1623108952.1808493, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02193450927734375, \"count\": 1, \"min\": 0.02193450927734375, \"max\": 0.02193450927734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108951.6957784, \"EndTime\": 1623108952.3179033, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108951.7881105, \"EndTime\": 1623108952.3334594, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024557113647460938, \"count\": 1, \"min\": 0.024557113647460938, \"max\": 0.024557113647460938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108951.938911, \"EndTime\": 1623108952.3909504, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108952.3179927, \"EndTime\": 1623108952.6304674, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108952.39107, \"EndTime\": 1623108952.7065625, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024318695068359375, \"count\": 1, \"min\": 0.024318695068359375, \"max\": 0.024318695068359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108952.1809425, \"EndTime\": 1623108952.836898, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02288818359375, \"count\": 1, \"min\": 0.02288818359375, \"max\": 0.02288818359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108952.333641, \"EndTime\": 1623108952.9961112, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024318695068359375, \"count\": 1, \"min\": 0.024318695068359375, \"max\": 0.024318695068359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108952.7066472, \"EndTime\": 1623108953.0906646, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.018358230590820312, \"count\": 1, \"min\": 0.018358230590820312, \"max\": 0.018358230590820312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108952.6305597, \"EndTime\": 1623108953.2866056, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108952.836983, \"EndTime\": 1623108953.3763564, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108952.996514, \"EndTime\": 1623108953.4536366, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108953.0907617, \"EndTime\": 1623108953.5560338, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108953.2869892, \"EndTime\": 1623108953.7871103, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108953.3767722, \"EndTime\": 1623108953.7959538, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.01811981201171875, \"count\": 1, \"min\": 0.01811981201171875, \"max\": 0.01811981201171875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108953.454043, \"EndTime\": 1623108953.9001021, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.026226043701171875, \"count\": 1, \"min\": 0.026226043701171875, \"max\": 0.026226043701171875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108952.333641, \"EndTime\": 1623108952.9961112, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024318695068359375, \"count\": 1, \"min\": 0.024318695068359375, \"max\": 0.024318695068359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108952.7066472, \"EndTime\": 1623108953.0906646, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.018358230590820312, \"count\": 1, \"min\": 0.018358230590820312, \"max\": 0.018358230590820312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108952.6305597, \"EndTime\": 1623108953.2866056, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108952.836983, \"EndTime\": 1623108953.3763564, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108952.996514, \"EndTime\": 1623108953.4536366, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108953.0907617, \"EndTime\": 1623108953.5560338, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108953.2869892, \"EndTime\": 1623108953.7871103, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108953.3767722, \"EndTime\": 1623108953.7959538, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.01811981201171875, \"count\": 1, \"min\": 0.01811981201171875, \"max\": 0.01811981201171875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108953.454043, \"EndTime\": 1623108953.9001021, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.026226043701171875, \"count\": 1, \"min\": 0.026226043701171875, \"max\": 0.026226043701171875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[32m2021-06-07T23:35:49.526:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108953.5561237, \"EndTime\": 1623108954.0857024, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023365020751953125, \"count\": 1, \"min\": 0.023365020751953125, \"max\": 0.023365020751953125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108953.796056, \"EndTime\": 1623108954.207595, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108953.7871952, \"EndTime\": 1623108954.2862113, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019788742065429688, \"count\": 1, \"min\": 0.019788742065429688, \"max\": 0.019788742065429688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108953.9001944, \"EndTime\": 1623108954.3674362, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108954.0861492, \"EndTime\": 1623108954.4602149, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108954.2862823, \"EndTime\": 1623108954.6355782, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108954.3679104, \"EndTime\": 1623108954.7776942, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108954.2076771, \"EndTime\": 1623108954.8009496, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108953.5561237, \"EndTime\": 1623108954.0857024, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023365020751953125, \"count\": 1, \"min\": 0.023365020751953125, \"max\": 0.023365020751953125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108953.796056, \"EndTime\": 1623108954.207595, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108953.7871952, \"EndTime\": 1623108954.2862113, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019788742065429688, \"count\": 1, \"min\": 0.019788742065429688, \"max\": 0.019788742065429688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108953.9001944, \"EndTime\": 1623108954.3674362, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108954.0861492, \"EndTime\": 1623108954.4602149, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108954.2862823, \"EndTime\": 1623108954.6355782, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108954.3679104, \"EndTime\": 1623108954.7776942, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108954.2076771, \"EndTime\": 1623108954.8009496, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108954.6356657, \"EndTime\": 1623108955.0070922, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108954.4602957, \"EndTime\": 1623108955.0194952, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.026941299438476562, \"count\": 1, \"min\": 0.026941299438476562, \"max\": 0.026941299438476562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108954.8010364, \"EndTime\": 1623108955.2482173, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0553131103515625, \"count\": 1, \"min\": 0.0553131103515625, \"max\": 0.0553131103515625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108954.7777803, \"EndTime\": 1623108955.2562635, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108955.0195816, \"EndTime\": 1623108955.467638, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108955.2563477, \"EndTime\": 1623108955.6143997, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108955.0071921, \"EndTime\": 1623108955.7049005, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.026941299438476562, \"count\": 1, \"min\": 0.026941299438476562, \"max\": 0.026941299438476562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108955.248307, \"EndTime\": 1623108955.7224264, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02288818359375, \"count\": 1, \"min\": 0.02288818359375, \"max\": 0.02288818359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108955.4677277, \"EndTime\": 1623108955.87349, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023365020751953125, \"count\": 1, \"min\": 0.023365020751953125, \"max\": 0.023365020751953125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108954.6356657, \"EndTime\": 1623108955.0070922, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108954.4602957, \"EndTime\": 1623108955.0194952, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.026941299438476562, \"count\": 1, \"min\": 0.026941299438476562, \"max\": 0.026941299438476562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108954.8010364, \"EndTime\": 1623108955.2482173, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0553131103515625, \"count\": 1, \"min\": 0.0553131103515625, \"max\": 0.0553131103515625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108954.7777803, \"EndTime\": 1623108955.2562635, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108955.0195816, \"EndTime\": 1623108955.467638, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108955.2563477, \"EndTime\": 1623108955.6143997, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108955.0071921, \"EndTime\": 1623108955.7049005, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.026941299438476562, \"count\": 1, \"min\": 0.026941299438476562, \"max\": 0.026941299438476562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108955.248307, \"EndTime\": 1623108955.7224264, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02288818359375, \"count\": 1, \"min\": 0.02288818359375, \"max\": 0.02288818359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108955.4677277, \"EndTime\": 1623108955.87349, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023365020751953125, \"count\": 1, \"min\": 0.023365020751953125, \"max\": 0.023365020751953125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108955.7049859, \"EndTime\": 1623108956.038804, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024318695068359375, \"count\": 1, \"min\": 0.024318695068359375, \"max\": 0.024318695068359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108955.6144867, \"EndTime\": 1623108956.180059, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02384185791015625, \"count\": 1, \"min\": 0.02384185791015625, \"max\": 0.02384185791015625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108955.7228236, \"EndTime\": 1623108956.214301, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.05435943603515625, \"count\": 1, \"min\": 0.05435943603515625, \"max\": 0.05435943603515625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108955.8735874, \"EndTime\": 1623108956.3148463, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0247955322265625, \"count\": 1, \"min\": 0.0247955322265625, \"max\": 0.0247955322265625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108956.0388923, \"EndTime\": 1623108956.4161954, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.025987625122070312, \"count\": 1, \"min\": 0.025987625122070312, \"max\": 0.025987625122070312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108956.1801445, \"EndTime\": 1623108956.7221768, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019311904907226562, \"count\": 1, \"min\": 0.019311904907226562, \"max\": 0.019311904907226562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108956.2151823, \"EndTime\": 1623108956.7348096, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023365020751953125, \"count\": 1, \"min\": 0.023365020751953125, \"max\": 0.023365020751953125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108956.4162853, \"EndTime\": 1623108956.837912, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108956.3149433, \"EndTime\": 1623108956.8749049, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108955.7049859, \"EndTime\": 1623108956.038804, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024318695068359375, \"count\": 1, \"min\": 0.024318695068359375, \"max\": 0.024318695068359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108955.6144867, \"EndTime\": 1623108956.180059, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02384185791015625, \"count\": 1, \"min\": 0.02384185791015625, \"max\": 0.02384185791015625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108955.7228236, \"EndTime\": 1623108956.214301, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.05435943603515625, \"count\": 1, \"min\": 0.05435943603515625, \"max\": 0.05435943603515625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108955.8735874, \"EndTime\": 1623108956.3148463, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0247955322265625, \"count\": 1, \"min\": 0.0247955322265625, \"max\": 0.0247955322265625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108956.0388923, \"EndTime\": 1623108956.4161954, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.025987625122070312, \"count\": 1, \"min\": 0.025987625122070312, \"max\": 0.025987625122070312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108956.1801445, \"EndTime\": 1623108956.7221768, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019311904907226562, \"count\": 1, \"min\": 0.019311904907226562, \"max\": 0.019311904907226562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108956.2151823, \"EndTime\": 1623108956.7348096, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023365020751953125, \"count\": 1, \"min\": 0.023365020751953125, \"max\": 0.023365020751953125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108956.4162853, \"EndTime\": 1623108956.837912, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108956.3149433, \"EndTime\": 1623108956.8749049, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108956.7222652, \"EndTime\": 1623108957.118249, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108956.875005, \"EndTime\": 1623108957.241688, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108956.7349007, \"EndTime\": 1623108957.2956567, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.026941299438476562, \"count\": 1, \"min\": 0.026941299438476562, \"max\": 0.026941299438476562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108956.838391, \"EndTime\": 1623108957.313418, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108957.1183333, \"EndTime\": 1623108957.6265478, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108957.2420382, \"EndTime\": 1623108957.707658, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.028371810913085938, \"count\": 1, \"min\": 0.028371810913085938, \"max\": 0.028371810913085938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108957.296028, \"EndTime\": 1623108957.7323961, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108957.313508, \"EndTime\": 1623108957.8972442, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024080276489257812, \"count\": 1, \"min\": 0.024080276489257812, \"max\": 0.024080276489257812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108956.7222652, \"EndTime\": 1623108957.118249, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108956.875005, \"EndTime\": 1623108957.241688, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108956.7349007, \"EndTime\": 1623108957.2956567, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.026941299438476562, \"count\": 1, \"min\": 0.026941299438476562, \"max\": 0.026941299438476562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108956.838391, \"EndTime\": 1623108957.313418, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108957.1183333, \"EndTime\": 1623108957.6265478, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108957.2420382, \"EndTime\": 1623108957.707658, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.028371810913085938, \"count\": 1, \"min\": 0.028371810913085938, \"max\": 0.028371810913085938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108957.296028, \"EndTime\": 1623108957.7323961, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108957.313508, \"EndTime\": 1623108957.8972442, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024080276489257812, \"count\": 1, \"min\": 0.024080276489257812, \"max\": 0.024080276489257812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108957.62662, \"EndTime\": 1623108958.1024692, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.028371810913085938, \"count\": 1, \"min\": 0.028371810913085938, \"max\": 0.028371810913085938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108957.7330418, \"EndTime\": 1623108958.1470065, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108957.7077427, \"EndTime\": 1623108958.3309643, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02193450927734375, \"count\": 1, \"min\": 0.02193450927734375, \"max\": 0.02193450927734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108957.897331, \"EndTime\": 1623108958.434256, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108958.147098, \"EndTime\": 1623108958.581534, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024080276489257812, \"count\": 1, \"min\": 0.024080276489257812, \"max\": 0.024080276489257812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108958.1029782, \"EndTime\": 1623108958.679878, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024080276489257812, \"count\": 1, \"min\": 0.024080276489257812, \"max\": 0.024080276489257812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108958.434827, \"EndTime\": 1623108958.7838418, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108958.3310614, \"EndTime\": 1623108958.8675067, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108957.62662, \"EndTime\": 1623108958.1024692, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.028371810913085938, \"count\": 1, \"min\": 0.028371810913085938, \"max\": 0.028371810913085938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108957.7330418, \"EndTime\": 1623108958.1470065, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108957.7077427, \"EndTime\": 1623108958.3309643, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02193450927734375, \"count\": 1, \"min\": 0.02193450927734375, \"max\": 0.02193450927734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108957.897331, \"EndTime\": 1623108958.434256, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108958.147098, \"EndTime\": 1623108958.581534, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024080276489257812, \"count\": 1, \"min\": 0.024080276489257812, \"max\": 0.024080276489257812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108958.1029782, \"EndTime\": 1623108958.679878, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024080276489257812, \"count\": 1, \"min\": 0.024080276489257812, \"max\": 0.024080276489257812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108958.434827, \"EndTime\": 1623108958.7838418, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108958.3310614, \"EndTime\": 1623108958.8675067, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108958.6799676, \"EndTime\": 1623108959.0625567, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02193450927734375, \"count\": 1, \"min\": 0.02193450927734375, \"max\": 0.02193450927734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108958.58163, \"EndTime\": 1623108959.114825, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108958.7839332, \"EndTime\": 1623108959.2636497, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024318695068359375, \"count\": 1, \"min\": 0.024318695068359375, \"max\": 0.024318695068359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108958.8675969, \"EndTime\": 1623108959.3658423, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108959.1153543, \"EndTime\": 1623108959.5818052, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108959.062644, \"EndTime\": 1623108959.637697, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108959.2637954, \"EndTime\": 1623108959.7743282, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108959.365927, \"EndTime\": 1623108959.8864615, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.018596649169921875, \"count\": 1, \"min\": 0.018596649169921875, \"max\": 0.018596649169921875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108958.6799676, \"EndTime\": 1623108959.0625567, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02193450927734375, \"count\": 1, \"min\": 0.02193450927734375, \"max\": 0.02193450927734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108958.58163, \"EndTime\": 1623108959.114825, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108958.7839332, \"EndTime\": 1623108959.2636497, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024318695068359375, \"count\": 1, \"min\": 0.024318695068359375, \"max\": 0.024318695068359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108958.8675969, \"EndTime\": 1623108959.3658423, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108959.1153543, \"EndTime\": 1623108959.5818052, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108959.062644, \"EndTime\": 1623108959.637697, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108959.2637954, \"EndTime\": 1623108959.7743282, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108959.365927, \"EndTime\": 1623108959.8864615, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.018596649169921875, \"count\": 1, \"min\": 0.018596649169921875, \"max\": 0.018596649169921875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108959.6377938, \"EndTime\": 1623108959.9992633, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108959.6377938, \"EndTime\": 1623108959.9992633, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108959.5823567, \"EndTime\": 1623108960.0388405, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019550323486328125, \"count\": 1, \"min\": 0.019550323486328125, \"max\": 0.019550323486328125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108959.7744164, \"EndTime\": 1623108960.1370826, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024318695068359375, \"count\": 1, \"min\": 0.024318695068359375, \"max\": 0.024318695068359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108959.9993443, \"EndTime\": 1623108960.3284438, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020265579223632812, \"count\": 1, \"min\": 0.020265579223632812, \"max\": 0.020265579223632812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108959.8865469, \"EndTime\": 1623108960.411282, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02384185791015625, \"count\": 1, \"min\": 0.02384185791015625, \"max\": 0.02384185791015625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108960.038995, \"EndTime\": 1623108960.4732058, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108960.1371713, \"EndTime\": 1623108960.6743183, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108960.4113748, \"EndTime\": 1623108960.7369268, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108960.3285584, \"EndTime\": 1623108960.8917649, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108960.4732985, \"EndTime\": 1623108960.9030356, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108959.5823567, \"EndTime\": 1623108960.0388405, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019550323486328125, \"count\": 1, \"min\": 0.019550323486328125, \"max\": 0.019550323486328125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108959.7744164, \"EndTime\": 1623108960.1370826, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024318695068359375, \"count\": 1, \"min\": 0.024318695068359375, \"max\": 0.024318695068359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108959.9993443, \"EndTime\": 1623108960.3284438, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020265579223632812, \"count\": 1, \"min\": 0.020265579223632812, \"max\": 0.020265579223632812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108959.8865469, \"EndTime\": 1623108960.411282, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02384185791015625, \"count\": 1, \"min\": 0.02384185791015625, \"max\": 0.02384185791015625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108960.038995, \"EndTime\": 1623108960.4732058, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108960.1371713, \"EndTime\": 1623108960.6743183, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108960.4113748, \"EndTime\": 1623108960.7369268, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108960.3285584, \"EndTime\": 1623108960.8917649, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108960.4732985, \"EndTime\": 1623108960.9030356, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108960.674405, \"EndTime\": 1623108961.1369803, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02193450927734375, \"count\": 1, \"min\": 0.02193450927734375, \"max\": 0.02193450927734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108960.7370183, \"EndTime\": 1623108961.2623405, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108960.9031203, \"EndTime\": 1623108961.2667663, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108960.8918529, \"EndTime\": 1623108961.3873038, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108961.2668507, \"EndTime\": 1623108961.568387, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108961.137075, \"EndTime\": 1623108961.7619898, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108961.264296, \"EndTime\": 1623108961.7826817, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108961.3873973, \"EndTime\": 1623108961.818863, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108961.5684721, \"EndTime\": 1623108961.933131, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108960.674405, \"EndTime\": 1623108961.1369803, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02193450927734375, \"count\": 1, \"min\": 0.02193450927734375, \"max\": 0.02193450927734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108960.7370183, \"EndTime\": 1623108961.2623405, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108960.9031203, \"EndTime\": 1623108961.2667663, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108960.8918529, \"EndTime\": 1623108961.3873038, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108961.2668507, \"EndTime\": 1623108961.568387, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108961.137075, \"EndTime\": 1623108961.7619898, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108961.264296, \"EndTime\": 1623108961.7826817, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108961.3873973, \"EndTime\": 1623108961.818863, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108961.5684721, \"EndTime\": 1623108961.933131, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108961.7620752, \"EndTime\": 1623108962.179471, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019788742065429688, \"count\": 1, \"min\": 0.019788742065429688, \"max\": 0.019788742065429688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108961.7832444, \"EndTime\": 1623108962.188221, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019311904907226562, \"count\": 1, \"min\": 0.019311904907226562, \"max\": 0.019311904907226562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108961.8189273, \"EndTime\": 1623108962.226434, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108961.9332151, \"EndTime\": 1623108962.524979, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020265579223632812, \"count\": 1, \"min\": 0.020265579223632812, \"max\": 0.020265579223632812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108962.2265167, \"EndTime\": 1623108962.5645568, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108962.1883047, \"EndTime\": 1623108962.630625, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108962.179597, \"EndTime\": 1623108962.668915, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108961.7620752, \"EndTime\": 1623108962.179471, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019788742065429688, \"count\": 1, \"min\": 0.019788742065429688, \"max\": 0.019788742065429688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108961.7832444, \"EndTime\": 1623108962.188221, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019311904907226562, \"count\": 1, \"min\": 0.019311904907226562, \"max\": 0.019311904907226562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108961.8189273, \"EndTime\": 1623108962.226434, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108961.9332151, \"EndTime\": 1623108962.524979, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020265579223632812, \"count\": 1, \"min\": 0.020265579223632812, \"max\": 0.020265579223632812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108962.2265167, \"EndTime\": 1623108962.5645568, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108962.1883047, \"EndTime\": 1623108962.630625, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108962.179597, \"EndTime\": 1623108962.668915, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108963.0364935, \"EndTime\": 1623108963.5401263, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108963.5151522, \"EndTime\": 1623108963.80766, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.025510787963867188, \"count\": 1, \"min\": 0.025510787963867188, \"max\": 0.025510787963867188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108963.5313518, \"EndTime\": 1623108963.891538, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108963.4806347, \"EndTime\": 1623108963.9470625, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108963.0364935, \"EndTime\": 1623108963.5401263, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108963.5151522, \"EndTime\": 1623108963.80766, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.025510787963867188, \"count\": 1, \"min\": 0.025510787963867188, \"max\": 0.025510787963867188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108963.5313518, \"EndTime\": 1623108963.891538, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108963.4806347, \"EndTime\": 1623108963.9470625, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108963.5401874, \"EndTime\": 1623108964.103414, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108963.807814, \"EndTime\": 1623108964.2409828, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108963.8916273, \"EndTime\": 1623108964.3611462, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108963.9471514, \"EndTime\": 1623108964.4066243, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02288818359375, \"count\": 1, \"min\": 0.02288818359375, \"max\": 0.02288818359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108964.1034973, \"EndTime\": 1623108964.5490632, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024080276489257812, \"count\": 1, \"min\": 0.024080276489257812, \"max\": 0.024080276489257812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108964.2410715, \"EndTime\": 1623108964.686067, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02384185791015625, \"count\": 1, \"min\": 0.02384185791015625, \"max\": 0.02384185791015625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108964.4067132, \"EndTime\": 1623108964.868644, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019788742065429688, \"count\": 1, \"min\": 0.019788742065429688, \"max\": 0.019788742065429688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108964.3622808, \"EndTime\": 1623108964.902156, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.2541542053222656, \"count\": 1, \"min\": 0.2541542053222656, \"max\": 0.2541542053222656}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108963.5401874, \"EndTime\": 1623108964.103414, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108963.807814, \"EndTime\": 1623108964.2409828, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108963.8916273, \"EndTime\": 1623108964.3611462, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108963.9471514, \"EndTime\": 1623108964.4066243, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02288818359375, \"count\": 1, \"min\": 0.02288818359375, \"max\": 0.02288818359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108964.1034973, \"EndTime\": 1623108964.5490632, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024080276489257812, \"count\": 1, \"min\": 0.024080276489257812, \"max\": 0.024080276489257812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108964.2410715, \"EndTime\": 1623108964.686067, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02384185791015625, \"count\": 1, \"min\": 0.02384185791015625, \"max\": 0.02384185791015625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108964.4067132, \"EndTime\": 1623108964.868644, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019788742065429688, \"count\": 1, \"min\": 0.019788742065429688, \"max\": 0.019788742065429688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108964.3622808, \"EndTime\": 1623108964.902156, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.2541542053222656, \"count\": 1, \"min\": 0.2541542053222656, \"max\": 0.2541542053222656}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108964.5491474, \"EndTime\": 1623108965.012827, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108964.5491474, \"EndTime\": 1623108965.012827, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108964.686166, \"EndTime\": 1623108965.1101966, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02384185791015625, \"count\": 1, \"min\": 0.02384185791015625, \"max\": 0.02384185791015625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108964.902738, \"EndTime\": 1623108965.332262, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.025033950805664062, \"count\": 1, \"min\": 0.025033950805664062, \"max\": 0.025033950805664062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108964.8687298, \"EndTime\": 1623108965.3590162, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.031232833862304688, \"count\": 1, \"min\": 0.031232833862304688, \"max\": 0.031232833862304688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108965.1102812, \"EndTime\": 1623108965.5480914, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019073486328125, \"count\": 1, \"min\": 0.019073486328125, \"max\": 0.019073486328125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108965.012914, \"EndTime\": 1623108965.5810041, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019311904907226562, \"count\": 1, \"min\": 0.019311904907226562, \"max\": 0.019311904907226562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108965.3591042, \"EndTime\": 1623108965.73673, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108965.3323493, \"EndTime\": 1623108965.9147835, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02574920654296875, \"count\": 1, \"min\": 0.02574920654296875, \"max\": 0.02574920654296875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108965.5810938, \"EndTime\": 1623108965.9335015, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02574920654296875, \"count\": 1, \"min\": 0.02574920654296875, \"max\": 0.02574920654296875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108964.686166, \"EndTime\": 1623108965.1101966, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02384185791015625, \"count\": 1, \"min\": 0.02384185791015625, \"max\": 0.02384185791015625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108964.902738, \"EndTime\": 1623108965.332262, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.025033950805664062, \"count\": 1, \"min\": 0.025033950805664062, \"max\": 0.025033950805664062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108964.8687298, \"EndTime\": 1623108965.3590162, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.031232833862304688, \"count\": 1, \"min\": 0.031232833862304688, \"max\": 0.031232833862304688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108965.1102812, \"EndTime\": 1623108965.5480914, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019073486328125, \"count\": 1, \"min\": 0.019073486328125, \"max\": 0.019073486328125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108965.012914, \"EndTime\": 1623108965.5810041, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019311904907226562, \"count\": 1, \"min\": 0.019311904907226562, \"max\": 0.019311904907226562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108965.3591042, \"EndTime\": 1623108965.73673, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108965.3323493, \"EndTime\": 1623108965.9147835, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02574920654296875, \"count\": 1, \"min\": 0.02574920654296875, \"max\": 0.02574920654296875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108965.5810938, \"EndTime\": 1623108965.9335015, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02574920654296875, \"count\": 1, \"min\": 0.02574920654296875, \"max\": 0.02574920654296875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108965.7368205, \"EndTime\": 1623108966.1109824, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108965.550061, \"EndTime\": 1623108966.1642303, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108965.9335895, \"EndTime\": 1623108966.329523, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108965.915304, \"EndTime\": 1623108966.5064116, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.026702880859375, \"count\": 1, \"min\": 0.026702880859375, \"max\": 0.026702880859375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108966.1110625, \"EndTime\": 1623108966.5418124, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108966.164319, \"EndTime\": 1623108966.5767732, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108966.541894, \"EndTime\": 1623108966.8660119, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.018835067749023438, \"count\": 1, \"min\": 0.018835067749023438, \"max\": 0.018835067749023438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108966.5069916, \"EndTime\": 1623108966.9495313, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108965.7368205, \"EndTime\": 1623108966.1109824, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108965.550061, \"EndTime\": 1623108966.1642303, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108965.9335895, \"EndTime\": 1623108966.329523, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108965.915304, \"EndTime\": 1623108966.5064116, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.026702880859375, \"count\": 1, \"min\": 0.026702880859375, \"max\": 0.026702880859375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108966.1110625, \"EndTime\": 1623108966.5418124, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108966.164319, \"EndTime\": 1623108966.5767732, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108966.541894, \"EndTime\": 1623108966.8660119, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.018835067749023438, \"count\": 1, \"min\": 0.018835067749023438, \"max\": 0.018835067749023438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108966.5069916, \"EndTime\": 1623108966.9495313, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108966.3296077, \"EndTime\": 1623108967.000985, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108966.5768573, \"EndTime\": 1623108967.0290816, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020265579223632812, \"count\": 1, \"min\": 0.020265579223632812, \"max\": 0.020265579223632812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108966.8660846, \"EndTime\": 1623108967.3061202, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108966.9496124, \"EndTime\": 1623108967.3791282, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108967.029145, \"EndTime\": 1623108967.3866634, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108967.0010843, \"EndTime\": 1623108967.5341003, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024080276489257812, \"count\": 1, \"min\": 0.024080276489257812, \"max\": 0.024080276489257812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108967.3792136, \"EndTime\": 1623108967.668842, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.027179718017578125, \"count\": 1, \"min\": 0.027179718017578125, \"max\": 0.027179718017578125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108967.306214, \"EndTime\": 1623108967.8533323, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108967.3867507, \"EndTime\": 1623108967.876352, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019073486328125, \"count\": 1, \"min\": 0.019073486328125, \"max\": 0.019073486328125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108966.3296077, \"EndTime\": 1623108967.000985, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108966.5768573, \"EndTime\": 1623108967.0290816, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020265579223632812, \"count\": 1, \"min\": 0.020265579223632812, \"max\": 0.020265579223632812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108966.8660846, \"EndTime\": 1623108967.3061202, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108966.9496124, \"EndTime\": 1623108967.3791282, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108967.029145, \"EndTime\": 1623108967.3866634, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108967.0010843, \"EndTime\": 1623108967.5341003, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024080276489257812, \"count\": 1, \"min\": 0.024080276489257812, \"max\": 0.024080276489257812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108967.3792136, \"EndTime\": 1623108967.668842, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.027179718017578125, \"count\": 1, \"min\": 0.027179718017578125, \"max\": 0.027179718017578125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108967.306214, \"EndTime\": 1623108967.8533323, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108967.3867507, \"EndTime\": 1623108967.876352, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019073486328125, \"count\": 1, \"min\": 0.019073486328125, \"max\": 0.019073486328125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108967.5342064, \"EndTime\": 1623108967.976298, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108967.6690373, \"EndTime\": 1623108968.0679314, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108967.876433, \"EndTime\": 1623108968.2563474, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019550323486328125, \"count\": 1, \"min\": 0.019550323486328125, \"max\": 0.019550323486328125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108967.8538823, \"EndTime\": 1623108968.3433063, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108967.9764314, \"EndTime\": 1623108968.3820963, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108968.068083, \"EndTime\": 1623108968.631029, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108968.2568352, \"EndTime\": 1623108968.6720908, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.018596649169921875, \"count\": 1, \"min\": 0.018596649169921875, \"max\": 0.018596649169921875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108968.382214, \"EndTime\": 1623108968.7734623, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108968.3439379, \"EndTime\": 1623108968.7980368, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.028371810913085938, \"count\": 1, \"min\": 0.028371810913085938, \"max\": 0.028371810913085938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108967.5342064, \"EndTime\": 1623108967.976298, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108967.6690373, \"EndTime\": 1623108968.0679314, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108967.876433, \"EndTime\": 1623108968.2563474, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019550323486328125, \"count\": 1, \"min\": 0.019550323486328125, \"max\": 0.019550323486328125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108967.8538823, \"EndTime\": 1623108968.3433063, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108967.9764314, \"EndTime\": 1623108968.3820963, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108968.068083, \"EndTime\": 1623108968.631029, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108968.2568352, \"EndTime\": 1623108968.6720908, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.018596649169921875, \"count\": 1, \"min\": 0.018596649169921875, \"max\": 0.018596649169921875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108968.382214, \"EndTime\": 1623108968.7734623, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108968.3439379, \"EndTime\": 1623108968.7980368, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.028371810913085938, \"count\": 1, \"min\": 0.028371810913085938, \"max\": 0.028371810913085938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108968.7735484, \"EndTime\": 1623108969.1058064, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108968.6721787, \"EndTime\": 1623108969.114191, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019311904907226562, \"count\": 1, \"min\": 0.019311904907226562, \"max\": 0.019311904907226562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108968.7980995, \"EndTime\": 1623108969.2201223, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108968.6311183, \"EndTime\": 1623108969.2395234, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108969.1142726, \"EndTime\": 1623108969.480293, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019073486328125, \"count\": 1, \"min\": 0.019073486328125, \"max\": 0.019073486328125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108969.1058922, \"EndTime\": 1623108969.5212502, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108969.2206974, \"EndTime\": 1623108969.6092122, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023365020751953125, \"count\": 1, \"min\": 0.023365020751953125, \"max\": 0.023365020751953125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108969.239607, \"EndTime\": 1623108969.6558836, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108969.521336, \"EndTime\": 1623108969.8574615, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108969.4803789, \"EndTime\": 1623108969.9107223, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108968.7735484, \"EndTime\": 1623108969.1058064, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108968.6721787, \"EndTime\": 1623108969.114191, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019311904907226562, \"count\": 1, \"min\": 0.019311904907226562, \"max\": 0.019311904907226562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108968.7980995, \"EndTime\": 1623108969.2201223, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108968.6311183, \"EndTime\": 1623108969.2395234, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108969.1142726, \"EndTime\": 1623108969.480293, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019073486328125, \"count\": 1, \"min\": 0.019073486328125, \"max\": 0.019073486328125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108969.1058922, \"EndTime\": 1623108969.5212502, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108969.2206974, \"EndTime\": 1623108969.6092122, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023365020751953125, \"count\": 1, \"min\": 0.023365020751953125, \"max\": 0.023365020751953125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108969.239607, \"EndTime\": 1623108969.6558836, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108969.521336, \"EndTime\": 1623108969.8574615, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108969.4803789, \"EndTime\": 1623108969.9107223, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108969.609788, \"EndTime\": 1623108969.9955573, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02384185791015625, \"count\": 1, \"min\": 0.02384185791015625, \"max\": 0.02384185791015625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108969.6559741, \"EndTime\": 1623108970.0240126, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.025033950805664062, \"count\": 1, \"min\": 0.025033950805664062, \"max\": 0.025033950805664062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108969.9111733, \"EndTime\": 1623108970.2795434, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108969.8580346, \"EndTime\": 1623108970.3096645, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108969.9960716, \"EndTime\": 1623108970.355993, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.015497207641601562, \"count\": 1, \"min\": 0.015497207641601562, \"max\": 0.015497207641601562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108970.0241032, \"EndTime\": 1623108970.39558, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.015974044799804688, \"count\": 1, \"min\": 0.015974044799804688, \"max\": 0.015974044799804688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108970.3097467, \"EndTime\": 1623108970.6500564, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108970.2796257, \"EndTime\": 1623108970.6929963, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108970.3560762, \"EndTime\": 1623108970.7575202, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108970.3956697, \"EndTime\": 1623108970.799298, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108969.609788, \"EndTime\": 1623108969.9955573, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02384185791015625, \"count\": 1, \"min\": 0.02384185791015625, \"max\": 0.02384185791015625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108969.6559741, \"EndTime\": 1623108970.0240126, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.025033950805664062, \"count\": 1, \"min\": 0.025033950805664062, \"max\": 0.025033950805664062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108969.9111733, \"EndTime\": 1623108970.2795434, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108969.8580346, \"EndTime\": 1623108970.3096645, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108969.9960716, \"EndTime\": 1623108970.355993, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.015497207641601562, \"count\": 1, \"min\": 0.015497207641601562, \"max\": 0.015497207641601562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108970.0241032, \"EndTime\": 1623108970.39558, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.015974044799804688, \"count\": 1, \"min\": 0.015974044799804688, \"max\": 0.015974044799804688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108970.3097467, \"EndTime\": 1623108970.6500564, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108970.2796257, \"EndTime\": 1623108970.6929963, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108970.3560762, \"EndTime\": 1623108970.7575202, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108970.3956697, \"EndTime\": 1623108970.799298, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108970.6501496, \"EndTime\": 1623108970.9810307, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02288818359375, \"count\": 1, \"min\": 0.02288818359375, \"max\": 0.02288818359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108970.693523, \"EndTime\": 1623108971.0343552, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020265579223632812, \"count\": 1, \"min\": 0.020265579223632812, \"max\": 0.020265579223632812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108970.75761, \"EndTime\": 1623108971.1784, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108970.7993839, \"EndTime\": 1623108971.2304578, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108970.9811172, \"EndTime\": 1623108971.3805625, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108971.0344417, \"EndTime\": 1623108971.4497135, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108971.1788137, \"EndTime\": 1623108971.5875137, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019550323486328125, \"count\": 1, \"min\": 0.019550323486328125, \"max\": 0.019550323486328125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108971.230872, \"EndTime\": 1623108971.6105528, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02288818359375, \"count\": 1, \"min\": 0.02288818359375, \"max\": 0.02288818359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108971.3806548, \"EndTime\": 1623108971.784512, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108971.4498205, \"EndTime\": 1623108971.8183222, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.025033950805664062, \"count\": 1, \"min\": 0.025033950805664062, \"max\": 0.025033950805664062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108970.6501496, \"EndTime\": 1623108970.9810307, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02288818359375, \"count\": 1, \"min\": 0.02288818359375, \"max\": 0.02288818359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108970.693523, \"EndTime\": 1623108971.0343552, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020265579223632812, \"count\": 1, \"min\": 0.020265579223632812, \"max\": 0.020265579223632812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108970.75761, \"EndTime\": 1623108971.1784, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0209808349609375, \"count\": 1, \"min\": 0.0209808349609375, \"max\": 0.0209808349609375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108970.7993839, \"EndTime\": 1623108971.2304578, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108970.9811172, \"EndTime\": 1623108971.3805625, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108971.0344417, \"EndTime\": 1623108971.4497135, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108971.1788137, \"EndTime\": 1623108971.5875137, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019550323486328125, \"count\": 1, \"min\": 0.019550323486328125, \"max\": 0.019550323486328125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108971.230872, \"EndTime\": 1623108971.6105528, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02288818359375, \"count\": 1, \"min\": 0.02288818359375, \"max\": 0.02288818359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108971.3806548, \"EndTime\": 1623108971.784512, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108971.4498205, \"EndTime\": 1623108971.8183222, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.025033950805664062, \"count\": 1, \"min\": 0.025033950805664062, \"max\": 0.025033950805664062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108971.6109188, \"EndTime\": 1623108971.982406, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108971.5876002, \"EndTime\": 1623108972.0008428, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108971.8184075, \"EndTime\": 1623108972.127492, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108971.784596, \"EndTime\": 1623108972.2235236, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108971.6109188, \"EndTime\": 1623108971.982406, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108971.5876002, \"EndTime\": 1623108972.0008428, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108971.8184075, \"EndTime\": 1623108972.127492, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108971.784596, \"EndTime\": 1623108972.2235236, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108971.9824991, \"EndTime\": 1623108972.3996053, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108972.001353, \"EndTime\": 1623108972.4036918, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108972.1275733, \"EndTime\": 1623108972.4950051, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108972.2236116, \"EndTime\": 1623108972.608452, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108972.4037511, \"EndTime\": 1623108972.764345, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020265579223632812, \"count\": 1, \"min\": 0.020265579223632812, \"max\": 0.020265579223632812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108972.3996944, \"EndTime\": 1623108972.7772257, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023365020751953125, \"count\": 1, \"min\": 0.023365020751953125, \"max\": 0.023365020751953125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108972.4950922, \"EndTime\": 1623108972.8345802, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.015974044799804688, \"count\": 1, \"min\": 0.015974044799804688, \"max\": 0.015974044799804688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623108972.6085382, \"EndTime\": 1623108972.8752165, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.01621246337890625, \"count\": 1, \"min\": 0.01621246337890625, \"max\": 0.01621246337890625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108971.9824991, \"EndTime\": 1623108972.3996053, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108972.001353, \"EndTime\": 1623108972.4036918, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108972.1275733, \"EndTime\": 1623108972.4950051, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108972.2236116, \"EndTime\": 1623108972.608452, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108972.4037511, \"EndTime\": 1623108972.764345, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020265579223632812, \"count\": 1, \"min\": 0.020265579223632812, \"max\": 0.020265579223632812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108972.3996944, \"EndTime\": 1623108972.7772257, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023365020751953125, \"count\": 1, \"min\": 0.023365020751953125, \"max\": 0.023365020751953125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108972.4950922, \"EndTime\": 1623108972.8345802, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.015974044799804688, \"count\": 1, \"min\": 0.015974044799804688, \"max\": 0.015974044799804688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623108972.6085382, \"EndTime\": 1623108972.8752165, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.01621246337890625, \"count\": 1, \"min\": 0.01621246337890625, \"max\": 0.01621246337890625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans_transformer.transform(pca_azdias_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "91455a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-1-178050996200/kmeans-2021-06-07-23-31-24-233/pca_azdias.csv.out to ../data/pca_azdias.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $kmeans_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0c81504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_azdias_kmeans = pd.read_csv(os.path.join(data_dir, 'pca_azdias.csv.out'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "84898770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"closest_cluster\": 4.0</td>\n",
       "      <td>\"distance_to_cluster\": 3.194801092147827}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"closest_cluster\": 4.0</td>\n",
       "      <td>\"distance_to_cluster\": 3.446899652481079}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"closest_cluster\": 7.0</td>\n",
       "      <td>\"distance_to_cluster\": 3.2063260078430176}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"closest_cluster\": 3.0</td>\n",
       "      <td>\"distance_to_cluster\": 4.0568084716796875}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"closest_cluster\": 2.0</td>\n",
       "      <td>\"distance_to_cluster\": 3.3404178619384766}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0                                            1\n",
       "0  {\"closest_cluster\": 4.0    \"distance_to_cluster\": 3.194801092147827}\n",
       "1  {\"closest_cluster\": 4.0    \"distance_to_cluster\": 3.446899652481079}\n",
       "2  {\"closest_cluster\": 7.0   \"distance_to_cluster\": 3.2063260078430176}\n",
       "3  {\"closest_cluster\": 3.0   \"distance_to_cluster\": 4.0568084716796875}\n",
       "4  {\"closest_cluster\": 2.0   \"distance_to_cluster\": 3.3404178619384766}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_azdias_kmeans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "16dfa0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[35mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[35mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] loading entry points\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] Number of server workers: 4\u001b[0m\n",
      "\u001b[34m[2021-06-07 23:43:58 +0000] [1] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-06-07 23:43:58 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-06-07 23:43:58 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2021-06-07 23:43:58 +0000] [43] [INFO] Booting worker with pid: 43\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 WARNING 140692085131072] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[2021-06-07 23:43:58 +0000] [64] [INFO] Booting worker with pid: 64\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 WARNING 140692085131072] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] loading entry points\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] loaded request iterator application/json\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] loaded response encoder application/json\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] Number of server workers: 4\u001b[0m\n",
      "\u001b[35m[2021-06-07 23:43:58 +0000] [1] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2021-06-07 23:43:58 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2021-06-07 23:43:58 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2021-06-07 23:43:58 +0000] [43] [INFO] Booting worker with pid: 43\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] loading model...\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 WARNING 140692085131072] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[2021-06-07 23:43:58 +0000] [64] [INFO] Booting worker with pid: 64\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] loading model...\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 WARNING 140692085131072] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi: took 0.037 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] ...model loaded.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi: took 0.038 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-07 23:43:58 +0000] [85] [INFO] Booting worker with pid: 85\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 WARNING 140692085131072] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi: took 0.036 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-07 23:43:58 +0000] [106] [INFO] Booting worker with pid: 106\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] loading model...\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 WARNING 140692085131072] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi: took 0.034 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/07/2021 23:43:58 INFO 140692085131072] ...model loaded.\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi: took 0.037 seconds to run.\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] ...model loaded.\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi: took 0.038 seconds to run.\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2021-06-07 23:43:58 +0000] [85] [INFO] Booting worker with pid: 85\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] loading model...\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 WARNING 140692085131072] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi: took 0.036 seconds to run.\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2021-06-07 23:43:58 +0000] [106] [INFO] Booting worker with pid: 106\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] loading model...\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 WARNING 140692085131072] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi: took 0.034 seconds to run.\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/07/2021 23:43:58 INFO 140692085131072] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109438.4947262, \"EndTime\": 1623109440.1070771, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109438.4947262, \"EndTime\": 1623109440.1070771, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[32m2021-06-07T23:44:00.116:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109440.1072433, \"EndTime\": 1623109442.341791, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.05054473876953125, \"count\": 1, \"min\": 0.05054473876953125, \"max\": 0.05054473876953125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109438.5967739, \"EndTime\": 1623109442.4342442, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.03170967102050781, \"count\": 1, \"min\": 0.03170967102050781, \"max\": 0.03170967102050781}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109438.532762, \"EndTime\": 1623109442.4667776, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0438690185546875, \"count\": 1, \"min\": 0.0438690185546875, \"max\": 0.0438690185546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109438.65308, \"EndTime\": 1623109442.4915743, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.027418136596679688, \"count\": 1, \"min\": 0.027418136596679688, \"max\": 0.027418136596679688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109442.4346993, \"EndTime\": 1623109442.821584, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109442.3418615, \"EndTime\": 1623109442.8344374, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019788742065429688, \"count\": 1, \"min\": 0.019788742065429688, \"max\": 0.019788742065429688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109440.1072433, \"EndTime\": 1623109442.341791, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.05054473876953125, \"count\": 1, \"min\": 0.05054473876953125, \"max\": 0.05054473876953125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109438.5967739, \"EndTime\": 1623109442.4342442, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.03170967102050781, \"count\": 1, \"min\": 0.03170967102050781, \"max\": 0.03170967102050781}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109438.532762, \"EndTime\": 1623109442.4667776, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0438690185546875, \"count\": 1, \"min\": 0.0438690185546875, \"max\": 0.0438690185546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109438.65308, \"EndTime\": 1623109442.4915743, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.027418136596679688, \"count\": 1, \"min\": 0.027418136596679688, \"max\": 0.027418136596679688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109442.4346993, \"EndTime\": 1623109442.821584, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109442.3418615, \"EndTime\": 1623109442.8344374, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019788742065429688, \"count\": 1, \"min\": 0.019788742065429688, \"max\": 0.019788742065429688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109442.4916966, \"EndTime\": 1623109442.8967946, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024557113647460938, \"count\": 1, \"min\": 0.024557113647460938, \"max\": 0.024557113647460938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109442.4669812, \"EndTime\": 1623109443.011452, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109442.4916966, \"EndTime\": 1623109442.8967946, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024557113647460938, \"count\": 1, \"min\": 0.024557113647460938, \"max\": 0.024557113647460938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109442.4669812, \"EndTime\": 1623109443.011452, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022411346435546875, \"count\": 1, \"min\": 0.022411346435546875, \"max\": 0.022411346435546875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109442.8216712, \"EndTime\": 1623109443.2400966, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.049114227294921875, \"count\": 1, \"min\": 0.049114227294921875, \"max\": 0.049114227294921875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109442.8969665, \"EndTime\": 1623109443.2535875, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.018835067749023438, \"count\": 1, \"min\": 0.018835067749023438, \"max\": 0.018835067749023438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109442.8345191, \"EndTime\": 1623109443.3431308, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109443.0115433, \"EndTime\": 1623109443.426109, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109443.2401822, \"EndTime\": 1623109443.625736, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109443.343215, \"EndTime\": 1623109443.6706908, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.018835067749023438, \"count\": 1, \"min\": 0.018835067749023438, \"max\": 0.018835067749023438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109443.2536767, \"EndTime\": 1623109443.7892413, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109443.4261875, \"EndTime\": 1623109443.8212662, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109442.8216712, \"EndTime\": 1623109443.2400966, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.049114227294921875, \"count\": 1, \"min\": 0.049114227294921875, \"max\": 0.049114227294921875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109442.8969665, \"EndTime\": 1623109443.2535875, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.018835067749023438, \"count\": 1, \"min\": 0.018835067749023438, \"max\": 0.018835067749023438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109442.8345191, \"EndTime\": 1623109443.3431308, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109443.0115433, \"EndTime\": 1623109443.426109, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109443.2401822, \"EndTime\": 1623109443.625736, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022649765014648438, \"count\": 1, \"min\": 0.022649765014648438, \"max\": 0.022649765014648438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109443.343215, \"EndTime\": 1623109443.6706908, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.018835067749023438, \"count\": 1, \"min\": 0.018835067749023438, \"max\": 0.018835067749023438}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109443.2536767, \"EndTime\": 1623109443.7892413, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109443.4261875, \"EndTime\": 1623109443.8212662, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109443.6258242, \"EndTime\": 1623109444.029264, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020265579223632812, \"count\": 1, \"min\": 0.020265579223632812, \"max\": 0.020265579223632812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109443.6707726, \"EndTime\": 1623109444.042825, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.016450881958007812, \"count\": 1, \"min\": 0.016450881958007812, \"max\": 0.016450881958007812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109443.8217754, \"EndTime\": 1623109444.1475914, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109443.7893317, \"EndTime\": 1623109444.2595654, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023365020751953125, \"count\": 1, \"min\": 0.023365020751953125, \"max\": 0.023365020751953125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109444.029352, \"EndTime\": 1623109444.4300985, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024557113647460938, \"count\": 1, \"min\": 0.024557113647460938, \"max\": 0.024557113647460938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109443.6258242, \"EndTime\": 1623109444.029264, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020265579223632812, \"count\": 1, \"min\": 0.020265579223632812, \"max\": 0.020265579223632812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109443.6707726, \"EndTime\": 1623109444.042825, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.016450881958007812, \"count\": 1, \"min\": 0.016450881958007812, \"max\": 0.016450881958007812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109443.8217754, \"EndTime\": 1623109444.1475914, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109443.7893317, \"EndTime\": 1623109444.2595654, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023365020751953125, \"count\": 1, \"min\": 0.023365020751953125, \"max\": 0.023365020751953125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109444.029352, \"EndTime\": 1623109444.4300985, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024557113647460938, \"count\": 1, \"min\": 0.024557113647460938, \"max\": 0.024557113647460938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109444.0429096, \"EndTime\": 1623109444.4577436, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019550323486328125, \"count\": 1, \"min\": 0.019550323486328125, \"max\": 0.019550323486328125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109444.1476932, \"EndTime\": 1623109444.545358, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109444.2596505, \"EndTime\": 1623109444.6717112, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02193450927734375, \"count\": 1, \"min\": 0.02193450927734375, \"max\": 0.02193450927734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109444.4301841, \"EndTime\": 1623109444.803471, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109444.0429096, \"EndTime\": 1623109444.4577436, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019550323486328125, \"count\": 1, \"min\": 0.019550323486328125, \"max\": 0.019550323486328125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109444.1476932, \"EndTime\": 1623109444.545358, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109444.2596505, \"EndTime\": 1623109444.6717112, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02193450927734375, \"count\": 1, \"min\": 0.02193450927734375, \"max\": 0.02193450927734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109444.4301841, \"EndTime\": 1623109444.803471, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.022172927856445312, \"count\": 1, \"min\": 0.022172927856445312, \"max\": 0.022172927856445312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109444.4578264, \"EndTime\": 1623109444.8823516, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109444.5459483, \"EndTime\": 1623109444.9770555, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109444.6717985, \"EndTime\": 1623109445.0535972, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019788742065429688, \"count\": 1, \"min\": 0.019788742065429688, \"max\": 0.019788742065429688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109444.8035586, \"EndTime\": 1623109445.178653, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109444.8824384, \"EndTime\": 1623109445.2400646, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109444.977143, \"EndTime\": 1623109445.3719854, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109445.0536788, \"EndTime\": 1623109445.4782503, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020265579223632812, \"count\": 1, \"min\": 0.020265579223632812, \"max\": 0.020265579223632812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109445.3725173, \"EndTime\": 1623109445.5177393, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.01811981201171875, \"count\": 1, \"min\": 0.01811981201171875, \"max\": 0.01811981201171875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109445.1787324, \"EndTime\": 1623109445.5630589, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.01621246337890625, \"count\": 1, \"min\": 0.01621246337890625, \"max\": 0.01621246337890625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623109445.2401564, \"EndTime\": 1623109445.582589, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109444.4578264, \"EndTime\": 1623109444.8823516, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109444.5459483, \"EndTime\": 1623109444.9770555, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109444.6717985, \"EndTime\": 1623109445.0535972, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.019788742065429688, \"count\": 1, \"min\": 0.019788742065429688, \"max\": 0.019788742065429688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109444.8035586, \"EndTime\": 1623109445.178653, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020742416381835938, \"count\": 1, \"min\": 0.020742416381835938, \"max\": 0.020742416381835938}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109444.8824384, \"EndTime\": 1623109445.2400646, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023126602172851562, \"count\": 1, \"min\": 0.023126602172851562, \"max\": 0.023126602172851562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109444.977143, \"EndTime\": 1623109445.3719854, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109445.0536788, \"EndTime\": 1623109445.4782503, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020265579223632812, \"count\": 1, \"min\": 0.020265579223632812, \"max\": 0.020265579223632812}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109445.3725173, \"EndTime\": 1623109445.5177393, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.01811981201171875, \"count\": 1, \"min\": 0.01811981201171875, \"max\": 0.01811981201171875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109445.1787324, \"EndTime\": 1623109445.5630589, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.01621246337890625, \"count\": 1, \"min\": 0.01621246337890625, \"max\": 0.01621246337890625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623109445.2401564, \"EndTime\": 1623109445.582589, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02002716064453125, \"count\": 1, \"min\": 0.02002716064453125, \"max\": 0.02002716064453125}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans_transformer.transform(pca_customers_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2e0d9123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-1-178050996200/kmeans-2021-06-07-23-39-49-063/pca_customers.csv.out to ../data/pca_customers.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $kmeans_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "acfd10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers_kmeans = pd.read_csv(os.path.join(data_dir, 'pca_customers.csv.out'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ef32c1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"closest_cluster\": 2.0</td>\n",
       "      <td>\"distance_to_cluster\": 3.5577127933502197}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"closest_cluster\": 6.0</td>\n",
       "      <td>\"distance_to_cluster\": 3.769582509994507}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"closest_cluster\": 2.0</td>\n",
       "      <td>\"distance_to_cluster\": 3.3980414867401123}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"closest_cluster\": 0.0</td>\n",
       "      <td>\"distance_to_cluster\": 4.010591983795166}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"closest_cluster\": 2.0</td>\n",
       "      <td>\"distance_to_cluster\": 3.645479440689087}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0                                            1\n",
       "0  {\"closest_cluster\": 2.0   \"distance_to_cluster\": 3.5577127933502197}\n",
       "1  {\"closest_cluster\": 6.0    \"distance_to_cluster\": 3.769582509994507}\n",
       "2  {\"closest_cluster\": 2.0   \"distance_to_cluster\": 3.3980414867401123}\n",
       "3  {\"closest_cluster\": 0.0    \"distance_to_cluster\": 4.010591983795166}\n",
       "4  {\"closest_cluster\": 2.0    \"distance_to_cluster\": 3.645479440689087}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers_kmeans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6f7306",
   "metadata": {},
   "source": [
    "3.3 Read in and clean the data from K-Means Model output for both population data and customers data. Analyze two sets of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5428c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_kmeans_output(df):\n",
    "    \"\"\"Clean the dataframe that directly reads from K-Means model output\n",
    "       input: the original DataFrame\n",
    "       return: a cleaned DataFrame with cluster information for each individual\"\"\"\n",
    "    df_1 = df.iloc[:, 0].copy()\n",
    "    df_1 = df_1.apply(lambda x: x.split(\":\"))\n",
    "    df_1 = df_1.apply(lambda x: int(float(x[1])))\n",
    "    \n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1d0f76ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_cluster = clean_kmeans_output(df_customers_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9ef27e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    6\n",
       "2    2\n",
       "3    0\n",
       "4    2\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d203cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_cluster = clean_kmeans_output(df_azdias_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "148e011c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    4\n",
       "2    7\n",
       "3    3\n",
       "4    2\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "azdias_cluster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05753a2",
   "metadata": {},
   "source": [
    "Count the percentage for each category for two sets of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "363c4bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    15.225592\n",
       "1    13.795659\n",
       "6    12.942486\n",
       "2    12.775314\n",
       "5    12.091222\n",
       "7    11.745548\n",
       "3    11.745421\n",
       "0     9.678758\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(azdias_cluster.value_counts()/azdias_cluster.count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "34f6ade1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    32.010885\n",
       "2    29.340106\n",
       "6    11.693298\n",
       "7    11.554381\n",
       "5     9.881671\n",
       "0     3.134551\n",
       "1     1.689808\n",
       "4     0.695300\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(customers_cluster.value_counts()/customers_cluster.count())*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb209d3",
   "metadata": {},
   "source": [
    "3.4 Calculate the percentage difference for each category between customer base and general population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d8d7a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_percent = (azdias_cluster.value_counts()/azdias_cluster.count())*100\n",
    "customers_percent = (customers_cluster.value_counts()/customers_cluster.count())*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a6bedad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category 0 has -6.544207687231854 more or less percents in customers than in general population\n",
      "category 1 has -12.105850910214343 more or less percents in customers than in general population\n",
      "category 2 has 16.564791731429132 more or less percents in customers than in general population\n",
      "category 3 has 20.265464830480155 more or less percents in customers than in general population\n",
      "category 4 has -14.530292077986726 more or less percents in customers than in general population\n",
      "category 5 has -2.209551699014632 more or less percents in customers than in general population\n",
      "category 6 has -1.2491871490291064 more or less percents in customers than in general population\n",
      "category 7 has -0.19116703843262783 more or less percents in customers than in general population\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,8):\n",
    "    diff = customers_percent.loc[i] - azdias_percent.loc[i]\n",
    "    print('category {} has {} more or less percents in customers than in general population'.format(i, diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aef221",
   "metadata": {},
   "source": [
    "## According to the result, being in category 3 and 2 increases the individual's chance to be a customer significantly, while being in category 4,1 and 0 decreases the individual's chance to be a customer significantly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9871ba",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4b3861e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>RESPONSE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1763</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1771</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1776</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1460</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1783</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  \\\n",
       "0  1763         2         1.0       8.0          NaN          NaN   \n",
       "1  1771         1         4.0      13.0          NaN          NaN   \n",
       "2  1776         1         1.0       9.0          NaN          NaN   \n",
       "3  1460         2         1.0       6.0          NaN          NaN   \n",
       "4  1783         2         1.0       9.0          NaN          NaN   \n",
       "\n",
       "   ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  ...  \\\n",
       "0          NaN          NaN                   8.0                 15.0  ...   \n",
       "1          NaN          NaN                  13.0                  1.0  ...   \n",
       "2          NaN          NaN                   7.0                  0.0  ...   \n",
       "3          NaN          NaN                   6.0                  4.0  ...   \n",
       "4          NaN          NaN                   9.0                 53.0  ...   \n",
       "\n",
       "   VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  \\\n",
       "0       5.0         2.0      1.0             6.0             9.0       3.0   \n",
       "1       1.0         2.0      1.0             4.0             9.0       7.0   \n",
       "2       6.0         4.0      2.0             NaN             9.0       2.0   \n",
       "3       8.0        11.0     11.0             6.0             9.0       1.0   \n",
       "4       2.0         2.0      1.0             6.0             9.0       3.0   \n",
       "\n",
       "   ZABEOTYP RESPONSE ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0         3        0         2                    4  \n",
       "1         1        0         2                    3  \n",
       "2         3        0         1                    4  \n",
       "3         3        0         2                    4  \n",
       "4         3        0         1                    3  \n",
       "\n",
       "[5 rows x 367 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_train = pd.read_csv('Data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';')\n",
    "mailout_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "04cd60d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42962 entries, 0 to 42961\n",
      "Columns: 367 entries, LNR to ALTERSKATEGORIE_GROB\n",
      "dtypes: float64(267), int64(94), object(6)\n",
      "memory usage: 120.3+ MB\n"
     ]
    }
   ],
   "source": [
    "mailout_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73efb25b",
   "metadata": {},
   "source": [
    "## Process mailout_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc75ea",
   "metadata": {},
   "source": [
    "1.1 Seperate mailout_train into train_features and train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "09191c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = mailout_train.drop(axis=1, columns = 'RESPONSE', inplace=False)\n",
    "train_labels = mailout_train['RESPONSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "8fde8621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>...</th>\n",
       "      <th>VHN</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1763</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1771</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1776</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1460</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1783</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 366 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LNR  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTER_KIND1  ALTER_KIND2  \\\n",
       "0  1763         2         1.0       8.0          NaN          NaN   \n",
       "1  1771         1         4.0      13.0          NaN          NaN   \n",
       "2  1776         1         1.0       9.0          NaN          NaN   \n",
       "3  1460         2         1.0       6.0          NaN          NaN   \n",
       "4  1783         2         1.0       9.0          NaN          NaN   \n",
       "\n",
       "   ALTER_KIND3  ALTER_KIND4  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  ...  \\\n",
       "0          NaN          NaN                   8.0                 15.0  ...   \n",
       "1          NaN          NaN                  13.0                  1.0  ...   \n",
       "2          NaN          NaN                   7.0                  0.0  ...   \n",
       "3          NaN          NaN                   6.0                  4.0  ...   \n",
       "4          NaN          NaN                   9.0                 53.0  ...   \n",
       "\n",
       "   VHN  VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  \\\n",
       "0  2.0       5.0         2.0      1.0             6.0             9.0   \n",
       "1  3.0       1.0         2.0      1.0             4.0             9.0   \n",
       "2  1.0       6.0         4.0      2.0             NaN             9.0   \n",
       "3  4.0       8.0        11.0     11.0             6.0             9.0   \n",
       "4  4.0       2.0         2.0      1.0             6.0             9.0   \n",
       "\n",
       "   WOHNLAGE ZABEOTYP ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0       3.0        3         2                    4  \n",
       "1       7.0        1         2                    3  \n",
       "2       2.0        3         1                    4  \n",
       "3       1.0        3         2                    4  \n",
       "4       3.0        3         1                    3  \n",
       "\n",
       "[5 rows x 366 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "fdf89699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: RESPONSE, dtype: int64"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262a425b",
   "metadata": {},
   "source": [
    "1.2 Process train_features to prepare for PCA batch transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "292de57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder the column order to make sure it is the same order as azdias \n",
    "column_order = azdias.columns.tolist()\n",
    "train_features = train_features[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "d2b959a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A new data_process is needed as we don't want to delete rows: \n",
    "def data_process_2(df):\n",
    "    \"\"\"All data cleaning process for the raw DataFrame from csv file \n",
    "       input: original dataframe \n",
    "       return: processed dataframe that has only integer/float as its values and no NaN\"\"\"\n",
    "    df_1 = convert_unknown_to_NaN(df) #convert the unknown values to NaN\n",
    "    df_2 = df_1.drop(axis=1, columns=column_NaN, inplace=False) #drop the columns that have high percentage of NaN\n",
    "    df_3 = process_ob_col(df_2) #process the columns that have object dtypes \n",
    "    df_4 = fill_col_mean(df_3) #fill the remaining NaN with column means\n",
    "    \n",
    "    return df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "9a9bfc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_processed = data_process_2(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a91942a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>BALLRAUM</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "      <th>CAMEO_INTL_FAM_Wealth</th>\n",
       "      <th>CAMEO_INTL_FAM_COMPOSITION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1771</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1776</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1460</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LNR  AKT_DAT_KL  ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  ANZ_KINDER  \\\n",
       "0  1763         1.0                 15.0      0.000000         0.0   \n",
       "1  1771         4.0                  1.0      0.000000         0.0   \n",
       "2  1776         1.0                  0.0      0.049574         0.0   \n",
       "3  1460         1.0                  4.0      0.000000         0.0   \n",
       "4  1783         1.0                 53.0      0.000000         0.0   \n",
       "\n",
       "   ANZ_PERSONEN  ANZ_STATISTISCHE_HAUSHALTE  ANZ_TITEL  ARBEIT  BALLRAUM  ...  \\\n",
       "0           1.0                        13.0        0.0     3.0       5.0  ...   \n",
       "1           2.0                         1.0        0.0     2.0       5.0  ...   \n",
       "2           0.0                         1.0        0.0     4.0       1.0  ...   \n",
       "3           2.0                         4.0        0.0     4.0       2.0  ...   \n",
       "4           1.0                        44.0        0.0     3.0       4.0  ...   \n",
       "\n",
       "   VK_DHT4A  VK_DISTANZ  VK_ZG11  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  \\\n",
       "0       5.0         2.0      1.0             9.0       3.0         3   \n",
       "1       1.0         2.0      1.0             9.0       7.0         1   \n",
       "2       6.0         4.0      2.0             9.0       2.0         3   \n",
       "3       8.0        11.0     11.0             9.0       1.0         3   \n",
       "4       2.0         2.0      1.0             9.0       3.0         3   \n",
       "\n",
       "   ANREDE_KZ  ALTERSKATEGORIE_GROB  CAMEO_INTL_FAM_Wealth  \\\n",
       "0          2                     4                    3.0   \n",
       "1          2                     3                    3.0   \n",
       "2          1                     4                    1.0   \n",
       "3          2                     4                    1.0   \n",
       "4          1                     3                    4.0   \n",
       "\n",
       "   CAMEO_INTL_FAM_COMPOSITION  \n",
       "0                         4.0  \n",
       "1                         2.0  \n",
       "2                         4.0  \n",
       "3                         4.0  \n",
       "4                         1.0  \n",
       "\n",
       "[5 rows x 278 columns]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "37021e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_processed.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2d40d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_processed.drop(axis=1, columns = 'LNR', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "30130dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>BALLRAUM</th>\n",
       "      <th>CAMEO_DEUG_2015</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "      <th>CAMEO_INTL_FAM_Wealth</th>\n",
       "      <th>CAMEO_INTL_FAM_COMPOSITION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.035230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.375</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.121005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.119241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AKT_DAT_KL  ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  ANZ_KINDER  ANZ_PERSONEN  \\\n",
       "0       0.000             0.034247      0.000000         0.0      0.041667   \n",
       "1       0.375             0.002283      0.000000         0.0      0.083333   \n",
       "2       0.000             0.000000      0.002479         0.0      0.000000   \n",
       "3       0.000             0.009132      0.000000         0.0      0.083333   \n",
       "4       0.000             0.121005      0.000000         0.0      0.041667   \n",
       "\n",
       "   ANZ_STATISTISCHE_HAUSHALTE  ANZ_TITEL  ARBEIT  BALLRAUM  CAMEO_DEUG_2015  \\\n",
       "0                    0.035230        0.0   0.250  0.666667            0.500   \n",
       "1                    0.002710        0.0   0.125  0.666667            0.500   \n",
       "2                    0.002710        0.0   0.375  0.000000            0.125   \n",
       "3                    0.010840        0.0   0.375  0.166667            0.125   \n",
       "4                    0.119241        0.0   0.250  0.500000            0.750   \n",
       "\n",
       "   ...  VK_DHT4A  VK_DISTANZ  VK_ZG11  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  \\\n",
       "0  ...       0.4    0.083333      0.0             1.0     0.375       0.4   \n",
       "1  ...       0.0    0.083333      0.0             1.0     0.875       0.0   \n",
       "2  ...       0.5    0.250000      0.1             1.0     0.250       0.4   \n",
       "3  ...       0.7    0.833333      1.0             1.0     0.125       0.4   \n",
       "4  ...       0.1    0.083333      0.0             1.0     0.375       0.4   \n",
       "\n",
       "   ANREDE_KZ  ALTERSKATEGORIE_GROB  CAMEO_INTL_FAM_Wealth  \\\n",
       "0        1.0                 0.375                   0.50   \n",
       "1        1.0                 0.250                   0.50   \n",
       "2        0.0                 0.375                   0.00   \n",
       "3        1.0                 0.375                   0.00   \n",
       "4        0.0                 0.250                   0.75   \n",
       "\n",
       "   CAMEO_INTL_FAM_COMPOSITION  \n",
       "0                        0.75  \n",
       "1                        0.25  \n",
       "2                        0.75  \n",
       "3                        0.75  \n",
       "4                        0.00  \n",
       "\n",
       "[5 rows x 277 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_3 = MinMaxScaler(feature_range= (0, 1))\n",
    "\n",
    "train_features_scaled= pd.DataFrame(scaler_3.fit_transform(train_features_processed.astype(float)))\n",
    "train_features_scaled.index = train_features_processed.index\n",
    "train_features_scaled.columns = train_features_processed.columns\n",
    "train_features_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "cbabdd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42962 entries, 0 to 42961\n",
      "Columns: 277 entries, AKT_DAT_KL to CAMEO_INTL_FAM_COMPOSITION\n",
      "dtypes: float64(277)\n",
      "memory usage: 90.8 MB\n"
     ]
    }
   ],
   "source": [
    "train_features_scaled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c13212",
   "metadata": {},
   "source": [
    "1.3 Run the PCA batch transform on the train features; Clean the transformed data to show only the values for top 80 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "3c27e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_scaled.to_csv(os.path.join(data_dir, 'train_features.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "7f5cd9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_location = session.upload_data(os.path.join(data_dir, 'train_features.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "288fea27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] nvidia-smi: took 0.030 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] loading entry points\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] Number of server workers: 4\u001b[0m\n",
      "\u001b[34m[2021-06-08 04:42:27 +0000] [1] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-06-08 04:42:27 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-06-08 04:42:27 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2021-06-08 04:42:27 +0000] [54] [INFO] Booting worker with pid: 54\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-08 04:42:27 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-08 04:42:27 +0000] [75] [INFO] Booting worker with pid: 75\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-08 04:42:27 +0000] [86] [INFO] Booting worker with pid: 86\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:27 INFO 140596081870656] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127347.2056582, \"EndTime\": 1623127348.8051832, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:30 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:30 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:30 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:30 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2620.\u001b[0m\n",
      "\n",
      "\u001b[34m[06/08/2021 04:42:30 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:30 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:30 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:30 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2611.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:30 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:30 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:30 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:30 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2623.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:30 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:30 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:30 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:30 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:30 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:30 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:30 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2611.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:30 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:30 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:30 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:30 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2623.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:30 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:30 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:30 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:30 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2604.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:30 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2604.\u001b[0m\n",
      "\u001b[32m2021-06-08T04:42:28.813:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127347.178116, \"EndTime\": 1623127351.818439, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127348.8053203, \"EndTime\": 1623127351.9440255, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127347.2217965, \"EndTime\": 1623127351.968647, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127347.1834185, \"EndTime\": 1623127351.9777312, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127347.178116, \"EndTime\": 1623127351.818439, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127348.8053203, \"EndTime\": 1623127351.9440255, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127347.2217965, \"EndTime\": 1623127351.968647, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127347.1834185, \"EndTime\": 1623127351.9777312, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2622.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2624.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2606.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:32 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2617.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2622.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2624.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2606.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:32 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2617.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127351.8185751, \"EndTime\": 1623127353.9356394, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127351.9441247, \"EndTime\": 1623127354.033041, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127351.9778626, \"EndTime\": 1623127354.0564823, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127351.9687834, \"EndTime\": 1623127354.1492465, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127351.8185751, \"EndTime\": 1623127353.9356394, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127351.9441247, \"EndTime\": 1623127354.033041, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127351.9778626, \"EndTime\": 1623127354.0564823, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127351.9687834, \"EndTime\": 1623127354.1492465, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2642.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2642.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2622.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2624.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:34 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2607.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2622.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2624.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:34 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2607.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127353.9361775, \"EndTime\": 1623127355.8309662, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127353.9361775, \"EndTime\": 1623127355.8309662, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127354.0331335, \"EndTime\": 1623127356.3014157, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127354.1493547, \"EndTime\": 1623127356.400042, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127354.0565772, \"EndTime\": 1623127356.4518046, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:36 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:36 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:36 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:36 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2598.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:36 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:36 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:36 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:36 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2603.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:37 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:37 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:37 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:37 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2600.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:37 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127354.0331335, \"EndTime\": 1623127356.3014157, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127354.1493547, \"EndTime\": 1623127356.400042, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127354.0565772, \"EndTime\": 1623127356.4518046, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:36 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:36 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:36 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:36 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2598.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:36 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:36 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:36 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:36 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2603.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:37 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:37 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:37 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:37 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2600.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:37 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:37 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:37 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:37 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2628.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:37 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:37 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:37 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2628.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127355.8314774, \"EndTime\": 1623127358.1466491, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127355.8314774, \"EndTime\": 1623127358.1466491, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127356.3019526, \"EndTime\": 1623127358.452488, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127356.3019526, \"EndTime\": 1623127358.452488, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127356.451878, \"EndTime\": 1623127358.587134, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:38 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:38 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:38 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:42:38 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1094.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127356.4001362, \"EndTime\": 1623127358.7877574, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127356.451878, \"EndTime\": 1623127358.587134, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:38 WARNING 140596081870656] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:38 INFO 140596081870656] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:38 INFO 140596081870656] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:42:38 INFO 140596081870656] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1094.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127356.4001362, \"EndTime\": 1623127358.7877574, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127358.146737, \"EndTime\": 1623127359.4048626, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127358.146737, \"EndTime\": 1623127359.4048626, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pca_transformer.transform(train_features_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "4a580205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-1-178050996200/pca-2021-06-08-04-38-12-110/train_features.csv.out to ../data/train_features.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $pca_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "d1453ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train_features = pd.read_csv(os.path.join(data_dir, 'train_features.csv.out'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "aebf8258",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_out(pca_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "a0ca3353",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 80 \n",
    "transformed_pca_train_features = create_transformed_df(pca_train_features, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "3f4742e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>c_9</th>\n",
       "      <th>c_10</th>\n",
       "      <th>...</th>\n",
       "      <th>c_71</th>\n",
       "      <th>c_72</th>\n",
       "      <th>c_73</th>\n",
       "      <th>c_74</th>\n",
       "      <th>c_75</th>\n",
       "      <th>c_76</th>\n",
       "      <th>c_77</th>\n",
       "      <th>c_78</th>\n",
       "      <th>c_79</th>\n",
       "      <th>c_80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.144516</td>\n",
       "      <td>1.887148</td>\n",
       "      <td>-1.882622</td>\n",
       "      <td>-0.048405</td>\n",
       "      <td>0.690094</td>\n",
       "      <td>0.020077</td>\n",
       "      <td>0.809921</td>\n",
       "      <td>0.020945</td>\n",
       "      <td>0.075813</td>\n",
       "      <td>-0.021491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054432</td>\n",
       "      <td>-0.362911</td>\n",
       "      <td>0.284236</td>\n",
       "      <td>0.155066</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>-0.049075</td>\n",
       "      <td>-0.322160</td>\n",
       "      <td>-0.088001</td>\n",
       "      <td>-0.347405</td>\n",
       "      <td>-0.073487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.439446</td>\n",
       "      <td>0.340658</td>\n",
       "      <td>0.197613</td>\n",
       "      <td>0.693218</td>\n",
       "      <td>0.979631</td>\n",
       "      <td>0.496533</td>\n",
       "      <td>0.851029</td>\n",
       "      <td>-0.067310</td>\n",
       "      <td>0.234468</td>\n",
       "      <td>0.077654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473752</td>\n",
       "      <td>-0.252177</td>\n",
       "      <td>0.224710</td>\n",
       "      <td>0.132591</td>\n",
       "      <td>0.029336</td>\n",
       "      <td>-0.059287</td>\n",
       "      <td>-0.424146</td>\n",
       "      <td>-0.242151</td>\n",
       "      <td>0.453012</td>\n",
       "      <td>-0.540896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.309988</td>\n",
       "      <td>1.616213</td>\n",
       "      <td>-0.912996</td>\n",
       "      <td>0.496057</td>\n",
       "      <td>-1.021015</td>\n",
       "      <td>-1.439816</td>\n",
       "      <td>-0.153049</td>\n",
       "      <td>0.416211</td>\n",
       "      <td>-0.023488</td>\n",
       "      <td>-1.677067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360875</td>\n",
       "      <td>0.025349</td>\n",
       "      <td>-0.312739</td>\n",
       "      <td>-0.345905</td>\n",
       "      <td>-0.184987</td>\n",
       "      <td>0.010898</td>\n",
       "      <td>0.272235</td>\n",
       "      <td>-0.180548</td>\n",
       "      <td>0.090512</td>\n",
       "      <td>0.021791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.766258</td>\n",
       "      <td>1.822620</td>\n",
       "      <td>-1.365426</td>\n",
       "      <td>-2.630953</td>\n",
       "      <td>0.756407</td>\n",
       "      <td>0.424133</td>\n",
       "      <td>-0.724646</td>\n",
       "      <td>-0.754212</td>\n",
       "      <td>-0.371986</td>\n",
       "      <td>0.397551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066517</td>\n",
       "      <td>-0.093322</td>\n",
       "      <td>-0.249120</td>\n",
       "      <td>-0.003015</td>\n",
       "      <td>0.075503</td>\n",
       "      <td>-0.312867</td>\n",
       "      <td>-0.187745</td>\n",
       "      <td>0.148759</td>\n",
       "      <td>-0.154118</td>\n",
       "      <td>-0.506283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.149392</td>\n",
       "      <td>1.341818</td>\n",
       "      <td>-1.403229</td>\n",
       "      <td>-0.793912</td>\n",
       "      <td>-0.992830</td>\n",
       "      <td>-1.549229</td>\n",
       "      <td>0.569451</td>\n",
       "      <td>-0.270216</td>\n",
       "      <td>0.536317</td>\n",
       "      <td>0.119262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585516</td>\n",
       "      <td>-0.055558</td>\n",
       "      <td>-0.153592</td>\n",
       "      <td>-0.103277</td>\n",
       "      <td>0.180957</td>\n",
       "      <td>0.131901</td>\n",
       "      <td>0.213031</td>\n",
       "      <td>-0.011378</td>\n",
       "      <td>0.155462</td>\n",
       "      <td>0.011923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        c_1       c_2       c_3       c_4       c_5       c_6       c_7  \\\n",
       "0  1.144516  1.887148 -1.882622 -0.048405  0.690094  0.020077  0.809921   \n",
       "1 -2.439446  0.340658  0.197613  0.693218  0.979631  0.496533  0.851029   \n",
       "2 -1.309988  1.616213 -0.912996  0.496057 -1.021015 -1.439816 -0.153049   \n",
       "3 -0.766258  1.822620 -1.365426 -2.630953  0.756407  0.424133 -0.724646   \n",
       "4 -0.149392  1.341818 -1.403229 -0.793912 -0.992830 -1.549229  0.569451   \n",
       "\n",
       "        c_8       c_9      c_10  ...      c_71      c_72      c_73      c_74  \\\n",
       "0  0.020945  0.075813 -0.021491  ... -0.054432 -0.362911  0.284236  0.155066   \n",
       "1 -0.067310  0.234468  0.077654  ...  0.473752 -0.252177  0.224710  0.132591   \n",
       "2  0.416211 -0.023488 -1.677067  ...  0.360875  0.025349 -0.312739 -0.345905   \n",
       "3 -0.754212 -0.371986  0.397551  ... -0.066517 -0.093322 -0.249120 -0.003015   \n",
       "4 -0.270216  0.536317  0.119262  ...  0.585516 -0.055558 -0.153592 -0.103277   \n",
       "\n",
       "       c_75      c_76      c_77      c_78      c_79      c_80  \n",
       "0  0.010453 -0.049075 -0.322160 -0.088001 -0.347405 -0.073487  \n",
       "1  0.029336 -0.059287 -0.424146 -0.242151  0.453012 -0.540896  \n",
       "2 -0.184987  0.010898  0.272235 -0.180548  0.090512  0.021791  \n",
       "3  0.075503 -0.312867 -0.187745  0.148759 -0.154118 -0.506283  \n",
       "4  0.180957  0.131901  0.213031 -0.011378  0.155462  0.011923  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = []\n",
    "for i in range(1, n+1):\n",
    "    column_names.append('c_'+str(i)) \n",
    "\n",
    "transformed_pca_train_features.columns = column_names\n",
    "\n",
    "transformed_pca_train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216b40d0",
   "metadata": {},
   "source": [
    "## Note: transformed_pca_train_features will be the new training_features for supervised model input, due to its reduced dimensionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6439fa0",
   "metadata": {},
   "source": [
    "1.4 Run the K-Means model on the transformed_pca_train_features, to know which category each individual falls into. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "c7f8aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_pca_train_features.to_csv(os.path.join(data_dir, 'pca_train_features.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "200e4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train_features_location = session.upload_data(os.path.join(data_dir, 'pca_train_features.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "ddc989e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] loading entry points\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] Number of server workers: 4\u001b[0m\n",
      "\u001b[34m[2021-06-08 04:51:36 +0000] [1] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-06-08 04:51:36 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-06-08 04:51:36 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[35mRunning default environment configuration script\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] loading entry points\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] loaded request iterator application/json\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] loaded response encoder application/json\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] Number of server workers: 4\u001b[0m\n",
      "\u001b[35m[2021-06-08 04:51:36 +0000] [1] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2021-06-08 04:51:36 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2021-06-08 04:51:36 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2021-06-08 04:51:36 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 WARNING 140331701110592] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[2021-06-08 04:51:36 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 WARNING 140331701110592] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[2021-06-08 04:51:36 +0000] [84] [INFO] Booting worker with pid: 84\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi: took 0.036 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] ...model loaded.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 WARNING 140331701110592] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi: took 0.030 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] ...model loaded.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-08 04:51:36 +0000] [105] [INFO] Booting worker with pid: 105\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 WARNING 140331701110592] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 04:51:36 INFO 140331701110592] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2021-06-08 04:51:36 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] loading model...\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 WARNING 140331701110592] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[2021-06-08 04:51:36 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] loading model...\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 WARNING 140331701110592] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[2021-06-08 04:51:36 +0000] [84] [INFO] Booting worker with pid: 84\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi: took 0.036 seconds to run.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] ...model loaded.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] loading model...\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 WARNING 140331701110592] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi: took 0.030 seconds to run.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] ...model loaded.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2021-06-08 04:51:36 +0000] [105] [INFO] Booting worker with pid: 105\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] loading model...\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 WARNING 140331701110592] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 04:51:36 INFO 140331701110592] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127896.7894657, \"EndTime\": 1623127898.3781424, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127896.7894657, \"EndTime\": 1623127898.3781424, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127896.7719502, \"EndTime\": 1623127899.443645, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.030755996704101562, \"count\": 1, \"min\": 0.030755996704101562, \"max\": 0.030755996704101562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127898.3782372, \"EndTime\": 1623127899.5397902, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.026226043701171875, \"count\": 1, \"min\": 0.026226043701171875, \"max\": 0.026226043701171875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127896.756323, \"EndTime\": 1623127899.5933774, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.030755996704101562, \"count\": 1, \"min\": 0.030755996704101562, \"max\": 0.030755996704101562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127896.8371305, \"EndTime\": 1623127899.6494265, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02956390380859375, \"count\": 1, \"min\": 0.02956390380859375, \"max\": 0.02956390380859375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127899.5398557, \"EndTime\": 1623127899.8719447, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0247955322265625, \"count\": 1, \"min\": 0.0247955322265625, \"max\": 0.0247955322265625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127899.4437637, \"EndTime\": 1623127899.9293187, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127899.593501, \"EndTime\": 1623127900.0574994, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024318695068359375, \"count\": 1, \"min\": 0.024318695068359375, \"max\": 0.024318695068359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127899.6495574, \"EndTime\": 1623127900.086144, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127896.7719502, \"EndTime\": 1623127899.443645, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.030755996704101562, \"count\": 1, \"min\": 0.030755996704101562, \"max\": 0.030755996704101562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127898.3782372, \"EndTime\": 1623127899.5397902, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.026226043701171875, \"count\": 1, \"min\": 0.026226043701171875, \"max\": 0.026226043701171875}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127896.756323, \"EndTime\": 1623127899.5933774, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.030755996704101562, \"count\": 1, \"min\": 0.030755996704101562, \"max\": 0.030755996704101562}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127896.8371305, \"EndTime\": 1623127899.6494265, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.02956390380859375, \"count\": 1, \"min\": 0.02956390380859375, \"max\": 0.02956390380859375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127899.5398557, \"EndTime\": 1623127899.8719447, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0247955322265625, \"count\": 1, \"min\": 0.0247955322265625, \"max\": 0.0247955322265625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127899.4437637, \"EndTime\": 1623127899.9293187, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.020503997802734375, \"count\": 1, \"min\": 0.020503997802734375, \"max\": 0.020503997802734375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127899.593501, \"EndTime\": 1623127900.0574994, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.024318695068359375, \"count\": 1, \"min\": 0.024318695068359375, \"max\": 0.024318695068359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127899.6495574, \"EndTime\": 1623127900.086144, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.023603439331054688, \"count\": 1, \"min\": 0.023603439331054688, \"max\": 0.023603439331054688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127899.8720317, \"EndTime\": 1623127900.2112703, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.025510787963867188, \"count\": 1, \"min\": 0.025510787963867188, \"max\": 0.025510787963867188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127900.0862296, \"EndTime\": 1623127900.2316823, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.017404556274414062, \"count\": 1, \"min\": 0.017404556274414062, \"max\": 0.017404556274414062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623127899.9294019, \"EndTime\": 1623127900.2820706, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.017881393432617188, \"count\": 1, \"min\": 0.017881393432617188, \"max\": 0.017881393432617188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127899.8720317, \"EndTime\": 1623127900.2112703, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.025510787963867188, \"count\": 1, \"min\": 0.025510787963867188, \"max\": 0.025510787963867188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127900.0862296, \"EndTime\": 1623127900.2316823, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.017404556274414062, \"count\": 1, \"min\": 0.017404556274414062, \"max\": 0.017404556274414062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623127899.9294019, \"EndTime\": 1623127900.2820706, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.017881393432617188, \"count\": 1, \"min\": 0.017881393432617188, \"max\": 0.017881393432617188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[32m2021-06-08T04:51:38.382:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans_transformer.transform(pca_train_features_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "cd672f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-1-178050996200/kmeans-2021-06-08-04-47-09-728/pca_train_features.csv.out to ../data/pca_train_features.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $kmeans_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "b9c8c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features_kmeans = pd.read_csv(os.path.join(data_dir, 'pca_train_features.csv.out'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "05f68f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_cluster = clean_kmeans_output(df_train_features_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "d2b7aae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    7\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_cluster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f343fe",
   "metadata": {},
   "source": [
    "1.5 Create a DataFrame that maps each category into a normalized number that indicates the relative likelihood of the individial in this category to be the client. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "7b7620f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.544207687231854, -12.105850910214343, 16.564791731429132, 20.265464830480155, -14.530292077986726, -2.209551699014632, -1.2491871490291064, -0.19116703843262783]\n"
     ]
    }
   ],
   "source": [
    "#create a panda Dataframe, the index is the category number (0-7). \n",
    "#the value is the difference percentage (customer percentage - population percentage) which was shown in Part 1 section 3.4\n",
    "diff_list = []\n",
    "for i in range(0,8):\n",
    "    diff_list.append(customers_percent.loc[i] - azdias_percent.loc[i])\n",
    "print(diff_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "14cbb7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df = pd.DataFrame(diff_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "bd39546e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.544208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-12.105851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.564792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.265465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.530292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2.209552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.249187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.191167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0  -6.544208\n",
       "1 -12.105851\n",
       "2  16.564792\n",
       "3  20.265465\n",
       "4 -14.530292\n",
       "5  -2.209552\n",
       "6  -1.249187\n",
       "7  -0.191167"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "292dbd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.229513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.069676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.893646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.354087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.381687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.412094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.229513\n",
       "1  0.069676\n",
       "2  0.893646\n",
       "3  1.000000\n",
       "4  0.000000\n",
       "5  0.354087\n",
       "6  0.381687\n",
       "7  0.412094"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize the value between (0,1)\n",
    "scaler_4 = MinMaxScaler(feature_range= (0, 1))\n",
    "category_scaled= pd.DataFrame(scaler_4.fit_transform(category_df.astype(float)))\n",
    "category_scaled.index = category_df.index\n",
    "category_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd53d57",
   "metadata": {},
   "source": [
    "1.6 Add additional column to the train features. It can add more information to the training data that can increase model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "0c5c8314",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_series = category_scaled.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "a2dd9924",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict = category_series.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "96ceb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_cluster_mapped = train_features_cluster.map(category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "4af129c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.381687\n",
       "1    0.412094\n",
       "2    0.893646\n",
       "3    0.893646\n",
       "4    0.893646\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_cluster_mapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "d04aaaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_finalized = pd.concat([transformed_pca_train_features, train_features_cluster_mapped], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "adef31f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>c_9</th>\n",
       "      <th>c_10</th>\n",
       "      <th>...</th>\n",
       "      <th>c_72</th>\n",
       "      <th>c_73</th>\n",
       "      <th>c_74</th>\n",
       "      <th>c_75</th>\n",
       "      <th>c_76</th>\n",
       "      <th>c_77</th>\n",
       "      <th>c_78</th>\n",
       "      <th>c_79</th>\n",
       "      <th>c_80</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.144516</td>\n",
       "      <td>1.887148</td>\n",
       "      <td>-1.882622</td>\n",
       "      <td>-0.048405</td>\n",
       "      <td>0.690094</td>\n",
       "      <td>0.020077</td>\n",
       "      <td>0.809921</td>\n",
       "      <td>0.020945</td>\n",
       "      <td>0.075813</td>\n",
       "      <td>-0.021491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362911</td>\n",
       "      <td>0.284236</td>\n",
       "      <td>0.155066</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>-0.049075</td>\n",
       "      <td>-0.322160</td>\n",
       "      <td>-0.088001</td>\n",
       "      <td>-0.347405</td>\n",
       "      <td>-0.073487</td>\n",
       "      <td>0.381687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.439446</td>\n",
       "      <td>0.340658</td>\n",
       "      <td>0.197613</td>\n",
       "      <td>0.693218</td>\n",
       "      <td>0.979631</td>\n",
       "      <td>0.496533</td>\n",
       "      <td>0.851029</td>\n",
       "      <td>-0.067310</td>\n",
       "      <td>0.234468</td>\n",
       "      <td>0.077654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.252177</td>\n",
       "      <td>0.224710</td>\n",
       "      <td>0.132591</td>\n",
       "      <td>0.029336</td>\n",
       "      <td>-0.059287</td>\n",
       "      <td>-0.424146</td>\n",
       "      <td>-0.242151</td>\n",
       "      <td>0.453012</td>\n",
       "      <td>-0.540896</td>\n",
       "      <td>0.412094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.309988</td>\n",
       "      <td>1.616213</td>\n",
       "      <td>-0.912996</td>\n",
       "      <td>0.496057</td>\n",
       "      <td>-1.021015</td>\n",
       "      <td>-1.439816</td>\n",
       "      <td>-0.153049</td>\n",
       "      <td>0.416211</td>\n",
       "      <td>-0.023488</td>\n",
       "      <td>-1.677067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025349</td>\n",
       "      <td>-0.312739</td>\n",
       "      <td>-0.345905</td>\n",
       "      <td>-0.184987</td>\n",
       "      <td>0.010898</td>\n",
       "      <td>0.272235</td>\n",
       "      <td>-0.180548</td>\n",
       "      <td>0.090512</td>\n",
       "      <td>0.021791</td>\n",
       "      <td>0.893646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.766258</td>\n",
       "      <td>1.822620</td>\n",
       "      <td>-1.365426</td>\n",
       "      <td>-2.630953</td>\n",
       "      <td>0.756407</td>\n",
       "      <td>0.424133</td>\n",
       "      <td>-0.724646</td>\n",
       "      <td>-0.754212</td>\n",
       "      <td>-0.371986</td>\n",
       "      <td>0.397551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093322</td>\n",
       "      <td>-0.249120</td>\n",
       "      <td>-0.003015</td>\n",
       "      <td>0.075503</td>\n",
       "      <td>-0.312867</td>\n",
       "      <td>-0.187745</td>\n",
       "      <td>0.148759</td>\n",
       "      <td>-0.154118</td>\n",
       "      <td>-0.506283</td>\n",
       "      <td>0.893646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.149392</td>\n",
       "      <td>1.341818</td>\n",
       "      <td>-1.403229</td>\n",
       "      <td>-0.793912</td>\n",
       "      <td>-0.992830</td>\n",
       "      <td>-1.549229</td>\n",
       "      <td>0.569451</td>\n",
       "      <td>-0.270216</td>\n",
       "      <td>0.536317</td>\n",
       "      <td>0.119262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055558</td>\n",
       "      <td>-0.153592</td>\n",
       "      <td>-0.103277</td>\n",
       "      <td>0.180957</td>\n",
       "      <td>0.131901</td>\n",
       "      <td>0.213031</td>\n",
       "      <td>-0.011378</td>\n",
       "      <td>0.155462</td>\n",
       "      <td>0.011923</td>\n",
       "      <td>0.893646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        c_1       c_2       c_3       c_4       c_5       c_6       c_7  \\\n",
       "0  1.144516  1.887148 -1.882622 -0.048405  0.690094  0.020077  0.809921   \n",
       "1 -2.439446  0.340658  0.197613  0.693218  0.979631  0.496533  0.851029   \n",
       "2 -1.309988  1.616213 -0.912996  0.496057 -1.021015 -1.439816 -0.153049   \n",
       "3 -0.766258  1.822620 -1.365426 -2.630953  0.756407  0.424133 -0.724646   \n",
       "4 -0.149392  1.341818 -1.403229 -0.793912 -0.992830 -1.549229  0.569451   \n",
       "\n",
       "        c_8       c_9      c_10  ...      c_72      c_73      c_74      c_75  \\\n",
       "0  0.020945  0.075813 -0.021491  ... -0.362911  0.284236  0.155066  0.010453   \n",
       "1 -0.067310  0.234468  0.077654  ... -0.252177  0.224710  0.132591  0.029336   \n",
       "2  0.416211 -0.023488 -1.677067  ...  0.025349 -0.312739 -0.345905 -0.184987   \n",
       "3 -0.754212 -0.371986  0.397551  ... -0.093322 -0.249120 -0.003015  0.075503   \n",
       "4 -0.270216  0.536317  0.119262  ... -0.055558 -0.153592 -0.103277  0.180957   \n",
       "\n",
       "       c_76      c_77      c_78      c_79      c_80         0  \n",
       "0 -0.049075 -0.322160 -0.088001 -0.347405 -0.073487  0.381687  \n",
       "1 -0.059287 -0.424146 -0.242151  0.453012 -0.540896  0.412094  \n",
       "2  0.010898  0.272235 -0.180548  0.090512  0.021791  0.893646  \n",
       "3 -0.312867 -0.187745  0.148759 -0.154118 -0.506283  0.893646  \n",
       "4  0.131901  0.213031 -0.011378  0.155462  0.011923  0.893646  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_finalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "d4549bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42962 entries, 0 to 42961\n",
      "Data columns (total 81 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   c_1     42962 non-null  float64\n",
      " 1   c_2     42962 non-null  float64\n",
      " 2   c_3     42962 non-null  float64\n",
      " 3   c_4     42962 non-null  float64\n",
      " 4   c_5     42962 non-null  float64\n",
      " 5   c_6     42962 non-null  float64\n",
      " 6   c_7     42962 non-null  float64\n",
      " 7   c_8     42962 non-null  float64\n",
      " 8   c_9     42962 non-null  float64\n",
      " 9   c_10    42962 non-null  float64\n",
      " 10  c_11    42962 non-null  float64\n",
      " 11  c_12    42962 non-null  float64\n",
      " 12  c_13    42962 non-null  float64\n",
      " 13  c_14    42962 non-null  float64\n",
      " 14  c_15    42962 non-null  float64\n",
      " 15  c_16    42962 non-null  float64\n",
      " 16  c_17    42962 non-null  float64\n",
      " 17  c_18    42962 non-null  float64\n",
      " 18  c_19    42962 non-null  float64\n",
      " 19  c_20    42962 non-null  float64\n",
      " 20  c_21    42962 non-null  float64\n",
      " 21  c_22    42962 non-null  float64\n",
      " 22  c_23    42962 non-null  float64\n",
      " 23  c_24    42962 non-null  float64\n",
      " 24  c_25    42962 non-null  float64\n",
      " 25  c_26    42962 non-null  float64\n",
      " 26  c_27    42962 non-null  float64\n",
      " 27  c_28    42962 non-null  float64\n",
      " 28  c_29    42962 non-null  float64\n",
      " 29  c_30    42962 non-null  float64\n",
      " 30  c_31    42962 non-null  float64\n",
      " 31  c_32    42962 non-null  float64\n",
      " 32  c_33    42962 non-null  float64\n",
      " 33  c_34    42962 non-null  float64\n",
      " 34  c_35    42962 non-null  float64\n",
      " 35  c_36    42962 non-null  float64\n",
      " 36  c_37    42962 non-null  float64\n",
      " 37  c_38    42962 non-null  float64\n",
      " 38  c_39    42962 non-null  float64\n",
      " 39  c_40    42962 non-null  float64\n",
      " 40  c_41    42962 non-null  float64\n",
      " 41  c_42    42962 non-null  float64\n",
      " 42  c_43    42962 non-null  float64\n",
      " 43  c_44    42962 non-null  float64\n",
      " 44  c_45    42962 non-null  float64\n",
      " 45  c_46    42962 non-null  float64\n",
      " 46  c_47    42962 non-null  float64\n",
      " 47  c_48    42962 non-null  float64\n",
      " 48  c_49    42962 non-null  float64\n",
      " 49  c_50    42962 non-null  float64\n",
      " 50  c_51    42962 non-null  float64\n",
      " 51  c_52    42962 non-null  float64\n",
      " 52  c_53    42962 non-null  float64\n",
      " 53  c_54    42962 non-null  float64\n",
      " 54  c_55    42962 non-null  float64\n",
      " 55  c_56    42962 non-null  float64\n",
      " 56  c_57    42962 non-null  float64\n",
      " 57  c_58    42962 non-null  float64\n",
      " 58  c_59    42962 non-null  float64\n",
      " 59  c_60    42962 non-null  float64\n",
      " 60  c_61    42962 non-null  float64\n",
      " 61  c_62    42962 non-null  float64\n",
      " 62  c_63    42962 non-null  float64\n",
      " 63  c_64    42962 non-null  float64\n",
      " 64  c_65    42962 non-null  float64\n",
      " 65  c_66    42962 non-null  float64\n",
      " 66  c_67    42962 non-null  float64\n",
      " 67  c_68    42962 non-null  float64\n",
      " 68  c_69    42962 non-null  float64\n",
      " 69  c_70    42962 non-null  float64\n",
      " 70  c_71    42962 non-null  float64\n",
      " 71  c_72    42962 non-null  float64\n",
      " 72  c_73    42962 non-null  float64\n",
      " 73  c_74    42962 non-null  float64\n",
      " 74  c_75    42962 non-null  float64\n",
      " 75  c_76    42962 non-null  float64\n",
      " 76  c_77    42962 non-null  float64\n",
      " 77  c_78    42962 non-null  float64\n",
      " 78  c_79    42962 non-null  float64\n",
      " 79  c_80    42962 non-null  float64\n",
      " 80  0       42962 non-null  float64\n",
      "dtypes: float64(81)\n",
      "memory usage: 26.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_features_finalized.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f2daf9",
   "metadata": {},
   "source": [
    "## Benchmark Model: LinearLearner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "36ddf1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a LinearLearner model\n",
    "from sagemaker import LinearLearner\n",
    "\n",
    "# instantiate LinearLearner\n",
    "# here as the result is highly imbalanced, I adjusted the positve_example_weight_mult to balanced \n",
    "# I also set the criteria to be precision at target recall, to compensate the imbalanced nature of the data set  \n",
    "LinearLearner_1 = LinearLearner (role = role,\n",
    "                               instance_count= 1,\n",
    "                               instance_type = 'ml.m5.2xlarge',\n",
    "                               output_path = output_path,\n",
    "                               predictor_type = 'binary_classifier', \n",
    "                               sagemaker_session = session, \n",
    "                               epochs = 30,\n",
    "                               binary_classifier_model_selection_criteria='precision_at_target_recall',\n",
    "                               target_recall = 0.85, \n",
    "                               positive_example_weight_mult='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "ebbe9afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RecordSet of training data\n",
    "train_labels = train_labels.astype('float32')\n",
    "train_features = train_features_finalized.astype('float32')\n",
    "\n",
    "train_labels_np = train_labels.to_numpy()\n",
    "train_features_np = train_features.to_numpy()\n",
    "\n",
    "formatted_train_data = LinearLearner_1.record_set(train = train_features_np, labels = train_labels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "b0bce459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-08 17:15:45 Starting - Starting the training job...\n",
      "2021-06-08 17:15:47 Starting - Launching requested ML instancesProfilerReport-1623172545: InProgress\n",
      "......\n",
      "2021-06-08 17:17:15 Starting - Preparing the instances for training......\n",
      "2021-06-08 17:18:15 Downloading - Downloading input data...\n",
      "2021-06-08 17:18:44 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:53 INFO 139839868135232] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:53 INFO 139839868135232] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'positive_example_weight_mult': 'balanced', 'feature_dim': '81', 'predictor_type': 'binary_classifier', 'epochs': '30', 'target_recall': '0.85', 'binary_classifier_model_selection_criteria': 'precision_at_target_recall', 'mini_batch_size': '1000'}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:53 INFO 139839868135232] Final configuration: {'mini_batch_size': '1000', 'epochs': '30', 'feature_dim': '81', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'precision_at_target_recall', 'f_beta': '1.0', 'target_recall': '0.85', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': 'balanced', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:53 WARNING 139839868135232] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:53 INFO 139839868135232] Using default worker.\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:53 INFO 139839868135232] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:18:53.636] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 18, \"num_examples\": 1, \"num_bytes\": 372000}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:53 INFO 139839868135232] Create Store: local\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:18:53.696] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 59, \"num_examples\": 11, \"num_bytes\": 4092000}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:53 INFO 139839868135232] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f2ea4359cd0>\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:53 INFO 139839868135232] Scaling model computed with parameters:\n",
      " {'stdev_label': None, 'stdev_weight': \u001b[0m\n",
      "\u001b[34m[1.370195   0.933881   1.0859637  0.98266894 0.79311574 0.67984086\n",
      " 0.6222028  0.5804693  0.5568346  0.52604145 0.48153597 0.47564965\n",
      " 0.4383537  0.44538096 0.5263256  0.4098545  0.44057795 0.4196977\n",
      " 0.40481797 0.3970001  0.3905713  0.37176716 0.38902235 0.4040231\n",
      " 0.35453817 0.3446608  0.3739252  0.35265562 0.33796972 0.32881942\n",
      " 0.33207533 0.32572553 0.34471157 0.3133428  0.33319926 0.31479827\n",
      " 0.3407188  0.32137564 0.31887814 0.29961243 0.34365362 0.3004113\n",
      " 0.31866083 0.35787034 0.31269053 0.29220548 0.33360815 0.28765094\n",
      " 0.33415192 0.317402   0.29990983 0.2802207  0.29533    0.3220272\n",
      " 0.2825223  0.30113307 0.27954623 0.28098255 0.28392693 0.27155364\n",
      " 0.29093915 0.30967227 0.26297304 0.3162528  0.2473041  0.2537619\n",
      " 0.2690534  0.2728689  0.26142636 0.28315738 0.28961012 0.24637839\n",
      " 0.2415551  0.2543277  0.23558365 0.26588637 0.2371737  0.2374952\n",
      " 0.22802418 0.28549975 0.35591173]\u001b[0m\n",
      "\u001b[34m<NDArray 81 @cpu(0)>, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[-7.2550994e-01  7.3213905e-01 -5.0072271e-01  1.3369644e-01\n",
      "  1.3747928e-01 -2.7237233e-02  4.5576487e-02 -1.7476426e-03\n",
      " -2.9101014e-02  8.5650772e-02  2.0313284e-01  5.7401478e-02\n",
      " -1.0599697e-01 -8.1825359e-03  1.1477494e-01 -2.1972459e-02\n",
      "  1.7322725e-01 -6.1230984e-02  2.1739138e-02 -9.0990700e-03\n",
      "  1.7104995e-02  5.5031758e-03  1.2545899e-01 -1.7886519e-01\n",
      " -3.1084884e-03 -1.8323543e-02 -2.9811386e-02 -5.2571803e-02\n",
      "  1.1396676e-02 -2.2758665e-03 -1.8549934e-02  3.9054246e-03\n",
      " -1.1749192e-01  1.1573640e-02 -1.1054998e-01  3.7347064e-03\n",
      "  2.7306935e-02 -8.5831834e-03 -3.1815611e-02 -1.5098377e-03\n",
      "  3.6868919e-03  1.1409157e-03  3.5180636e-02  1.0353057e-01\n",
      "  4.4318903e-02 -4.8420257e-03 -3.7760850e-02 -1.8542001e-02\n",
      " -5.4732710e-02  4.1972917e-02  6.1684288e-02 -4.4452883e-03\n",
      "  6.8109497e-02  1.0732662e-01 -3.6725909e-02 -8.9715421e-04\n",
      "  3.0722721e-02  1.7220681e-03  2.0142457e-02 -6.8433806e-03\n",
      "  3.7513793e-02  8.3310053e-02  3.0305486e-02 -4.1551594e-02\n",
      "  2.3516845e-03  3.5988417e-02  3.0088682e-02 -1.7711887e-04\n",
      "  2.2216950e-02 -6.2600881e-02  1.0994927e-01 -3.7042335e-02\n",
      "  2.2247139e-02 -1.7599491e-02 -5.8616567e-03  4.9659773e-03\n",
      "  1.9634483e-04 -1.5914319e-02 -2.7412749e-03  7.1733452e-02\n",
      "  5.3517967e-01]\u001b[0m\n",
      "\u001b[34m<NDArray 81 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:53 INFO 139839868135232] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:53 INFO 139839868135232] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:53 INFO 139839868135232] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172733.8528874, \"EndTime\": 1623172733.8529184, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12000.0, \"count\": 1, \"min\": 12000, \"max\": 12000}, \"Total Batches Seen\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Max Records Seen Between Resets\": {\"sum\": 11000.0, \"count\": 1, \"min\": 11000, \"max\": 11000}, \"Max Batches Seen Between Resets\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:18:54.840] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 3, \"duration\": 987, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8402996, \"EndTime\": 1623172734.840374, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3315474621000745, \"count\": 1, \"min\": 1.3315474621000745, \"max\": 1.3315474621000745}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8404555, \"EndTime\": 1623172734.84047, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3400364350818452, \"count\": 1, \"min\": 1.3400364350818452, \"max\": 1.3400364350818452}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8405218, \"EndTime\": 1623172734.8405344, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3288021545410156, \"count\": 1, \"min\": 1.3288021545410156, \"max\": 1.3288021545410156}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8405797, \"EndTime\": 1623172734.8405917, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3302122730073476, \"count\": 1, \"min\": 1.3302122730073476, \"max\": 1.3302122730073476}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8406272, \"EndTime\": 1623172734.8406363, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.799389401390439, \"count\": 1, \"min\": 1.799389401390439, \"max\": 1.799389401390439}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8406773, \"EndTime\": 1623172734.8406966, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.8068316999162946, \"count\": 1, \"min\": 1.8068316999162946, \"max\": 1.8068316999162946}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8407311, \"EndTime\": 1623172734.8407407, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.8031193527948288, \"count\": 1, \"min\": 1.8031193527948288, \"max\": 1.8031193527948288}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.840768, \"EndTime\": 1623172734.8407757, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7934884033203125, \"count\": 1, \"min\": 1.7934884033203125, \"max\": 1.7934884033203125}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8408122, \"EndTime\": 1623172734.8408208, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3303069675990513, \"count\": 1, \"min\": 1.3303069675990513, \"max\": 1.3303069675990513}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.840855, \"EndTime\": 1623172734.8408642, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3424482189360119, \"count\": 1, \"min\": 1.3424482189360119, \"max\": 1.3424482189360119}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8408973, \"EndTime\": 1623172734.8409069, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3380414312453497, \"count\": 1, \"min\": 1.3380414312453497, \"max\": 1.3380414312453497}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8409445, \"EndTime\": 1623172734.8409536, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3320183570498512, \"count\": 1, \"min\": 1.3320183570498512, \"max\": 1.3320183570498512}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8409917, \"EndTime\": 1623172734.8410015, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7889956839425223, \"count\": 1, \"min\": 1.7889956839425223, \"max\": 1.7889956839425223}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8410366, \"EndTime\": 1623172734.8410437, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7864532877604167, \"count\": 1, \"min\": 1.7864532877604167, \"max\": 1.7864532877604167}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8410778, \"EndTime\": 1623172734.8410861, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7820270269484748, \"count\": 1, \"min\": 1.7820270269484748, \"max\": 1.7820270269484748}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8411136, \"EndTime\": 1623172734.8411198, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7629174586704799, \"count\": 1, \"min\": 1.7629174586704799, \"max\": 1.7629174586704799}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8411396, \"EndTime\": 1623172734.8411446, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3447593776157925, \"count\": 1, \"min\": 1.3447593776157925, \"max\": 1.3447593776157925}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8411646, \"EndTime\": 1623172734.8411698, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3438343447730654, \"count\": 1, \"min\": 1.3438343447730654, \"max\": 1.3438343447730654}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.841202, \"EndTime\": 1623172734.8412101, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3330838855561755, \"count\": 1, \"min\": 1.3330838855561755, \"max\": 1.3330838855561755}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.841243, \"EndTime\": 1623172734.8412519, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3426279006231399, \"count\": 1, \"min\": 1.3426279006231399, \"max\": 1.3426279006231399}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8412833, \"EndTime\": 1623172734.8412917, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.463957788376581, \"count\": 1, \"min\": 1.463957788376581, \"max\": 1.463957788376581}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.841314, \"EndTime\": 1623172734.8413203, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4499709923153832, \"count\": 1, \"min\": 1.4499709923153832, \"max\": 1.4499709923153832}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.841356, \"EndTime\": 1623172734.841365, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4557730073474702, \"count\": 1, \"min\": 1.4557730073474702, \"max\": 1.4557730073474702}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.841405, \"EndTime\": 1623172734.8414142, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4492352614629835, \"count\": 1, \"min\": 1.4492352614629835, \"max\": 1.4492352614629835}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.841454, \"EndTime\": 1623172734.8414636, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3511390671502976, \"count\": 1, \"min\": 1.3511390671502976, \"max\": 1.3511390671502976}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.841503, \"EndTime\": 1623172734.841513, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3521972104027158, \"count\": 1, \"min\": 1.3521972104027158, \"max\": 1.3521972104027158}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8415494, \"EndTime\": 1623172734.841559, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3468667849586125, \"count\": 1, \"min\": 1.3468667849586125, \"max\": 1.3468667849586125}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.841591, \"EndTime\": 1623172734.8416002, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.355402820405506, \"count\": 1, \"min\": 1.355402820405506, \"max\": 1.355402820405506}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.841623, \"EndTime\": 1623172734.8416283, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.358622023809524, \"count\": 1, \"min\": 1.358622023809524, \"max\": 1.358622023809524}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8416476, \"EndTime\": 1623172734.8416524, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.365116950625465, \"count\": 1, \"min\": 1.365116950625465, \"max\": 1.365116950625465}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8416715, \"EndTime\": 1623172734.8416784, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3632168564569382, \"count\": 1, \"min\": 1.3632168564569382, \"max\": 1.3632168564569382}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.8417094, \"EndTime\": 1623172734.841718, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3710340125674294, \"count\": 1, \"min\": 1.3710340125674294, \"max\": 1.3710340125674294}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:54 INFO 139839868135232] #quality_metric: host=algo-1, epoch=0, train binary_classification_weighted_cross_entropy_objective <loss>=1.3315474621000745\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:54 INFO 139839868135232] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=binary_classification_weighted_cross_entropy_objective, value=1.3288021545410156\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:54 INFO 139839868135232] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:54 INFO 139839868135232] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:54 INFO 139839868135232] Saved checkpoint to \"/tmp/tmpoyvx5onb/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:54 INFO 139839868135232] #progress_metric: host=algo-1, completed 3.3333333333333335 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172733.8531356, \"EndTime\": 1623172734.8520424, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 54962.0, \"count\": 1, \"min\": 54962, \"max\": 54962}, \"Total Batches Seen\": {\"sum\": 55.0, \"count\": 1, \"min\": 55, \"max\": 55}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:54 INFO 139839868135232] #throughput_metric: host=algo-1, train throughput=43005.27899996253 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:18:55.965] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 5, \"duration\": 1113, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9659176, \"EndTime\": 1623172735.965984, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2757369820731026, \"count\": 1, \"min\": 1.2757369820731026, \"max\": 1.2757369820731026}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9660559, \"EndTime\": 1623172735.9660668, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2767523425874256, \"count\": 1, \"min\": 1.2767523425874256, \"max\": 1.2767523425874256}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9660997, \"EndTime\": 1623172735.9661071, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2754825410388766, \"count\": 1, \"min\": 1.2754825410388766, \"max\": 1.2754825410388766}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9661372, \"EndTime\": 1623172735.9661443, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2745119222005208, \"count\": 1, \"min\": 1.2745119222005208, \"max\": 1.2745119222005208}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.966173, \"EndTime\": 1623172735.9661796, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7105114455450148, \"count\": 1, \"min\": 1.7105114455450148, \"max\": 1.7105114455450148}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9662108, \"EndTime\": 1623172735.966218, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7266761343819754, \"count\": 1, \"min\": 1.7266761343819754, \"max\": 1.7266761343819754}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.966248, \"EndTime\": 1623172735.9662547, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7103619936988468, \"count\": 1, \"min\": 1.7103619936988468, \"max\": 1.7103619936988468}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9662812, \"EndTime\": 1623172735.9662876, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7357349490211123, \"count\": 1, \"min\": 1.7357349490211123, \"max\": 1.7357349490211123}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.966314, \"EndTime\": 1623172735.96632, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2738736891973585, \"count\": 1, \"min\": 1.2738736891973585, \"max\": 1.2738736891973585}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9663475, \"EndTime\": 1623172735.966354, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.278644760858445, \"count\": 1, \"min\": 1.278644760858445, \"max\": 1.278644760858445}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9663813, \"EndTime\": 1623172735.966388, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2793521205357143, \"count\": 1, \"min\": 1.2793521205357143, \"max\": 1.2793521205357143}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9664152, \"EndTime\": 1623172735.9664216, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.278540525890532, \"count\": 1, \"min\": 1.278540525890532, \"max\": 1.278540525890532}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.966453, \"EndTime\": 1623172735.9664605, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.692237069266183, \"count\": 1, \"min\": 1.692237069266183, \"max\": 1.692237069266183}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9664886, \"EndTime\": 1623172735.9664955, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7282389468238468, \"count\": 1, \"min\": 1.7282389468238468, \"max\": 1.7282389468238468}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9665227, \"EndTime\": 1623172735.9665296, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6874378226143973, \"count\": 1, \"min\": 1.6874378226143973, \"max\": 1.6874378226143973}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.966557, \"EndTime\": 1623172735.966564, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.730140404110863, \"count\": 1, \"min\": 1.730140404110863, \"max\": 1.730140404110863}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9665954, \"EndTime\": 1623172735.9666026, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3073584740048363, \"count\": 1, \"min\": 1.3073584740048363, \"max\": 1.3073584740048363}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9666348, \"EndTime\": 1623172735.9666421, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3081583862304687, \"count\": 1, \"min\": 1.3081583862304687, \"max\": 1.3081583862304687}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9666739, \"EndTime\": 1623172735.9666812, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3080772734142485, \"count\": 1, \"min\": 1.3080772734142485, \"max\": 1.3080772734142485}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9667137, \"EndTime\": 1623172735.9667208, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.308704352969215, \"count\": 1, \"min\": 1.308704352969215, \"max\": 1.308704352969215}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.966753, \"EndTime\": 1623172735.9667602, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.50229202125186, \"count\": 1, \"min\": 1.50229202125186, \"max\": 1.50229202125186}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9667928, \"EndTime\": 1623172735.9668, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5126903061639696, \"count\": 1, \"min\": 1.5126903061639696, \"max\": 1.5126903061639696}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9668486, \"EndTime\": 1623172735.9668574, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5006426914760045, \"count\": 1, \"min\": 1.5006426914760045, \"max\": 1.5006426914760045}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9668887, \"EndTime\": 1623172735.9668958, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5091283075241815, \"count\": 1, \"min\": 1.5091283075241815, \"max\": 1.5091283075241815}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9669282, \"EndTime\": 1623172735.9669356, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3452618582589286, \"count\": 1, \"min\": 1.3452618582589286, \"max\": 1.3452618582589286}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9669673, \"EndTime\": 1623172735.9669755, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3451363045828684, \"count\": 1, \"min\": 1.3451363045828684, \"max\": 1.3451363045828684}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9670076, \"EndTime\": 1623172735.9670165, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3445921311151414, \"count\": 1, \"min\": 1.3445921311151414, \"max\": 1.3445921311151414}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9670506, \"EndTime\": 1623172735.967059, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3454642566499255, \"count\": 1, \"min\": 1.3454642566499255, \"max\": 1.3454642566499255}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9670951, \"EndTime\": 1623172735.9671035, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.418489276704334, \"count\": 1, \"min\": 1.418489276704334, \"max\": 1.418489276704334}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9671385, \"EndTime\": 1623172735.9671466, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4130035211472285, \"count\": 1, \"min\": 1.4130035211472285, \"max\": 1.4130035211472285}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.967179, \"EndTime\": 1623172735.9671872, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4162444428943453, \"count\": 1, \"min\": 1.4162444428943453, \"max\": 1.4162444428943453}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9672208, \"EndTime\": 1623172735.9672284, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4172528206961497, \"count\": 1, \"min\": 1.4172528206961497, \"max\": 1.4172528206961497}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:55 INFO 139839868135232] #quality_metric: host=algo-1, epoch=1, train binary_classification_weighted_cross_entropy_objective <loss>=1.2757369820731026\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:55 INFO 139839868135232] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=binary_classification_weighted_cross_entropy_objective, value=1.2738736891973585\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:55 INFO 139839868135232] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:55 INFO 139839868135232] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:55 INFO 139839868135232] Saved checkpoint to \"/tmp/tmpm28d05ah/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:55 INFO 139839868135232] #progress_metric: host=algo-1, completed 6.666666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172734.852247, \"EndTime\": 1623172735.978535, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 97924.0, \"count\": 1, \"min\": 97924, \"max\": 97924}, \"Total Batches Seen\": {\"sum\": 98.0, \"count\": 1, \"min\": 98, \"max\": 98}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:55 INFO 139839868135232] #throughput_metric: host=algo-1, train throughput=38140.818859371735 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:18:56.951] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 7, \"duration\": 972, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9518764, \"EndTime\": 1623172736.9519377, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.265753137497675, \"count\": 1, \"min\": 1.265753137497675, \"max\": 1.265753137497675}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9520028, \"EndTime\": 1623172736.952016, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2662496933710008, \"count\": 1, \"min\": 1.2662496933710008, \"max\": 1.2662496933710008}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.952063, \"EndTime\": 1623172736.9520738, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2658670058477492, \"count\": 1, \"min\": 1.2658670058477492, \"max\": 1.2658670058477492}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9521186, \"EndTime\": 1623172736.95213, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2654092944917226, \"count\": 1, \"min\": 1.2654092944917226, \"max\": 1.2654092944917226}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9521716, \"EndTime\": 1623172736.9521806, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.674491440545945, \"count\": 1, \"min\": 1.674491440545945, \"max\": 1.674491440545945}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9522276, \"EndTime\": 1623172736.9522383, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7152276436941964, \"count\": 1, \"min\": 1.7152276436941964, \"max\": 1.7152276436941964}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9522893, \"EndTime\": 1623172736.9522994, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6739119800385975, \"count\": 1, \"min\": 1.6739119800385975, \"max\": 1.6739119800385975}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9523325, \"EndTime\": 1623172736.95234, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.719454549153646, \"count\": 1, \"min\": 1.719454549153646, \"max\": 1.719454549153646}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9523664, \"EndTime\": 1623172736.952374, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2645331057593936, \"count\": 1, \"min\": 1.2645331057593936, \"max\": 1.2645331057593936}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9524095, \"EndTime\": 1623172736.9524183, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2675901343936011, \"count\": 1, \"min\": 1.2675901343936011, \"max\": 1.2675901343936011}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9524548, \"EndTime\": 1623172736.9524634, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2672955264136905, \"count\": 1, \"min\": 1.2672955264136905, \"max\": 1.2672955264136905}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9525, \"EndTime\": 1623172736.9525099, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2685147370837984, \"count\": 1, \"min\": 1.2685147370837984, \"max\": 1.2685147370837984}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9525464, \"EndTime\": 1623172736.952556, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6623862987699962, \"count\": 1, \"min\": 1.6623862987699962, \"max\": 1.6623862987699962}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9525917, \"EndTime\": 1623172736.9526014, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.704162618001302, \"count\": 1, \"min\": 1.704162618001302, \"max\": 1.704162618001302}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9526331, \"EndTime\": 1623172736.9526398, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6634776495070684, \"count\": 1, \"min\": 1.6634776495070684, \"max\": 1.6634776495070684}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9526694, \"EndTime\": 1623172736.952676, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7059622555687315, \"count\": 1, \"min\": 1.7059622555687315, \"max\": 1.7059622555687315}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9527118, \"EndTime\": 1623172736.952721, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3074884672619047, \"count\": 1, \"min\": 1.3074884672619047, \"max\": 1.3074884672619047}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9527593, \"EndTime\": 1623172736.9527688, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.309210197812035, \"count\": 1, \"min\": 1.309210197812035, \"max\": 1.309210197812035}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9528036, \"EndTime\": 1623172736.9528124, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.30757762218657, \"count\": 1, \"min\": 1.30757762218657, \"max\": 1.30757762218657}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9528444, \"EndTime\": 1623172736.9528532, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3091949608212425, \"count\": 1, \"min\": 1.3091949608212425, \"max\": 1.3091949608212425}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.952881, \"EndTime\": 1623172736.9528894, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4743175557454427, \"count\": 1, \"min\": 1.4743175557454427, \"max\": 1.4743175557454427}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.952924, \"EndTime\": 1623172736.9529333, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.493096189953032, \"count\": 1, \"min\": 1.493096189953032, \"max\": 1.493096189953032}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.952965, \"EndTime\": 1623172736.9529743, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.478425266810826, \"count\": 1, \"min\": 1.478425266810826, \"max\": 1.478425266810826}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9530125, \"EndTime\": 1623172736.9530191, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5016366388230096, \"count\": 1, \"min\": 1.5016366388230096, \"max\": 1.5016366388230096}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.953048, \"EndTime\": 1623172736.9530542, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3444326389857701, \"count\": 1, \"min\": 1.3444326389857701, \"max\": 1.3444326389857701}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.953078, \"EndTime\": 1623172736.9530833, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.344646969749814, \"count\": 1, \"min\": 1.344646969749814, \"max\": 1.344646969749814}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.953104, \"EndTime\": 1623172736.9531095, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3442381402878534, \"count\": 1, \"min\": 1.3442381402878534, \"max\": 1.3442381402878534}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9531288, \"EndTime\": 1623172736.953134, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3450220772879464, \"count\": 1, \"min\": 1.3450220772879464, \"max\": 1.3450220772879464}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9531531, \"EndTime\": 1623172736.9531581, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.429152840750558, \"count\": 1, \"min\": 1.429152840750558, \"max\": 1.429152840750558}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.953178, \"EndTime\": 1623172736.9531827, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4466939755394346, \"count\": 1, \"min\": 1.4466939755394346, \"max\": 1.4466939755394346}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9532018, \"EndTime\": 1623172736.9532068, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4334513215564546, \"count\": 1, \"min\": 1.4334513215564546, \"max\": 1.4334513215564546}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9532406, \"EndTime\": 1623172736.9532497, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4447804216657365, \"count\": 1, \"min\": 1.4447804216657365, \"max\": 1.4447804216657365}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:56 INFO 139839868135232] #quality_metric: host=algo-1, epoch=2, train binary_classification_weighted_cross_entropy_objective <loss>=1.265753137497675\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:56 INFO 139839868135232] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=binary_classification_weighted_cross_entropy_objective, value=1.2645331057593936\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:56 INFO 139839868135232] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:56 INFO 139839868135232] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:56 INFO 139839868135232] Saved checkpoint to \"/tmp/tmpf11qskoz/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:56 INFO 139839868135232] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172735.9792297, \"EndTime\": 1623172736.9613414, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 140886.0, \"count\": 1, \"min\": 140886, \"max\": 140886}, \"Total Batches Seen\": {\"sum\": 141.0, \"count\": 1, \"min\": 141, \"max\": 141}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:56 INFO 139839868135232] #throughput_metric: host=algo-1, train throughput=43739.8114259277 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:18:57.859] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 9, \"duration\": 898, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8600206, \"EndTime\": 1623172737.8600779, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2618780851818265, \"count\": 1, \"min\": 1.2618780851818265, \"max\": 1.2618780851818265}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8601456, \"EndTime\": 1623172737.8601587, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2629794049944196, \"count\": 1, \"min\": 1.2629794049944196, \"max\": 1.2629794049944196}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8601983, \"EndTime\": 1623172737.8602083, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2619744713192895, \"count\": 1, \"min\": 1.2619744713192895, \"max\": 1.2619744713192895}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8602476, \"EndTime\": 1623172737.8602564, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2625242469424294, \"count\": 1, \"min\": 1.2625242469424294, \"max\": 1.2625242469424294}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8602955, \"EndTime\": 1623172737.860306, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6546808064778646, \"count\": 1, \"min\": 1.6546808064778646, \"max\": 1.6546808064778646}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8603466, \"EndTime\": 1623172737.8603563, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.714390625, \"count\": 1, \"min\": 1.714390625, \"max\": 1.714390625}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8603966, \"EndTime\": 1623172737.8604057, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6534643002464657, \"count\": 1, \"min\": 1.6534643002464657, \"max\": 1.6534643002464657}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.860435, \"EndTime\": 1623172737.8604424, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7170955142066593, \"count\": 1, \"min\": 1.7170955142066593, \"max\": 1.7170955142066593}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8604712, \"EndTime\": 1623172737.8604796, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2610069216773623, \"count\": 1, \"min\": 1.2610069216773623, \"max\": 1.2610069216773623}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8605118, \"EndTime\": 1623172737.8605187, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2639637145996094, \"count\": 1, \"min\": 1.2639637145996094, \"max\": 1.2639637145996094}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8605516, \"EndTime\": 1623172737.860558, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2625642627534412, \"count\": 1, \"min\": 1.2625642627534412, \"max\": 1.2625642627534412}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.860591, \"EndTime\": 1623172737.8605995, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2647452988397507, \"count\": 1, \"min\": 1.2647452988397507, \"max\": 1.2647452988397507}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.860637, \"EndTime\": 1623172737.8606465, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6434860374813989, \"count\": 1, \"min\": 1.6434860374813989, \"max\": 1.6434860374813989}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.860686, \"EndTime\": 1623172737.8606932, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7029236479259673, \"count\": 1, \"min\": 1.7029236479259673, \"max\": 1.7029236479259673}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8607159, \"EndTime\": 1623172737.860722, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6442784627278646, \"count\": 1, \"min\": 1.6442784627278646, \"max\": 1.6442784627278646}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8607576, \"EndTime\": 1623172737.8607678, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7042654055640811, \"count\": 1, \"min\": 1.7042654055640811, \"max\": 1.7042654055640811}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.860808, \"EndTime\": 1623172737.8608177, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.306744409470331, \"count\": 1, \"min\": 1.306744409470331, \"max\": 1.306744409470331}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8608477, \"EndTime\": 1623172737.860855, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3090935625348772, \"count\": 1, \"min\": 1.3090935625348772, \"max\": 1.3090935625348772}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8608863, \"EndTime\": 1623172737.8608937, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.30678564453125, \"count\": 1, \"min\": 1.30678564453125, \"max\": 1.30678564453125}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8609247, \"EndTime\": 1623172737.860933, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3091061256045387, \"count\": 1, \"min\": 1.3091061256045387, \"max\": 1.3091061256045387}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8609672, \"EndTime\": 1623172737.8609753, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4599390084402901, \"count\": 1, \"min\": 1.4599390084402901, \"max\": 1.4599390084402901}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8610094, \"EndTime\": 1623172737.8610163, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4855217924572173, \"count\": 1, \"min\": 1.4855217924572173, \"max\": 1.4855217924572173}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8610494, \"EndTime\": 1623172737.8610582, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4598741440545946, \"count\": 1, \"min\": 1.4598741440545946, \"max\": 1.4598741440545946}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.861091, \"EndTime\": 1623172737.8611, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.486354516892206, \"count\": 1, \"min\": 1.486354516892206, \"max\": 1.486354516892206}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.861138, \"EndTime\": 1623172737.861148, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3442741800944011, \"count\": 1, \"min\": 1.3442741800944011, \"max\": 1.3442741800944011}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8611834, \"EndTime\": 1623172737.861193, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3446797674269904, \"count\": 1, \"min\": 1.3446797674269904, \"max\": 1.3446797674269904}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8612318, \"EndTime\": 1623172737.8612418, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3440684393019904, \"count\": 1, \"min\": 1.3440684393019904, \"max\": 1.3440684393019904}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.8612776, \"EndTime\": 1623172737.8612874, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3450830557686941, \"count\": 1, \"min\": 1.3450830557686941, \"max\": 1.3450830557686941}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.861325, \"EndTime\": 1623172737.861335, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3965516938709077, \"count\": 1, \"min\": 1.3965516938709077, \"max\": 1.3965516938709077}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.86137, \"EndTime\": 1623172737.8613791, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4228068077450706, \"count\": 1, \"min\": 1.4228068077450706, \"max\": 1.4228068077450706}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.861414, \"EndTime\": 1623172737.8614237, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.399212161109561, \"count\": 1, \"min\": 1.399212161109561, \"max\": 1.399212161109561}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.861457, \"EndTime\": 1623172737.8614666, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4183661847795759, \"count\": 1, \"min\": 1.4183661847795759, \"max\": 1.4183661847795759}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:57 INFO 139839868135232] #quality_metric: host=algo-1, epoch=3, train binary_classification_weighted_cross_entropy_objective <loss>=1.2618780851818265\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:57 INFO 139839868135232] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=binary_classification_weighted_cross_entropy_objective, value=1.2610069216773623\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:57 INFO 139839868135232] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:57 INFO 139839868135232] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:57 INFO 139839868135232] Saved checkpoint to \"/tmp/tmpq1ic6er0/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:57 INFO 139839868135232] #progress_metric: host=algo-1, completed 13.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172736.9615512, \"EndTime\": 1623172737.8693635, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 183848.0, \"count\": 1, \"min\": 183848, \"max\": 183848}, \"Total Batches Seen\": {\"sum\": 184.0, \"count\": 1, \"min\": 184, \"max\": 184}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:57 INFO 139839868135232] #throughput_metric: host=algo-1, train throughput=47320.10993864257 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:18:58.720] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 11, \"duration\": 851, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7207508, \"EndTime\": 1623172738.7208107, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2597503284272693, \"count\": 1, \"min\": 1.2597503284272693, \"max\": 1.2597503284272693}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7208767, \"EndTime\": 1623172738.7208905, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2616957106817337, \"count\": 1, \"min\": 1.2616957106817337, \"max\": 1.2616957106817337}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7209265, \"EndTime\": 1623172738.7209358, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2598320733933221, \"count\": 1, \"min\": 1.2598320733933221, \"max\": 1.2598320733933221}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7209733, \"EndTime\": 1623172738.72098, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2613695824032738, \"count\": 1, \"min\": 1.2613695824032738, \"max\": 1.2613695824032738}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7210083, \"EndTime\": 1623172738.7210145, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6358466041201636, \"count\": 1, \"min\": 1.6358466041201636, \"max\": 1.6358466041201636}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7210376, \"EndTime\": 1623172738.721043, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7148964524042039, \"count\": 1, \"min\": 1.7148964524042039, \"max\": 1.7148964524042039}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7210724, \"EndTime\": 1623172738.7210805, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.63517577398391, \"count\": 1, \"min\": 1.63517577398391, \"max\": 1.63517577398391}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7211134, \"EndTime\": 1623172738.721121, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7166793038504464, \"count\": 1, \"min\": 1.7166793038504464, \"max\": 1.7166793038504464}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7211554, \"EndTime\": 1623172738.7211647, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.259102305094401, \"count\": 1, \"min\": 1.259102305094401, \"max\": 1.259102305094401}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7211955, \"EndTime\": 1623172738.7212014, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2624456394740513, \"count\": 1, \"min\": 1.2624456394740513, \"max\": 1.2624456394740513}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7212265, \"EndTime\": 1623172738.7212353, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.260096166701544, \"count\": 1, \"min\": 1.260096166701544, \"max\": 1.260096166701544}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7212715, \"EndTime\": 1623172738.7212806, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2630109122140067, \"count\": 1, \"min\": 1.2630109122140067, \"max\": 1.2630109122140067}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7213151, \"EndTime\": 1623172738.721324, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6262953055245535, \"count\": 1, \"min\": 1.6262953055245535, \"max\": 1.6262953055245535}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7213578, \"EndTime\": 1623172738.7213674, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.702169962565104, \"count\": 1, \"min\": 1.702169962565104, \"max\": 1.702169962565104}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.721399, \"EndTime\": 1623172738.721408, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6268839358375187, \"count\": 1, \"min\": 1.6268839358375187, \"max\": 1.6268839358375187}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7214417, \"EndTime\": 1623172738.721448, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.702987022763207, \"count\": 1, \"min\": 1.702987022763207, \"max\": 1.702987022763207}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7214687, \"EndTime\": 1623172738.7214737, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3060906328473771, \"count\": 1, \"min\": 1.3060906328473771, \"max\": 1.3060906328473771}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7214987, \"EndTime\": 1623172738.721507, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3091215762183779, \"count\": 1, \"min\": 1.3091215762183779, \"max\": 1.3091215762183779}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7215452, \"EndTime\": 1623172738.7215538, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3061261407761346, \"count\": 1, \"min\": 1.3061261407761346, \"max\": 1.3061261407761346}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.721582, \"EndTime\": 1623172738.72159, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.309132781982422, \"count\": 1, \"min\": 1.309132781982422, \"max\": 1.309132781982422}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7216222, \"EndTime\": 1623172738.7216291, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4512388567243304, \"count\": 1, \"min\": 1.4512388567243304, \"max\": 1.4512388567243304}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7216654, \"EndTime\": 1623172738.7216744, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.487342989966983, \"count\": 1, \"min\": 1.487342989966983, \"max\": 1.487342989966983}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7217107, \"EndTime\": 1623172738.7217202, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4515349019368489, \"count\": 1, \"min\": 1.4515349019368489, \"max\": 1.4515349019368489}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7217488, \"EndTime\": 1623172738.721755, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4883307189941406, \"count\": 1, \"min\": 1.4883307189941406, \"max\": 1.4883307189941406}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7217767, \"EndTime\": 1623172738.7217834, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3441927650088357, \"count\": 1, \"min\": 1.3441927650088357, \"max\": 1.3441927650088357}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.721813, \"EndTime\": 1623172738.721819, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.344772696358817, \"count\": 1, \"min\": 1.344772696358817, \"max\": 1.344772696358817}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.721838, \"EndTime\": 1623172738.7218435, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3439675787062872, \"count\": 1, \"min\": 1.3439675787062872, \"max\": 1.3439675787062872}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7218623, \"EndTime\": 1623172738.7218673, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3451774437313988, \"count\": 1, \"min\": 1.3451774437313988, \"max\": 1.3451774437313988}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7218866, \"EndTime\": 1623172738.7218916, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3914740658714657, \"count\": 1, \"min\": 1.3914740658714657, \"max\": 1.3914740658714657}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7219107, \"EndTime\": 1623172738.7219157, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4109017086937314, \"count\": 1, \"min\": 1.4109017086937314, \"max\": 1.4109017086937314}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7219346, \"EndTime\": 1623172738.7219396, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3914310418991815, \"count\": 1, \"min\": 1.3914310418991815, \"max\": 1.3914310418991815}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7219582, \"EndTime\": 1623172738.721963, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4105941162109374, \"count\": 1, \"min\": 1.4105941162109374, \"max\": 1.4105941162109374}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:58 INFO 139839868135232] #quality_metric: host=algo-1, epoch=4, train binary_classification_weighted_cross_entropy_objective <loss>=1.2597503284272693\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:58 INFO 139839868135232] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=binary_classification_weighted_cross_entropy_objective, value=1.259102305094401\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:58 INFO 139839868135232] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:58 INFO 139839868135232] Saving model for epoch: 4\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:58 INFO 139839868135232] Saved checkpoint to \"/tmp/tmpa49upuk8/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:58 INFO 139839868135232] #progress_metric: host=algo-1, completed 16.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172737.869565, \"EndTime\": 1623172738.7297645, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 226810.0, \"count\": 1, \"min\": 226810, \"max\": 226810}, \"Total Batches Seen\": {\"sum\": 227.0, \"count\": 1, \"min\": 227, \"max\": 227}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:58 INFO 139839868135232] #throughput_metric: host=algo-1, train throughput=49938.94345512593 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:18:59.765] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 13, \"duration\": 1034, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.765249, \"EndTime\": 1623172739.7653005, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.258294443766276, \"count\": 1, \"min\": 1.258294443766276, \"max\": 1.258294443766276}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7653637, \"EndTime\": 1623172739.7653778, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2608887895856584, \"count\": 1, \"min\": 1.2608887895856584, \"max\": 1.2608887895856584}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7654254, \"EndTime\": 1623172739.7654371, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2583685840425036, \"count\": 1, \"min\": 1.2583685840425036, \"max\": 1.2583685840425036}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7654781, \"EndTime\": 1623172739.765486, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2606224931989398, \"count\": 1, \"min\": 1.2606224931989398, \"max\": 1.2606224931989398}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7655108, \"EndTime\": 1623172739.7655187, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6173575061616443, \"count\": 1, \"min\": 1.6173575061616443, \"max\": 1.6173575061616443}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7655613, \"EndTime\": 1623172739.7655692, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7105184616815476, \"count\": 1, \"min\": 1.7105184616815476, \"max\": 1.7105184616815476}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.765609, \"EndTime\": 1623172739.7656198, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6169693952287947, \"count\": 1, \"min\": 1.6169693952287947, \"max\": 1.6169693952287947}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7656646, \"EndTime\": 1623172739.7656713, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7118521292550224, \"count\": 1, \"min\": 1.7118521292550224, \"max\": 1.7118521292550224}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.765693, \"EndTime\": 1623172739.765701, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2578019743419828, \"count\": 1, \"min\": 1.2578019743419828, \"max\": 1.2578019743419828}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7657273, \"EndTime\": 1623172739.7657347, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2614840334937687, \"count\": 1, \"min\": 1.2614840334937687, \"max\": 1.2614840334937687}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.765768, \"EndTime\": 1623172739.7657764, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2584960588727678, \"count\": 1, \"min\": 1.2584960588727678, \"max\": 1.2584960588727678}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7658105, \"EndTime\": 1623172739.7658188, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.261885721842448, \"count\": 1, \"min\": 1.261885721842448, \"max\": 1.261885721842448}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7658525, \"EndTime\": 1623172739.765859, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6092219528924852, \"count\": 1, \"min\": 1.6092219528924852, \"max\": 1.6092219528924852}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7658887, \"EndTime\": 1623172739.7658968, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6976062607538132, \"count\": 1, \"min\": 1.6976062607538132, \"max\": 1.6976062607538132}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7659202, \"EndTime\": 1623172739.7659287, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.609706795828683, \"count\": 1, \"min\": 1.609706795828683, \"max\": 1.609706795828683}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7659638, \"EndTime\": 1623172739.7659729, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6981583629789807, \"count\": 1, \"min\": 1.6981583629789807, \"max\": 1.6981583629789807}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.765999, \"EndTime\": 1623172739.766005, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3054373910086496, \"count\": 1, \"min\": 1.3054373910086496, \"max\": 1.3054373910086496}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.766026, \"EndTime\": 1623172739.766031, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3089824741908482, \"count\": 1, \"min\": 1.3089824741908482, \"max\": 1.3089824741908482}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.766065, \"EndTime\": 1623172739.7660732, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3054644499279204, \"count\": 1, \"min\": 1.3054644499279204, \"max\": 1.3054644499279204}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7661064, \"EndTime\": 1623172739.7661152, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3089905395507813, \"count\": 1, \"min\": 1.3089905395507813, \"max\": 1.3089905395507813}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7661486, \"EndTime\": 1623172739.7661576, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4429270440964472, \"count\": 1, \"min\": 1.4429270440964472, \"max\": 1.4429270440964472}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7661922, \"EndTime\": 1623172739.7662015, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.485157210577102, \"count\": 1, \"min\": 1.485157210577102, \"max\": 1.485157210577102}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7662342, \"EndTime\": 1623172739.7662437, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4430187174479168, \"count\": 1, \"min\": 1.4430187174479168, \"max\": 1.4430187174479168}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7662766, \"EndTime\": 1623172739.7662857, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.48577346656436, \"count\": 1, \"min\": 1.48577346656436, \"max\": 1.48577346656436}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.766319, \"EndTime\": 1623172739.7663283, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.34412157476516, \"count\": 1, \"min\": 1.34412157476516, \"max\": 1.34412157476516}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7663589, \"EndTime\": 1623172739.7663674, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3448065185546876, \"count\": 1, \"min\": 1.3448065185546876, \"max\": 1.3448065185546876}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7664027, \"EndTime\": 1623172739.7664123, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3438904709588915, \"count\": 1, \"min\": 1.3438904709588915, \"max\": 1.3438904709588915}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.766444, \"EndTime\": 1623172739.7664533, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3451830110095797, \"count\": 1, \"min\": 1.3451830110095797, \"max\": 1.3451830110095797}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7664852, \"EndTime\": 1623172739.7664938, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3889527544294085, \"count\": 1, \"min\": 1.3889527544294085, \"max\": 1.3889527544294085}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7665284, \"EndTime\": 1623172739.7665372, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4085464274088542, \"count\": 1, \"min\": 1.4085464274088542, \"max\": 1.4085464274088542}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7665696, \"EndTime\": 1623172739.7665787, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3891427176339286, \"count\": 1, \"min\": 1.3891427176339286, \"max\": 1.3891427176339286}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7666137, \"EndTime\": 1623172739.766623, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4092693365187872, \"count\": 1, \"min\": 1.4092693365187872, \"max\": 1.4092693365187872}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:59 INFO 139839868135232] #quality_metric: host=algo-1, epoch=5, train binary_classification_weighted_cross_entropy_objective <loss>=1.258294443766276\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:59 INFO 139839868135232] #early_stopping_criteria_metric: host=algo-1, epoch=5, criteria=binary_classification_weighted_cross_entropy_objective, value=1.2578019743419828\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:59 INFO 139839868135232] Epoch 5: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:59 INFO 139839868135232] Saving model for epoch: 5\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:59 INFO 139839868135232] Saved checkpoint to \"/tmp/tmplgnjwkgh/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:59 INFO 139839868135232] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172738.7303088, \"EndTime\": 1623172739.7752814, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 269772.0, \"count\": 1, \"min\": 269772, \"max\": 269772}, \"Total Batches Seen\": {\"sum\": 270.0, \"count\": 1, \"min\": 270, \"max\": 270}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:18:59 INFO 139839868135232] #throughput_metric: host=algo-1, train throughput=41109.09809180324 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:19:00.640] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 15, \"duration\": 865, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6406498, \"EndTime\": 1623172740.6407118, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2571553504580544, \"count\": 1, \"min\": 1.2571553504580544, \"max\": 1.2571553504580544}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6407835, \"EndTime\": 1623172740.6407967, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.260514376685733, \"count\": 1, \"min\": 1.260514376685733, \"max\": 1.260514376685733}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6408377, \"EndTime\": 1623172740.6408467, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.257224403018043, \"count\": 1, \"min\": 1.257224403018043, \"max\": 1.257224403018043}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6408827, \"EndTime\": 1623172740.6408916, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2602873796735492, \"count\": 1, \"min\": 1.2602873796735492, \"max\": 1.2602873796735492}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6409256, \"EndTime\": 1623172740.6409345, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5999225783575148, \"count\": 1, \"min\": 1.5999225783575148, \"max\": 1.5999225783575148}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6409662, \"EndTime\": 1623172740.640974, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7103995419456846, \"count\": 1, \"min\": 1.7103995419456846, \"max\": 1.7103995419456846}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6410055, \"EndTime\": 1623172740.6410143, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.599707545689174, \"count\": 1, \"min\": 1.599707545689174, \"max\": 1.599707545689174}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6410468, \"EndTime\": 1623172740.6410558, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7114644368489584, \"count\": 1, \"min\": 1.7114644368489584, \"max\": 1.7114644368489584}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6410954, \"EndTime\": 1623172740.6411042, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2567794291178385, \"count\": 1, \"min\": 1.2567794291178385, \"max\": 1.2567794291178385}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.641138, \"EndTime\": 1623172740.641147, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2610079171316964, \"count\": 1, \"min\": 1.2610079171316964, \"max\": 1.2610079171316964}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6411812, \"EndTime\": 1623172740.6411898, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2572959783644904, \"count\": 1, \"min\": 1.2572959783644904, \"max\": 1.2572959783644904}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6412182, \"EndTime\": 1623172740.6412268, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2612989516485305, \"count\": 1, \"min\": 1.2612989516485305, \"max\": 1.2612989516485305}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.641261, \"EndTime\": 1623172740.6412702, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5930078241257442, \"count\": 1, \"min\": 1.5930078241257442, \"max\": 1.5930078241257442}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.641303, \"EndTime\": 1623172740.6413116, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6972877429780506, \"count\": 1, \"min\": 1.6972877429780506, \"max\": 1.6972877429780506}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6413412, \"EndTime\": 1623172740.64135, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5934226321265812, \"count\": 1, \"min\": 1.5934226321265812, \"max\": 1.5934226321265812}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6413786, \"EndTime\": 1623172740.6413872, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6977002912248884, \"count\": 1, \"min\": 1.6977002912248884, \"max\": 1.6977002912248884}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6414187, \"EndTime\": 1623172740.6414278, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3047998613630023, \"count\": 1, \"min\": 1.3047998613630023, \"max\": 1.3047998613630023}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6414616, \"EndTime\": 1623172740.6414702, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3090006481352308, \"count\": 1, \"min\": 1.3090006481352308, \"max\": 1.3090006481352308}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6415002, \"EndTime\": 1623172740.6415088, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.304821261451358, \"count\": 1, \"min\": 1.304821261451358, \"max\": 1.304821261451358}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6415348, \"EndTime\": 1623172740.6415436, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3090069914318265, \"count\": 1, \"min\": 1.3090069914318265, \"max\": 1.3090069914318265}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6415694, \"EndTime\": 1623172740.6415777, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4351293538411458, \"count\": 1, \"min\": 1.4351293538411458, \"max\": 1.4351293538411458}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6416075, \"EndTime\": 1623172740.6416163, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4850612298874628, \"count\": 1, \"min\": 1.4850612298874628, \"max\": 1.4850612298874628}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6416504, \"EndTime\": 1623172740.6416595, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.435093979608445, \"count\": 1, \"min\": 1.435093979608445, \"max\": 1.435093979608445}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6416886, \"EndTime\": 1623172740.641697, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4855237949916296, \"count\": 1, \"min\": 1.4855237949916296, \"max\": 1.4855237949916296}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6417246, \"EndTime\": 1623172740.6417315, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3440431329636346, \"count\": 1, \"min\": 1.3440431329636346, \"max\": 1.3440431329636346}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6417584, \"EndTime\": 1623172740.6417642, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3448549586704799, \"count\": 1, \"min\": 1.3448549586704799, \"max\": 1.3448549586704799}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6417882, \"EndTime\": 1623172740.641797, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3438201366606213, \"count\": 1, \"min\": 1.3438201366606213, \"max\": 1.3438201366606213}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6418307, \"EndTime\": 1623172740.6418393, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3452066010974701, \"count\": 1, \"min\": 1.3452066010974701, \"max\": 1.3452066010974701}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6418707, \"EndTime\": 1623172740.6418796, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3868201933361235, \"count\": 1, \"min\": 1.3868201933361235, \"max\": 1.3868201933361235}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.64191, \"EndTime\": 1623172740.6419184, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.408904805501302, \"count\": 1, \"min\": 1.408904805501302, \"max\": 1.408904805501302}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.641955, \"EndTime\": 1623172740.641964, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3869866521926153, \"count\": 1, \"min\": 1.3869866521926153, \"max\": 1.3869866521926153}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6420004, \"EndTime\": 1623172740.6420083, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.409896949404762, \"count\": 1, \"min\": 1.409896949404762, \"max\": 1.409896949404762}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:00 INFO 139839868135232] #quality_metric: host=algo-1, epoch=6, train binary_classification_weighted_cross_entropy_objective <loss>=1.2571553504580544\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:00 INFO 139839868135232] #early_stopping_criteria_metric: host=algo-1, epoch=6, criteria=binary_classification_weighted_cross_entropy_objective, value=1.2567794291178385\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:00 INFO 139839868135232] Saving model for epoch: 6\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:00 INFO 139839868135232] Saved checkpoint to \"/tmp/tmpbcd0tan7/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:00 INFO 139839868135232] #progress_metric: host=algo-1, completed 23.333333333333332 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172739.7754948, \"EndTime\": 1623172740.6494336, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 312734.0, \"count\": 1, \"min\": 312734, \"max\": 312734}, \"Total Batches Seen\": {\"sum\": 313.0, \"count\": 1, \"min\": 313, \"max\": 313}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:00 INFO 139839868135232] #throughput_metric: host=algo-1, train throughput=49153.13516890043 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:19:01.609] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 17, \"duration\": 959, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.609214, \"EndTime\": 1623172741.6092777, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2561972292945498, \"count\": 1, \"min\": 1.2561972292945498, \"max\": 1.2561972292945498}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6093478, \"EndTime\": 1623172741.6093614, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2601068667457218, \"count\": 1, \"min\": 1.2601068667457218, \"max\": 1.2601068667457218}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.609404, \"EndTime\": 1623172741.6094143, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2562613496326265, \"count\": 1, \"min\": 1.2562613496326265, \"max\": 1.2562613496326265}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6094553, \"EndTime\": 1623172741.609466, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.259911131359282, \"count\": 1, \"min\": 1.259911131359282, \"max\": 1.259911131359282}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6095061, \"EndTime\": 1623172741.6095157, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5838551228841147, \"count\": 1, \"min\": 1.5838551228841147, \"max\": 1.5838551228841147}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6095526, \"EndTime\": 1623172741.6095617, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.707055430094401, \"count\": 1, \"min\": 1.707055430094401, \"max\": 1.707055430094401}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6095953, \"EndTime\": 1623172741.609605, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5837712881905692, \"count\": 1, \"min\": 1.5837712881905692, \"max\": 1.5837712881905692}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.60964, \"EndTime\": 1623172741.6096518, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7079332188197545, \"count\": 1, \"min\": 1.7079332188197545, \"max\": 1.7079332188197545}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6096876, \"EndTime\": 1623172741.6096973, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.255912110828218, \"count\": 1, \"min\": 1.255912110828218, \"max\": 1.255912110828218}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6097267, \"EndTime\": 1623172741.6097357, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2605332583472841, \"count\": 1, \"min\": 1.2605332583472841, \"max\": 1.2605332583472841}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6097682, \"EndTime\": 1623172741.6097772, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2563148513067337, \"count\": 1, \"min\": 1.2563148513067337, \"max\": 1.2563148513067337}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6098115, \"EndTime\": 1623172741.6098208, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2607494361514138, \"count\": 1, \"min\": 1.2607494361514138, \"max\": 1.2607494361514138}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6098459, \"EndTime\": 1623172741.6098514, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.57803221929641, \"count\": 1, \"min\": 1.57803221929641, \"max\": 1.57803221929641}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6098793, \"EndTime\": 1623172741.6098852, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6939283432733445, \"count\": 1, \"min\": 1.6939283432733445, \"max\": 1.6939283432733445}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6099124, \"EndTime\": 1623172741.609921, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5783917875744047, \"count\": 1, \"min\": 1.5783917875744047, \"max\": 1.5783917875744047}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6099577, \"EndTime\": 1623172741.6099665, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6942523251488095, \"count\": 1, \"min\": 1.6942523251488095, \"max\": 1.6942523251488095}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6100025, \"EndTime\": 1623172741.6100116, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.304182878766741, \"count\": 1, \"min\": 1.304182878766741, \"max\": 1.304182878766741}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6100469, \"EndTime\": 1623172741.610056, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3088785109747023, \"count\": 1, \"min\": 1.3088785109747023, \"max\": 1.3088785109747023}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6100883, \"EndTime\": 1623172741.6100974, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.304200222923642, \"count\": 1, \"min\": 1.304200222923642, \"max\": 1.304200222923642}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6101315, \"EndTime\": 1623172741.6101406, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3088837222144718, \"count\": 1, \"min\": 1.3088837222144718, \"max\": 1.3088837222144718}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.610173, \"EndTime\": 1623172741.6101818, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.427718792143322, \"count\": 1, \"min\": 1.427718792143322, \"max\": 1.427718792143322}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6102169, \"EndTime\": 1623172741.6102262, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4836591055733817, \"count\": 1, \"min\": 1.4836591055733817, \"max\": 1.4836591055733817}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6102502, \"EndTime\": 1623172741.6102579, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4275968250093005, \"count\": 1, \"min\": 1.4275968250093005, \"max\": 1.4275968250093005}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6102812, \"EndTime\": 1623172741.610287, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4840238414946056, \"count\": 1, \"min\": 1.4840238414946056, \"max\": 1.4840238414946056}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6103199, \"EndTime\": 1623172741.6103287, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3439484122140066, \"count\": 1, \"min\": 1.3439484122140066, \"max\": 1.3439484122140066}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6103659, \"EndTime\": 1623172741.6103752, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3448612438383556, \"count\": 1, \"min\": 1.3448612438383556, \"max\": 1.3448612438383556}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.610405, \"EndTime\": 1623172741.610411, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3437398608979725, \"count\": 1, \"min\": 1.3437398608979725, \"max\": 1.3437398608979725}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6104403, \"EndTime\": 1623172741.610449, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3451970825195312, \"count\": 1, \"min\": 1.3451970825195312, \"max\": 1.3451970825195312}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6104827, \"EndTime\": 1623172741.61049, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3852002810523623, \"count\": 1, \"min\": 1.3852002810523623, \"max\": 1.3852002810523623}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.610511, \"EndTime\": 1623172741.6105163, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.408532499767485, \"count\": 1, \"min\": 1.408532499767485, \"max\": 1.408532499767485}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.610543, \"EndTime\": 1623172741.610551, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3853890497116816, \"count\": 1, \"min\": 1.3853890497116816, \"max\": 1.3853890497116816}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6105838, \"EndTime\": 1623172741.6105936, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4097653532482328, \"count\": 1, \"min\": 1.4097653532482328, \"max\": 1.4097653532482328}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:01 INFO 139839868135232] #quality_metric: host=algo-1, epoch=7, train binary_classification_weighted_cross_entropy_objective <loss>=1.2561972292945498\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:01 INFO 139839868135232] #early_stopping_criteria_metric: host=algo-1, epoch=7, criteria=binary_classification_weighted_cross_entropy_objective, value=1.255912110828218\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:01 INFO 139839868135232] Saving model for epoch: 7\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:01 INFO 139839868135232] Saved checkpoint to \"/tmp/tmpwnurka5m/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:01 INFO 139839868135232] #progress_metric: host=algo-1, completed 26.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172740.6499813, \"EndTime\": 1623172741.6180434, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 355696.0, \"count\": 1, \"min\": 355696, \"max\": 355696}, \"Total Batches Seen\": {\"sum\": 356.0, \"count\": 1, \"min\": 356, \"max\": 356}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:01 INFO 139839868135232] #throughput_metric: host=algo-1, train throughput=44375.09735247697 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:19:02.554] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 19, \"duration\": 936, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.554965, \"EndTime\": 1623172742.5550299, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2553646080380394, \"count\": 1, \"min\": 1.2553646080380394, \"max\": 1.2553646080380394}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5550969, \"EndTime\": 1623172742.555107, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.259874283563523, \"count\": 1, \"min\": 1.259874283563523, \"max\": 1.259874283563523}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5551465, \"EndTime\": 1623172742.5551567, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.255423363095238, \"count\": 1, \"min\": 1.255423363095238, \"max\": 1.255423363095238}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.555193, \"EndTime\": 1623172742.5552027, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2597055533272878, \"count\": 1, \"min\": 1.2597055533272878, \"max\": 1.2597055533272878}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5552416, \"EndTime\": 1623172742.555251, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5689780564081102, \"count\": 1, \"min\": 1.5689780564081102, \"max\": 1.5689780564081102}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.555291, \"EndTime\": 1623172742.555299, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7051744820731027, \"count\": 1, \"min\": 1.7051744820731027, \"max\": 1.7051744820731027}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5553288, \"EndTime\": 1623172742.5553374, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.568986580984933, \"count\": 1, \"min\": 1.568986580984933, \"max\": 1.568986580984933}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.555372, \"EndTime\": 1623172742.5553796, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7059116501581102, \"count\": 1, \"min\": 1.7059116501581102, \"max\": 1.7059116501581102}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5554097, \"EndTime\": 1623172742.5554192, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2551521446591332, \"count\": 1, \"min\": 1.2551521446591332, \"max\": 1.2551521446591332}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5554545, \"EndTime\": 1623172742.555463, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2602562677292597, \"count\": 1, \"min\": 1.2602562677292597, \"max\": 1.2602562677292597}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5554988, \"EndTime\": 1623172742.5555081, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2554771728515626, \"count\": 1, \"min\": 1.2554771728515626, \"max\": 1.2554771728515626}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.555545, \"EndTime\": 1623172742.5555546, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2604208911714099, \"count\": 1, \"min\": 1.2604208911714099, \"max\": 1.2604208911714099}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5555866, \"EndTime\": 1623172742.555593, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5641036275227864, \"count\": 1, \"min\": 1.5641036275227864, \"max\": 1.5641036275227864}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5556138, \"EndTime\": 1623172742.5556188, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6921219773065477, \"count\": 1, \"min\": 1.6921219773065477, \"max\": 1.6921219773065477}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5556402, \"EndTime\": 1623172742.555648, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.564419939313616, \"count\": 1, \"min\": 1.564419939313616, \"max\": 1.564419939313616}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.555673, \"EndTime\": 1623172742.555679, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6923800237746465, \"count\": 1, \"min\": 1.6923800237746465, \"max\": 1.6923800237746465}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5557122, \"EndTime\": 1623172742.5557208, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3035966477167038, \"count\": 1, \"min\": 1.3035966477167038, \"max\": 1.3035966477167038}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5557597, \"EndTime\": 1623172742.5557687, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3088277646019346, \"count\": 1, \"min\": 1.3088277646019346, \"max\": 1.3088277646019346}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5558069, \"EndTime\": 1623172742.5558162, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3036109517415364, \"count\": 1, \"min\": 1.3036109517415364, \"max\": 1.3036109517415364}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5558493, \"EndTime\": 1623172742.5558581, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3088321896507626, \"count\": 1, \"min\": 1.3088321896507626, \"max\": 1.3088321896507626}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5558937, \"EndTime\": 1623172742.5559018, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4207203819638208, \"count\": 1, \"min\": 1.4207203819638208, \"max\": 1.4207203819638208}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5559342, \"EndTime\": 1623172742.5559437, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4827652297247025, \"count\": 1, \"min\": 1.4827652297247025, \"max\": 1.4827652297247025}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.555973, \"EndTime\": 1623172742.5559819, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4205500124976749, \"count\": 1, \"min\": 1.4205500124976749, \"max\": 1.4205500124976749}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5560162, \"EndTime\": 1623172742.556025, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4830605788457962, \"count\": 1, \"min\": 1.4830605788457962, \"max\": 1.4830605788457962}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5560553, \"EndTime\": 1623172742.5560646, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3438521321614583, \"count\": 1, \"min\": 1.3438521321614583, \"max\": 1.3438521321614583}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5560982, \"EndTime\": 1623172742.5561075, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.344860089983259, \"count\": 1, \"min\": 1.344860089983259, \"max\": 1.344860089983259}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5561354, \"EndTime\": 1623172742.5561447, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3436537272135416, \"count\": 1, \"min\": 1.3436537272135416, \"max\": 1.3436537272135416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5561733, \"EndTime\": 1623172742.5561795, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3451976492745537, \"count\": 1, \"min\": 1.3451976492745537, \"max\": 1.3451976492745537}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5562112, \"EndTime\": 1623172742.5562193, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3841773042224703, \"count\": 1, \"min\": 1.3841773042224703, \"max\": 1.3841773042224703}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5562534, \"EndTime\": 1623172742.5562627, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4075413353329613, \"count\": 1, \"min\": 1.4075413353329613, \"max\": 1.4075413353329613}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.556292, \"EndTime\": 1623172742.5563006, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.384324195498512, \"count\": 1, \"min\": 1.384324195498512, \"max\": 1.384324195498512}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5563328, \"EndTime\": 1623172742.5563412, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4092294980003721, \"count\": 1, \"min\": 1.4092294980003721, \"max\": 1.4092294980003721}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:02 INFO 139839868135232] #quality_metric: host=algo-1, epoch=8, train binary_classification_weighted_cross_entropy_objective <loss>=1.2553646080380394\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:02 INFO 139839868135232] #early_stopping_criteria_metric: host=algo-1, epoch=8, criteria=binary_classification_weighted_cross_entropy_objective, value=1.2551521446591332\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:02 INFO 139839868135232] Saving model for epoch: 8\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:02 INFO 139839868135232] Saved checkpoint to \"/tmp/tmps2w2s2hi/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:02 INFO 139839868135232] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172741.6182332, \"EndTime\": 1623172742.5638666, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 398658.0, \"count\": 1, \"min\": 398658, \"max\": 398658}, \"Total Batches Seen\": {\"sum\": 399.0, \"count\": 1, \"min\": 399, \"max\": 399}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:02 INFO 139839868135232] #throughput_metric: host=algo-1, train throughput=45427.11419444732 records/second\u001b[0m\n",
      "\n",
      "2021-06-08 17:19:15 Uploading - Uploading generated training model\n",
      "2021-06-08 17:19:15 Completed - Training job completed\n",
      "\u001b[34m[2021-06-08 17:19:03.435] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 21, \"duration\": 870, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4353306, \"EndTime\": 1623172743.4353967, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2546187627883185, \"count\": 1, \"min\": 1.2546187627883185, \"max\": 1.2546187627883185}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4354625, \"EndTime\": 1623172743.435473, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2596591796875, \"count\": 1, \"min\": 1.2596591796875, \"max\": 1.2596591796875}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4355094, \"EndTime\": 1623172743.435519, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2546720072428386, \"count\": 1, \"min\": 1.2546720072428386, \"max\": 1.2546720072428386}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.435555, \"EndTime\": 1623172743.4355645, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.259513947986421, \"count\": 1, \"min\": 1.259513947986421, \"max\": 1.259513947986421}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4356017, \"EndTime\": 1623172743.43561, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5548732270740326, \"count\": 1, \"min\": 1.5548732270740326, \"max\": 1.5548732270740326}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4356327, \"EndTime\": 1623172743.4356413, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7042303699311756, \"count\": 1, \"min\": 1.7042303699311756, \"max\": 1.7042303699311756}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4356647, \"EndTime\": 1623172743.4356723, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5549391929989769, \"count\": 1, \"min\": 1.5549391929989769, \"max\": 1.5549391929989769}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4357, \"EndTime\": 1623172743.435706, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7048635995047432, \"count\": 1, \"min\": 1.7048635995047432, \"max\": 1.7048635995047432}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4357295, \"EndTime\": 1623172743.4357352, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2544656749906995, \"count\": 1, \"min\": 1.2544656749906995, \"max\": 1.2544656749906995}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.43577, \"EndTime\": 1623172743.4357784, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2600114339192707, \"count\": 1, \"min\": 1.2600114339192707, \"max\": 1.2600114339192707}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4358108, \"EndTime\": 1623172743.4358187, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2547350841703868, \"count\": 1, \"min\": 1.2547350841703868, \"max\": 1.2547350841703868}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4358556, \"EndTime\": 1623172743.435865, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2601394478934151, \"count\": 1, \"min\": 1.2601394478934151, \"max\": 1.2601394478934151}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4359004, \"EndTime\": 1623172743.435909, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5508021821521578, \"count\": 1, \"min\": 1.5508021821521578, \"max\": 1.5508021821521578}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.435947, \"EndTime\": 1623172743.4359558, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6911060064406622, \"count\": 1, \"min\": 1.6911060064406622, \"max\": 1.6911060064406622}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4359925, \"EndTime\": 1623172743.4360015, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.551083754766555, \"count\": 1, \"min\": 1.551083754766555, \"max\": 1.551083754766555}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4360392, \"EndTime\": 1623172743.436046, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6913211611793155, \"count\": 1, \"min\": 1.6913211611793155, \"max\": 1.6913211611793155}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4360807, \"EndTime\": 1623172743.4360886, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3030398908342633, \"count\": 1, \"min\": 1.3030398908342633, \"max\": 1.3030398908342633}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4361262, \"EndTime\": 1623172743.4361362, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3087754807245164, \"count\": 1, \"min\": 1.3087754807245164, \"max\": 1.3087754807245164}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4361722, \"EndTime\": 1623172743.436182, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3030518464587983, \"count\": 1, \"min\": 1.3030518464587983, \"max\": 1.3030518464587983}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4362154, \"EndTime\": 1623172743.4362247, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3087792547316779, \"count\": 1, \"min\": 1.3087792547316779, \"max\": 1.3087792547316779}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4362607, \"EndTime\": 1623172743.43627, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4142587338402157, \"count\": 1, \"min\": 1.4142587338402157, \"max\": 1.4142587338402157}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4363093, \"EndTime\": 1623172743.4363189, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4825999973842077, \"count\": 1, \"min\": 1.4825999973842077, \"max\": 1.4825999973842077}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4363513, \"EndTime\": 1623172743.436358, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4140685163225446, \"count\": 1, \"min\": 1.4140685163225446, \"max\": 1.4140685163225446}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.436395, \"EndTime\": 1623172743.436405, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4828478873116628, \"count\": 1, \"min\": 1.4828478873116628, \"max\": 1.4828478873116628}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4364421, \"EndTime\": 1623172743.4364505, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3437565133231026, \"count\": 1, \"min\": 1.3437565133231026, \"max\": 1.3437565133231026}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4364886, \"EndTime\": 1623172743.4364982, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3448465183803013, \"count\": 1, \"min\": 1.3448465183803013, \"max\": 1.3448465183803013}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4365315, \"EndTime\": 1623172743.4365377, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3435581635974703, \"count\": 1, \"min\": 1.3435581635974703, \"max\": 1.3435581635974703}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4365754, \"EndTime\": 1623172743.436585, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3451863606770833, \"count\": 1, \"min\": 1.3451863606770833, \"max\": 1.3451863606770833}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.43662, \"EndTime\": 1623172743.4366293, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3836868533179874, \"count\": 1, \"min\": 1.3836868533179874, \"max\": 1.3836868533179874}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4366682, \"EndTime\": 1623172743.4366777, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4078705284481956, \"count\": 1, \"min\": 1.4078705284481956, \"max\": 1.4078705284481956}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.4367101, \"EndTime\": 1623172743.4367166, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3837635948544458, \"count\": 1, \"min\": 1.3837635948544458, \"max\": 1.3837635948544458}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172743.436754, \"EndTime\": 1623172743.4367628, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4093355858212426, \"count\": 1, \"min\": 1.4093355858212426, \"max\": 1.4093355858212426}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #quality_metric: host=algo-1, epoch=9, train binary_classification_weighted_cross_entropy_objective <loss>=1.2546187627883185\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #early_stopping_criteria_metric: host=algo-1, epoch=9, criteria=binary_classification_weighted_cross_entropy_objective, value=1.2544656749906995\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] Saving model for epoch: 9\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] Saved checkpoint to \"/tmp/tmp9c5cjjze/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172742.5644379, \"EndTime\": 1623172743.4444015, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 441620.0, \"count\": 1, \"min\": 441620, \"max\": 441620}, \"Total Batches Seen\": {\"sum\": 442.0, \"count\": 1, \"min\": 442, \"max\": 442}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #throughput_metric: host=algo-1, train throughput=48816.95653615629 records/second\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 WARNING 139839868135232] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 WARNING 139839868135232] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:19:03.449] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 23, \"duration\": 4, \"num_examples\": 1, \"num_bytes\": 372000}\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:19:03.567] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 116, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:19:03.695] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 100, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #train_score (algo-1) : ('binary_classification_weighted_cross_entropy_objective', 1.2516525976762531)\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #train_score (algo-1) : ('binary_classification_accuracy', 0.3858526139378986)\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #train_score (algo-1) : ('binary_f_1.000', 0.03333943945777615)\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #train_score (algo-1) : ('precision', 0.01700108358554721)\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #train_score (algo-1) : ('recall', 0.8552631578947368)\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #train_score (algo-1) : ('roc_auc_score', 0.6831440639071164)\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #quality_metric: host=algo-1, train binary_classification_weighted_cross_entropy_objective <loss>=1.2516525976762531\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #quality_metric: host=algo-1, train binary_classification_accuracy <score>=0.3858526139378986\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #quality_metric: host=algo-1, train binary_f_1.000 <score>=0.03333943945777615\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #quality_metric: host=algo-1, train precision <score>=0.01700108358554721\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #quality_metric: host=algo-1, train recall <score>=0.8552631578947368\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] #quality_metric: host=algo-1, train roc_auc_score <score>=0.6831440639071164\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] Best model found for hyperparameters: {\"optimizer\": \"adam\", \"learning_rate\": 0.005, \"wd\": 0.01, \"l1\": 0.0, \"lr_scheduler_step\": 10, \"lr_scheduler_factor\": 0.99, \"lr_scheduler_minimum_lr\": 1e-05}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] Saved checkpoint to \"/tmp/tmpmkeh3z3k/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:19:03 INFO 139839868135232] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623172733.6178112, \"EndTime\": 1623172743.7181995, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 232.10787773132324, \"count\": 1, \"min\": 232.10787773132324, \"max\": 232.10787773132324}, \"epochs\": {\"sum\": 30.0, \"count\": 1, \"min\": 30, \"max\": 30}, \"check_early_stopping.time\": {\"sum\": 5.02467155456543, \"count\": 10, \"min\": 0.16260147094726562, \"max\": 0.9152889251708984}, \"update.time\": {\"sum\": 9563.304901123047, \"count\": 10, \"min\": 858.086109161377, \"max\": 1123.3019828796387}, \"finalize.time\": {\"sum\": 265.0461196899414, \"count\": 1, \"min\": 265.0461196899414, \"max\": 265.0461196899414}, \"setuptime\": {\"sum\": 18.82028579711914, \"count\": 1, \"min\": 18.82028579711914, \"max\": 18.82028579711914}, \"totaltime\": {\"sum\": 10277.08888053894, \"count\": 1, \"min\": 10277.08888053894, \"max\": 10277.08888053894}}}\n",
      "\u001b[0m\n",
      "Training seconds: 60\n",
      "Billable seconds: 60\n",
      "CPU times: user 526 ms, sys: 40.6 ms, total: 567 ms\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# train the estimator on formatted training data\n",
    "LinearLearner_1.fit(formatted_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4a9bd",
   "metadata": {},
   "source": [
    "The ROC-AUC score is 0.6831. I instantiated another LinearLearner model that uses accuracy as the selection criteria, in the hope to improve ROC-AUC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "3c5210f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune the model a slightly differently to check the result \n",
    "LinearLearner_2 = LinearLearner (role = role,\n",
    "                                 instance_count= 1,\n",
    "                                 instance_type = 'ml.m5.2xlarge',\n",
    "                                 output_path = output_path,\n",
    "                                 predictor_type = 'binary_classifier', \n",
    "                                 sagemaker_session = session, \n",
    "                                 epochs = 30,\n",
    "                                 binary_classifier_model_selection_criteria = 'accuracy',\n",
    "                                 positive_example_weight_mult='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "1558c0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-08 17:20:03 Starting - Starting the training job...\n",
      "2021-06-08 17:20:05 Starting - Launching requested ML instancesProfilerReport-1623172803: InProgress\n",
      ".........\n",
      "2021-06-08 17:21:54 Starting - Preparing the instances for training......\n",
      "2021-06-08 17:22:54 Downloading - Downloading input data...\n",
      "2021-06-08 17:23:34 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:39 INFO 140708987352896] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:39 INFO 140708987352896] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'positive_example_weight_mult': 'balanced', 'feature_dim': '81', 'predictor_type': 'binary_classifier', 'epochs': '30', 'binary_classifier_model_selection_criteria': 'accuracy', 'mini_batch_size': '1000'}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:39 INFO 140708987352896] Final configuration: {'mini_batch_size': '1000', 'epochs': '30', 'feature_dim': '81', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': 'balanced', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:39 WARNING 140708987352896] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:39 INFO 140708987352896] Using default worker.\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:39 INFO 140708987352896] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:23:39.693] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 16, \"num_examples\": 1, \"num_bytes\": 372000}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:39 INFO 140708987352896] Create Store: local\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:23:39.759] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 65, \"num_examples\": 11, \"num_bytes\": 4092000}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:39 INFO 140708987352896] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7ff8f3bb9410>\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:39 INFO 140708987352896] Scaling model computed with parameters:\n",
      " {'stdev_label': None, 'stdev_weight': \u001b[0m\n",
      "\u001b[34m[1.370195   0.933881   1.0859637  0.98266894 0.79311574 0.67984086\n",
      " 0.6222028  0.5804693  0.5568346  0.52604145 0.48153597 0.47564965\n",
      " 0.4383537  0.44538096 0.5263256  0.4098545  0.44057795 0.4196977\n",
      " 0.40481797 0.3970001  0.3905713  0.37176716 0.38902235 0.4040231\n",
      " 0.35453817 0.3446608  0.3739252  0.35265562 0.33796972 0.32881942\n",
      " 0.33207533 0.32572553 0.34471157 0.3133428  0.33319926 0.31479827\n",
      " 0.3407188  0.32137564 0.31887814 0.29961243 0.34365362 0.3004113\n",
      " 0.31866083 0.35787034 0.31269053 0.29220548 0.33360815 0.28765094\n",
      " 0.33415192 0.317402   0.29990983 0.2802207  0.29533    0.3220272\n",
      " 0.2825223  0.30113307 0.27954623 0.28098255 0.28392693 0.27155364\n",
      " 0.29093915 0.30967227 0.26297304 0.3162528  0.2473041  0.2537619\n",
      " 0.2690534  0.2728689  0.26142636 0.28315738 0.28961012 0.24637839\n",
      " 0.2415551  0.2543277  0.23558365 0.26588637 0.2371737  0.2374952\n",
      " 0.22802418 0.28549975 0.35591173]\u001b[0m\n",
      "\u001b[34m<NDArray 81 @cpu(0)>, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[-7.2550994e-01  7.3213905e-01 -5.0072271e-01  1.3369644e-01\n",
      "  1.3747928e-01 -2.7237233e-02  4.5576487e-02 -1.7476426e-03\n",
      " -2.9101014e-02  8.5650772e-02  2.0313284e-01  5.7401478e-02\n",
      " -1.0599697e-01 -8.1825359e-03  1.1477494e-01 -2.1972459e-02\n",
      "  1.7322725e-01 -6.1230984e-02  2.1739138e-02 -9.0990700e-03\n",
      "  1.7104995e-02  5.5031758e-03  1.2545899e-01 -1.7886519e-01\n",
      " -3.1084884e-03 -1.8323543e-02 -2.9811386e-02 -5.2571803e-02\n",
      "  1.1396676e-02 -2.2758665e-03 -1.8549934e-02  3.9054246e-03\n",
      " -1.1749192e-01  1.1573640e-02 -1.1054998e-01  3.7347064e-03\n",
      "  2.7306935e-02 -8.5831834e-03 -3.1815611e-02 -1.5098377e-03\n",
      "  3.6868919e-03  1.1409157e-03  3.5180636e-02  1.0353057e-01\n",
      "  4.4318903e-02 -4.8420257e-03 -3.7760850e-02 -1.8542001e-02\n",
      " -5.4732710e-02  4.1972917e-02  6.1684288e-02 -4.4452883e-03\n",
      "  6.8109497e-02  1.0732662e-01 -3.6725909e-02 -8.9715421e-04\n",
      "  3.0722721e-02  1.7220681e-03  2.0142457e-02 -6.8433806e-03\n",
      "  3.7513793e-02  8.3310053e-02  3.0305486e-02 -4.1551594e-02\n",
      "  2.3516845e-03  3.5988417e-02  3.0088682e-02 -1.7711887e-04\n",
      "  2.2216950e-02 -6.2600881e-02  1.0994927e-01 -3.7042335e-02\n",
      "  2.2247139e-02 -1.7599491e-02 -5.8616567e-03  4.9659773e-03\n",
      "  1.9634483e-04 -1.5914319e-02 -2.7412749e-03  7.1733452e-02\n",
      "  5.3517967e-01]\u001b[0m\n",
      "\u001b[34m<NDArray 81 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:39 INFO 140708987352896] nvidia-smi: took 0.030 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:39 INFO 140708987352896] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:39 INFO 140708987352896] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173019.9206202, \"EndTime\": 1623173019.9206543, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12000.0, \"count\": 1, \"min\": 12000, \"max\": 12000}, \"Total Batches Seen\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Max Records Seen Between Resets\": {\"sum\": 11000.0, \"count\": 1, \"min\": 11000, \"max\": 11000}, \"Max Batches Seen Between Resets\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:23:41.035] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 3, \"duration\": 1114, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0356674, \"EndTime\": 1623173021.035746, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3315474621000745, \"count\": 1, \"min\": 1.3315474621000745, \"max\": 1.3315474621000745}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0358267, \"EndTime\": 1623173021.0358431, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3400364350818452, \"count\": 1, \"min\": 1.3400364350818452, \"max\": 1.3400364350818452}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0358825, \"EndTime\": 1623173021.0358942, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3288021545410156, \"count\": 1, \"min\": 1.3288021545410156, \"max\": 1.3288021545410156}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0359242, \"EndTime\": 1623173021.0359316, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3302122730073476, \"count\": 1, \"min\": 1.3302122730073476, \"max\": 1.3302122730073476}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0359695, \"EndTime\": 1623173021.035979, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.799389401390439, \"count\": 1, \"min\": 1.799389401390439, \"max\": 1.799389401390439}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0360074, \"EndTime\": 1623173021.0360172, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.8068316999162946, \"count\": 1, \"min\": 1.8068316999162946, \"max\": 1.8068316999162946}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.036056, \"EndTime\": 1623173021.036063, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.8031193527948288, \"count\": 1, \"min\": 1.8031193527948288, \"max\": 1.8031193527948288}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0360944, \"EndTime\": 1623173021.0361018, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7934884033203125, \"count\": 1, \"min\": 1.7934884033203125, \"max\": 1.7934884033203125}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0361428, \"EndTime\": 1623173021.0361495, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3303069675990513, \"count\": 1, \"min\": 1.3303069675990513, \"max\": 1.3303069675990513}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0361724, \"EndTime\": 1623173021.0361803, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3424482189360119, \"count\": 1, \"min\": 1.3424482189360119, \"max\": 1.3424482189360119}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.03621, \"EndTime\": 1623173021.036216, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3380414312453497, \"count\": 1, \"min\": 1.3380414312453497, \"max\": 1.3380414312453497}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0362468, \"EndTime\": 1623173021.0362563, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3320183570498512, \"count\": 1, \"min\": 1.3320183570498512, \"max\": 1.3320183570498512}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0362918, \"EndTime\": 1623173021.0363016, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7889956839425223, \"count\": 1, \"min\": 1.7889956839425223, \"max\": 1.7889956839425223}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0363438, \"EndTime\": 1623173021.0363545, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7864532877604167, \"count\": 1, \"min\": 1.7864532877604167, \"max\": 1.7864532877604167}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.036393, \"EndTime\": 1623173021.0364027, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7820270269484748, \"count\": 1, \"min\": 1.7820270269484748, \"max\": 1.7820270269484748}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0364623, \"EndTime\": 1623173021.0364735, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7629174586704799, \"count\": 1, \"min\": 1.7629174586704799, \"max\": 1.7629174586704799}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0365152, \"EndTime\": 1623173021.036523, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3447593776157925, \"count\": 1, \"min\": 1.3447593776157925, \"max\": 1.3447593776157925}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0365615, \"EndTime\": 1623173021.0365717, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3438343447730654, \"count\": 1, \"min\": 1.3438343447730654, \"max\": 1.3438343447730654}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0366106, \"EndTime\": 1623173021.0366206, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3330838855561755, \"count\": 1, \"min\": 1.3330838855561755, \"max\": 1.3330838855561755}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0366607, \"EndTime\": 1623173021.036672, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3426279006231399, \"count\": 1, \"min\": 1.3426279006231399, \"max\": 1.3426279006231399}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0367107, \"EndTime\": 1623173021.0367217, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.463957788376581, \"count\": 1, \"min\": 1.463957788376581, \"max\": 1.463957788376581}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.036755, \"EndTime\": 1623173021.036765, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4499709923153832, \"count\": 1, \"min\": 1.4499709923153832, \"max\": 1.4499709923153832}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0367963, \"EndTime\": 1623173021.0368066, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4557730073474702, \"count\": 1, \"min\": 1.4557730073474702, \"max\": 1.4557730073474702}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0368476, \"EndTime\": 1623173021.036857, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4492352614629835, \"count\": 1, \"min\": 1.4492352614629835, \"max\": 1.4492352614629835}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0369008, \"EndTime\": 1623173021.0369112, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3511390671502976, \"count\": 1, \"min\": 1.3511390671502976, \"max\": 1.3511390671502976}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0369475, \"EndTime\": 1623173021.036958, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3521972104027158, \"count\": 1, \"min\": 1.3521972104027158, \"max\": 1.3521972104027158}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0369997, \"EndTime\": 1623173021.0370107, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3468667849586125, \"count\": 1, \"min\": 1.3468667849586125, \"max\": 1.3468667849586125}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0370555, \"EndTime\": 1623173021.037067, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.355402820405506, \"count\": 1, \"min\": 1.355402820405506, \"max\": 1.355402820405506}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0371118, \"EndTime\": 1623173021.0371227, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.358622023809524, \"count\": 1, \"min\": 1.358622023809524, \"max\": 1.358622023809524}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0371642, \"EndTime\": 1623173021.0371742, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.365116950625465, \"count\": 1, \"min\": 1.365116950625465, \"max\": 1.365116950625465}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0372171, \"EndTime\": 1623173021.0372283, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3632168564569382, \"count\": 1, \"min\": 1.3632168564569382, \"max\": 1.3632168564569382}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0372708, \"EndTime\": 1623173021.0372813, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3710340125674294, \"count\": 1, \"min\": 1.3710340125674294, \"max\": 1.3710340125674294}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:41 INFO 140708987352896] #quality_metric: host=algo-1, epoch=0, train binary_classification_weighted_cross_entropy_objective <loss>=1.3315474621000745\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:41 INFO 140708987352896] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=binary_classification_weighted_cross_entropy_objective, value=1.3288021545410156\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:41 INFO 140708987352896] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:41 INFO 140708987352896] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:41 INFO 140708987352896] Saved checkpoint to \"/tmp/tmpuzwwy6lw/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:41 INFO 140708987352896] #progress_metric: host=algo-1, completed 3.3333333333333335 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173019.92088, \"EndTime\": 1623173021.0501187, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 54962.0, \"count\": 1, \"min\": 54962, \"max\": 54962}, \"Total Batches Seen\": {\"sum\": 55.0, \"count\": 1, \"min\": 55, \"max\": 55}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:41 INFO 140708987352896] #throughput_metric: host=algo-1, train throughput=38041.931243791914 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:23:42.137] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 5, \"duration\": 1087, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1379137, \"EndTime\": 1623173022.137972, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2757369820731026, \"count\": 1, \"min\": 1.2757369820731026, \"max\": 1.2757369820731026}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.13804, \"EndTime\": 1623173022.1380515, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2767523425874256, \"count\": 1, \"min\": 1.2767523425874256, \"max\": 1.2767523425874256}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1380827, \"EndTime\": 1623173022.13809, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2754825410388766, \"count\": 1, \"min\": 1.2754825410388766, \"max\": 1.2754825410388766}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.138116, \"EndTime\": 1623173022.138122, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2745119222005208, \"count\": 1, \"min\": 1.2745119222005208, \"max\": 1.2745119222005208}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.138148, \"EndTime\": 1623173022.1381545, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7105114455450148, \"count\": 1, \"min\": 1.7105114455450148, \"max\": 1.7105114455450148}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1381814, \"EndTime\": 1623173022.1381874, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7266761343819754, \"count\": 1, \"min\": 1.7266761343819754, \"max\": 1.7266761343819754}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1382143, \"EndTime\": 1623173022.1382208, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7103619936988468, \"count\": 1, \"min\": 1.7103619936988468, \"max\": 1.7103619936988468}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.138246, \"EndTime\": 1623173022.1382523, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7357349490211123, \"count\": 1, \"min\": 1.7357349490211123, \"max\": 1.7357349490211123}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1382768, \"EndTime\": 1623173022.1382828, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2738736891973585, \"count\": 1, \"min\": 1.2738736891973585, \"max\": 1.2738736891973585}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.13831, \"EndTime\": 1623173022.138316, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.278644760858445, \"count\": 1, \"min\": 1.278644760858445, \"max\": 1.278644760858445}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1383395, \"EndTime\": 1623173022.1383455, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2793521205357143, \"count\": 1, \"min\": 1.2793521205357143, \"max\": 1.2793521205357143}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1383715, \"EndTime\": 1623173022.1383777, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.278540525890532, \"count\": 1, \"min\": 1.278540525890532, \"max\": 1.278540525890532}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1384013, \"EndTime\": 1623173022.1384075, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.692237069266183, \"count\": 1, \"min\": 1.692237069266183, \"max\": 1.692237069266183}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1384335, \"EndTime\": 1623173022.1384397, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7282389468238468, \"count\": 1, \"min\": 1.7282389468238468, \"max\": 1.7282389468238468}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1384661, \"EndTime\": 1623173022.138472, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6874378226143973, \"count\": 1, \"min\": 1.6874378226143973, \"max\": 1.6874378226143973}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1384957, \"EndTime\": 1623173022.1385016, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.730140404110863, \"count\": 1, \"min\": 1.730140404110863, \"max\": 1.730140404110863}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1385274, \"EndTime\": 1623173022.1385336, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3073584740048363, \"count\": 1, \"min\": 1.3073584740048363, \"max\": 1.3073584740048363}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1385574, \"EndTime\": 1623173022.1385636, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3081583862304687, \"count\": 1, \"min\": 1.3081583862304687, \"max\": 1.3081583862304687}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1385863, \"EndTime\": 1623173022.1385922, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3080772734142485, \"count\": 1, \"min\": 1.3080772734142485, \"max\": 1.3080772734142485}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.138616, \"EndTime\": 1623173022.1386223, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.308704352969215, \"count\": 1, \"min\": 1.308704352969215, \"max\": 1.308704352969215}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1386476, \"EndTime\": 1623173022.138654, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.50229202125186, \"count\": 1, \"min\": 1.50229202125186, \"max\": 1.50229202125186}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1386774, \"EndTime\": 1623173022.1386833, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5126903061639696, \"count\": 1, \"min\": 1.5126903061639696, \"max\": 1.5126903061639696}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1387067, \"EndTime\": 1623173022.1387126, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5006426914760045, \"count\": 1, \"min\": 1.5006426914760045, \"max\": 1.5006426914760045}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.138739, \"EndTime\": 1623173022.1387453, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5091283075241815, \"count\": 1, \"min\": 1.5091283075241815, \"max\": 1.5091283075241815}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1387715, \"EndTime\": 1623173022.138778, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3452618582589286, \"count\": 1, \"min\": 1.3452618582589286, \"max\": 1.3452618582589286}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1388042, \"EndTime\": 1623173022.1388104, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3451363045828684, \"count\": 1, \"min\": 1.3451363045828684, \"max\": 1.3451363045828684}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1388364, \"EndTime\": 1623173022.1388426, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3445921311151414, \"count\": 1, \"min\": 1.3445921311151414, \"max\": 1.3445921311151414}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.13887, \"EndTime\": 1623173022.1388764, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3454642566499255, \"count\": 1, \"min\": 1.3454642566499255, \"max\": 1.3454642566499255}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1389034, \"EndTime\": 1623173022.1389096, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.418489276704334, \"count\": 1, \"min\": 1.418489276704334, \"max\": 1.418489276704334}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.138936, \"EndTime\": 1623173022.138942, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4130035211472285, \"count\": 1, \"min\": 1.4130035211472285, \"max\": 1.4130035211472285}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1389656, \"EndTime\": 1623173022.1389716, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4162444428943453, \"count\": 1, \"min\": 1.4162444428943453, \"max\": 1.4162444428943453}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.138997, \"EndTime\": 1623173022.139003, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4172528206961497, \"count\": 1, \"min\": 1.4172528206961497, \"max\": 1.4172528206961497}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:42 INFO 140708987352896] #quality_metric: host=algo-1, epoch=1, train binary_classification_weighted_cross_entropy_objective <loss>=1.2757369820731026\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:42 INFO 140708987352896] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=binary_classification_weighted_cross_entropy_objective, value=1.2738736891973585\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:42 INFO 140708987352896] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:42 INFO 140708987352896] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:42 INFO 140708987352896] Saved checkpoint to \"/tmp/tmpqry4qphs/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:42 INFO 140708987352896] #progress_metric: host=algo-1, completed 6.666666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173021.0503178, \"EndTime\": 1623173022.1483028, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 97924.0, \"count\": 1, \"min\": 97924, \"max\": 97924}, \"Total Batches Seen\": {\"sum\": 98.0, \"count\": 1, \"min\": 98, \"max\": 98}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:42 INFO 140708987352896] #throughput_metric: host=algo-1, train throughput=39124.69927281033 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:23:43.133] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 7, \"duration\": 984, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1336403, \"EndTime\": 1623173023.133705, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.265753137497675, \"count\": 1, \"min\": 1.265753137497675, \"max\": 1.265753137497675}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1337836, \"EndTime\": 1623173023.1338, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2662496933710008, \"count\": 1, \"min\": 1.2662496933710008, \"max\": 1.2662496933710008}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.133845, \"EndTime\": 1623173023.1338553, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2658670058477492, \"count\": 1, \"min\": 1.2658670058477492, \"max\": 1.2658670058477492}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1338983, \"EndTime\": 1623173023.1339078, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2654092944917226, \"count\": 1, \"min\": 1.2654092944917226, \"max\": 1.2654092944917226}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.133946, \"EndTime\": 1623173023.1339552, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.674491440545945, \"count\": 1, \"min\": 1.674491440545945, \"max\": 1.674491440545945}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.133996, \"EndTime\": 1623173023.1340065, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7152276436941964, \"count\": 1, \"min\": 1.7152276436941964, \"max\": 1.7152276436941964}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.134042, \"EndTime\": 1623173023.1340513, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6739119800385975, \"count\": 1, \"min\": 1.6739119800385975, \"max\": 1.6739119800385975}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1340914, \"EndTime\": 1623173023.1341023, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.719454549153646, \"count\": 1, \"min\": 1.719454549153646, \"max\": 1.719454549153646}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1341355, \"EndTime\": 1623173023.1341457, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2645331057593936, \"count\": 1, \"min\": 1.2645331057593936, \"max\": 1.2645331057593936}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1341743, \"EndTime\": 1623173023.1341841, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2675901343936011, \"count\": 1, \"min\": 1.2675901343936011, \"max\": 1.2675901343936011}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1342247, \"EndTime\": 1623173023.1342342, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2672955264136905, \"count\": 1, \"min\": 1.2672955264136905, \"max\": 1.2672955264136905}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1342704, \"EndTime\": 1623173023.1342793, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2685147370837984, \"count\": 1, \"min\": 1.2685147370837984, \"max\": 1.2685147370837984}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1343172, \"EndTime\": 1623173023.1343267, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6623862987699962, \"count\": 1, \"min\": 1.6623862987699962, \"max\": 1.6623862987699962}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1343658, \"EndTime\": 1623173023.1343768, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.704162618001302, \"count\": 1, \"min\": 1.704162618001302, \"max\": 1.704162618001302}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1344128, \"EndTime\": 1623173023.134423, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6634776495070684, \"count\": 1, \"min\": 1.6634776495070684, \"max\": 1.6634776495070684}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1344612, \"EndTime\": 1623173023.1344712, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7059622555687315, \"count\": 1, \"min\": 1.7059622555687315, \"max\": 1.7059622555687315}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.134508, \"EndTime\": 1623173023.1345172, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3074884672619047, \"count\": 1, \"min\": 1.3074884672619047, \"max\": 1.3074884672619047}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.134557, \"EndTime\": 1623173023.134568, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.309210197812035, \"count\": 1, \"min\": 1.309210197812035, \"max\": 1.309210197812035}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1346002, \"EndTime\": 1623173023.1346107, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.30757762218657, \"count\": 1, \"min\": 1.30757762218657, \"max\": 1.30757762218657}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1346495, \"EndTime\": 1623173023.1346593, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3091949608212425, \"count\": 1, \"min\": 1.3091949608212425, \"max\": 1.3091949608212425}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1346967, \"EndTime\": 1623173023.1347063, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4743175557454427, \"count\": 1, \"min\": 1.4743175557454427, \"max\": 1.4743175557454427}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.134751, \"EndTime\": 1623173023.134762, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.493096189953032, \"count\": 1, \"min\": 1.493096189953032, \"max\": 1.493096189953032}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1348, \"EndTime\": 1623173023.1348104, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.478425266810826, \"count\": 1, \"min\": 1.478425266810826, \"max\": 1.478425266810826}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1348839, \"EndTime\": 1623173023.134897, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5016366388230096, \"count\": 1, \"min\": 1.5016366388230096, \"max\": 1.5016366388230096}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1349392, \"EndTime\": 1623173023.1349502, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3444326389857701, \"count\": 1, \"min\": 1.3444326389857701, \"max\": 1.3444326389857701}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1349897, \"EndTime\": 1623173023.1350002, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.344646969749814, \"count\": 1, \"min\": 1.344646969749814, \"max\": 1.344646969749814}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1350393, \"EndTime\": 1623173023.1350496, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3442381402878534, \"count\": 1, \"min\": 1.3442381402878534, \"max\": 1.3442381402878534}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1350877, \"EndTime\": 1623173023.1350977, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3450220772879464, \"count\": 1, \"min\": 1.3450220772879464, \"max\": 1.3450220772879464}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1351368, \"EndTime\": 1623173023.135147, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.429152840750558, \"count\": 1, \"min\": 1.429152840750558, \"max\": 1.429152840750558}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.135184, \"EndTime\": 1623173023.1351948, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4466939755394346, \"count\": 1, \"min\": 1.4466939755394346, \"max\": 1.4466939755394346}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1352267, \"EndTime\": 1623173023.135237, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4334513215564546, \"count\": 1, \"min\": 1.4334513215564546, \"max\": 1.4334513215564546}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1352732, \"EndTime\": 1623173023.1352832, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4447804216657365, \"count\": 1, \"min\": 1.4447804216657365, \"max\": 1.4447804216657365}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:43 INFO 140708987352896] #quality_metric: host=algo-1, epoch=2, train binary_classification_weighted_cross_entropy_objective <loss>=1.265753137497675\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:43 INFO 140708987352896] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=binary_classification_weighted_cross_entropy_objective, value=1.2645331057593936\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:43 INFO 140708987352896] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:43 INFO 140708987352896] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:43 INFO 140708987352896] Saved checkpoint to \"/tmp/tmp5s7nvt4_/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:43 INFO 140708987352896] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173022.1488714, \"EndTime\": 1623173023.1439915, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 140886.0, \"count\": 1, \"min\": 140886, \"max\": 140886}, \"Total Batches Seen\": {\"sum\": 141.0, \"count\": 1, \"min\": 141, \"max\": 141}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:43 INFO 140708987352896] #throughput_metric: host=algo-1, train throughput=43167.8920096524 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:23:44.187] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 9, \"duration\": 1042, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1870518, \"EndTime\": 1623173024.1871104, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2618780851818265, \"count\": 1, \"min\": 1.2618780851818265, \"max\": 1.2618780851818265}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1871867, \"EndTime\": 1623173024.187203, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2629794049944196, \"count\": 1, \"min\": 1.2629794049944196, \"max\": 1.2629794049944196}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.187236, \"EndTime\": 1623173024.1872432, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2619744713192895, \"count\": 1, \"min\": 1.2619744713192895, \"max\": 1.2619744713192895}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1872678, \"EndTime\": 1623173024.1872737, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2625242469424294, \"count\": 1, \"min\": 1.2625242469424294, \"max\": 1.2625242469424294}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1873157, \"EndTime\": 1623173024.1873257, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6546808064778646, \"count\": 1, \"min\": 1.6546808064778646, \"max\": 1.6546808064778646}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1873567, \"EndTime\": 1623173024.1873662, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.714390625, \"count\": 1, \"min\": 1.714390625, \"max\": 1.714390625}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.187412, \"EndTime\": 1623173024.187422, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6534643002464657, \"count\": 1, \"min\": 1.6534643002464657, \"max\": 1.6534643002464657}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.187465, \"EndTime\": 1623173024.1874752, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7170955142066593, \"count\": 1, \"min\": 1.7170955142066593, \"max\": 1.7170955142066593}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1875136, \"EndTime\": 1623173024.1875217, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2610069216773623, \"count\": 1, \"min\": 1.2610069216773623, \"max\": 1.2610069216773623}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1875536, \"EndTime\": 1623173024.1875627, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2639637145996094, \"count\": 1, \"min\": 1.2639637145996094, \"max\": 1.2639637145996094}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1875868, \"EndTime\": 1623173024.1875927, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2625642627534412, \"count\": 1, \"min\": 1.2625642627534412, \"max\": 1.2625642627534412}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1876278, \"EndTime\": 1623173024.1876373, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2647452988397507, \"count\": 1, \"min\": 1.2647452988397507, \"max\": 1.2647452988397507}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1876693, \"EndTime\": 1623173024.1876757, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6434860374813989, \"count\": 1, \"min\": 1.6434860374813989, \"max\": 1.6434860374813989}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1877067, \"EndTime\": 1623173024.1877158, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7029236479259673, \"count\": 1, \"min\": 1.7029236479259673, \"max\": 1.7029236479259673}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1877553, \"EndTime\": 1623173024.1877646, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6442784627278646, \"count\": 1, \"min\": 1.6442784627278646, \"max\": 1.6442784627278646}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1877995, \"EndTime\": 1623173024.1878097, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7042654055640811, \"count\": 1, \"min\": 1.7042654055640811, \"max\": 1.7042654055640811}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1878426, \"EndTime\": 1623173024.1878517, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.306744409470331, \"count\": 1, \"min\": 1.306744409470331, \"max\": 1.306744409470331}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1878896, \"EndTime\": 1623173024.1878994, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3090935625348772, \"count\": 1, \"min\": 1.3090935625348772, \"max\": 1.3090935625348772}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.187928, \"EndTime\": 1623173024.187935, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.30678564453125, \"count\": 1, \"min\": 1.30678564453125, \"max\": 1.30678564453125}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1879728, \"EndTime\": 1623173024.1879826, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3091061256045387, \"count\": 1, \"min\": 1.3091061256045387, \"max\": 1.3091061256045387}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1880138, \"EndTime\": 1623173024.1880233, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4599390084402901, \"count\": 1, \"min\": 1.4599390084402901, \"max\": 1.4599390084402901}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1880617, \"EndTime\": 1623173024.1880713, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4855217924572173, \"count\": 1, \"min\": 1.4855217924572173, \"max\": 1.4855217924572173}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1880975, \"EndTime\": 1623173024.1881058, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4598741440545946, \"count\": 1, \"min\": 1.4598741440545946, \"max\": 1.4598741440545946}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1881433, \"EndTime\": 1623173024.188153, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.486354516892206, \"count\": 1, \"min\": 1.486354516892206, \"max\": 1.486354516892206}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1881819, \"EndTime\": 1623173024.1881893, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3442741800944011, \"count\": 1, \"min\": 1.3442741800944011, \"max\": 1.3442741800944011}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1882267, \"EndTime\": 1623173024.1882362, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3446797674269904, \"count\": 1, \"min\": 1.3446797674269904, \"max\": 1.3446797674269904}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1882672, \"EndTime\": 1623173024.188277, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3440684393019904, \"count\": 1, \"min\": 1.3440684393019904, \"max\": 1.3440684393019904}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1883154, \"EndTime\": 1623173024.1883247, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3450830557686941, \"count\": 1, \"min\": 1.3450830557686941, \"max\": 1.3450830557686941}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.188351, \"EndTime\": 1623173024.1883597, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3965516938709077, \"count\": 1, \"min\": 1.3965516938709077, \"max\": 1.3965516938709077}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1883974, \"EndTime\": 1623173024.1884065, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4228068077450706, \"count\": 1, \"min\": 1.4228068077450706, \"max\": 1.4228068077450706}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1884627, \"EndTime\": 1623173024.1884737, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.399212161109561, \"count\": 1, \"min\": 1.399212161109561, \"max\": 1.399212161109561}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.188499, \"EndTime\": 1623173024.1885066, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4183661847795759, \"count\": 1, \"min\": 1.4183661847795759, \"max\": 1.4183661847795759}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:44 INFO 140708987352896] #quality_metric: host=algo-1, epoch=3, train binary_classification_weighted_cross_entropy_objective <loss>=1.2618780851818265\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:44 INFO 140708987352896] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=binary_classification_weighted_cross_entropy_objective, value=1.2610069216773623\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:44 INFO 140708987352896] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:44 INFO 140708987352896] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:44 INFO 140708987352896] Saved checkpoint to \"/tmp/tmpfhmyl_5e/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:44 INFO 140708987352896] #progress_metric: host=algo-1, completed 13.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173023.1442423, \"EndTime\": 1623173024.1971803, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 183848.0, \"count\": 1, \"min\": 183848, \"max\": 183848}, \"Total Batches Seen\": {\"sum\": 184.0, \"count\": 1, \"min\": 184, \"max\": 184}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:44 INFO 140708987352896] #throughput_metric: host=algo-1, train throughput=40797.46887714846 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:23:45.268] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 11, \"duration\": 1071, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2686899, \"EndTime\": 1623173025.268767, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2597503284272693, \"count\": 1, \"min\": 1.2597503284272693, \"max\": 1.2597503284272693}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2688446, \"EndTime\": 1623173025.2688577, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2616957106817337, \"count\": 1, \"min\": 1.2616957106817337, \"max\": 1.2616957106817337}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2688873, \"EndTime\": 1623173025.2688963, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2598320733933221, \"count\": 1, \"min\": 1.2598320733933221, \"max\": 1.2598320733933221}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2689276, \"EndTime\": 1623173025.2689345, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2613695824032738, \"count\": 1, \"min\": 1.2613695824032738, \"max\": 1.2613695824032738}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.268961, \"EndTime\": 1623173025.2689674, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6358466041201636, \"count\": 1, \"min\": 1.6358466041201636, \"max\": 1.6358466041201636}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2689927, \"EndTime\": 1623173025.268999, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7148964524042039, \"count\": 1, \"min\": 1.7148964524042039, \"max\": 1.7148964524042039}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2690227, \"EndTime\": 1623173025.269029, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.63517577398391, \"count\": 1, \"min\": 1.63517577398391, \"max\": 1.63517577398391}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.269053, \"EndTime\": 1623173025.2690594, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7166793038504464, \"count\": 1, \"min\": 1.7166793038504464, \"max\": 1.7166793038504464}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2690828, \"EndTime\": 1623173025.269089, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.259102305094401, \"count\": 1, \"min\": 1.259102305094401, \"max\": 1.259102305094401}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.269112, \"EndTime\": 1623173025.2691183, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2624456394740513, \"count\": 1, \"min\": 1.2624456394740513, \"max\": 1.2624456394740513}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2691448, \"EndTime\": 1623173025.269151, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.260096166701544, \"count\": 1, \"min\": 1.260096166701544, \"max\": 1.260096166701544}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.269179, \"EndTime\": 1623173025.2691853, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2630109122140067, \"count\": 1, \"min\": 1.2630109122140067, \"max\": 1.2630109122140067}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2692134, \"EndTime\": 1623173025.2692204, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6262953055245535, \"count\": 1, \"min\": 1.6262953055245535, \"max\": 1.6262953055245535}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2692447, \"EndTime\": 1623173025.2692506, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.702169962565104, \"count\": 1, \"min\": 1.702169962565104, \"max\": 1.702169962565104}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2692804, \"EndTime\": 1623173025.269287, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6268839358375187, \"count\": 1, \"min\": 1.6268839358375187, \"max\": 1.6268839358375187}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2693143, \"EndTime\": 1623173025.2693207, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.702987022763207, \"count\": 1, \"min\": 1.702987022763207, \"max\": 1.702987022763207}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.269344, \"EndTime\": 1623173025.26935, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3060906328473771, \"count\": 1, \"min\": 1.3060906328473771, \"max\": 1.3060906328473771}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2693763, \"EndTime\": 1623173025.2693825, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3091215762183779, \"count\": 1, \"min\": 1.3091215762183779, \"max\": 1.3091215762183779}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2694092, \"EndTime\": 1623173025.2694154, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3061261407761346, \"count\": 1, \"min\": 1.3061261407761346, \"max\": 1.3061261407761346}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.26944, \"EndTime\": 1623173025.2694461, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.309132781982422, \"count\": 1, \"min\": 1.309132781982422, \"max\": 1.309132781982422}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.269472, \"EndTime\": 1623173025.269478, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4512388567243304, \"count\": 1, \"min\": 1.4512388567243304, \"max\": 1.4512388567243304}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2695048, \"EndTime\": 1623173025.269511, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.487342989966983, \"count\": 1, \"min\": 1.487342989966983, \"max\": 1.487342989966983}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.269537, \"EndTime\": 1623173025.2695432, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4515349019368489, \"count\": 1, \"min\": 1.4515349019368489, \"max\": 1.4515349019368489}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2695706, \"EndTime\": 1623173025.2695773, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4883307189941406, \"count\": 1, \"min\": 1.4883307189941406, \"max\": 1.4883307189941406}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2696042, \"EndTime\": 1623173025.269612, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3441927650088357, \"count\": 1, \"min\": 1.3441927650088357, \"max\": 1.3441927650088357}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.269638, \"EndTime\": 1623173025.2696445, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.344772696358817, \"count\": 1, \"min\": 1.344772696358817, \"max\": 1.344772696358817}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2696712, \"EndTime\": 1623173025.2696776, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3439675787062872, \"count\": 1, \"min\": 1.3439675787062872, \"max\": 1.3439675787062872}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2697039, \"EndTime\": 1623173025.26971, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3451774437313988, \"count\": 1, \"min\": 1.3451774437313988, \"max\": 1.3451774437313988}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2697365, \"EndTime\": 1623173025.2697425, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3914740658714657, \"count\": 1, \"min\": 1.3914740658714657, \"max\": 1.3914740658714657}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2697687, \"EndTime\": 1623173025.269775, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4109017086937314, \"count\": 1, \"min\": 1.4109017086937314, \"max\": 1.4109017086937314}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.269798, \"EndTime\": 1623173025.2698042, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3914310418991815, \"count\": 1, \"min\": 1.3914310418991815, \"max\": 1.3914310418991815}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2698274, \"EndTime\": 1623173025.2698333, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4105941162109374, \"count\": 1, \"min\": 1.4105941162109374, \"max\": 1.4105941162109374}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:45 INFO 140708987352896] #quality_metric: host=algo-1, epoch=4, train binary_classification_weighted_cross_entropy_objective <loss>=1.2597503284272693\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:45 INFO 140708987352896] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=binary_classification_weighted_cross_entropy_objective, value=1.259102305094401\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:45 INFO 140708987352896] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:45 INFO 140708987352896] Saving model for epoch: 4\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:45 INFO 140708987352896] Saved checkpoint to \"/tmp/tmpjk10r_33/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:45 INFO 140708987352896] #progress_metric: host=algo-1, completed 16.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173024.1974194, \"EndTime\": 1623173025.2800622, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 226810.0, \"count\": 1, \"min\": 226810, \"max\": 226810}, \"Total Batches Seen\": {\"sum\": 227.0, \"count\": 1, \"min\": 227, \"max\": 227}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:45 INFO 140708987352896] #throughput_metric: host=algo-1, train throughput=39678.75043032216 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:23:46.409] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 13, \"duration\": 1128, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4097767, \"EndTime\": 1623173026.4098508, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.258294443766276, \"count\": 1, \"min\": 1.258294443766276, \"max\": 1.258294443766276}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4099238, \"EndTime\": 1623173026.4099383, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2608887895856584, \"count\": 1, \"min\": 1.2608887895856584, \"max\": 1.2608887895856584}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4099872, \"EndTime\": 1623173026.4099994, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2583685840425036, \"count\": 1, \"min\": 1.2583685840425036, \"max\": 1.2583685840425036}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4100454, \"EndTime\": 1623173026.4100573, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2606224931989398, \"count\": 1, \"min\": 1.2606224931989398, \"max\": 1.2606224931989398}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4101012, \"EndTime\": 1623173026.4101129, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6173575061616443, \"count\": 1, \"min\": 1.6173575061616443, \"max\": 1.6173575061616443}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.410157, \"EndTime\": 1623173026.4101686, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7105184616815476, \"count\": 1, \"min\": 1.7105184616815476, \"max\": 1.7105184616815476}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4102144, \"EndTime\": 1623173026.4102256, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6169693952287947, \"count\": 1, \"min\": 1.6169693952287947, \"max\": 1.6169693952287947}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4102619, \"EndTime\": 1623173026.4102697, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7118521292550224, \"count\": 1, \"min\": 1.7118521292550224, \"max\": 1.7118521292550224}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4102995, \"EndTime\": 1623173026.4103074, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2578019743419828, \"count\": 1, \"min\": 1.2578019743419828, \"max\": 1.2578019743419828}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4103482, \"EndTime\": 1623173026.410358, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2614840334937687, \"count\": 1, \"min\": 1.2614840334937687, \"max\": 1.2614840334937687}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4103885, \"EndTime\": 1623173026.4103963, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2584960588727678, \"count\": 1, \"min\": 1.2584960588727678, \"max\": 1.2584960588727678}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4104276, \"EndTime\": 1623173026.4104338, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.261885721842448, \"count\": 1, \"min\": 1.261885721842448, \"max\": 1.261885721842448}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.410455, \"EndTime\": 1623173026.4104607, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6092219528924852, \"count\": 1, \"min\": 1.6092219528924852, \"max\": 1.6092219528924852}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4104965, \"EndTime\": 1623173026.410505, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6976062607538132, \"count\": 1, \"min\": 1.6976062607538132, \"max\": 1.6976062607538132}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4105387, \"EndTime\": 1623173026.4105473, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.609706795828683, \"count\": 1, \"min\": 1.609706795828683, \"max\": 1.609706795828683}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4105892, \"EndTime\": 1623173026.4106, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6981583629789807, \"count\": 1, \"min\": 1.6981583629789807, \"max\": 1.6981583629789807}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4106328, \"EndTime\": 1623173026.410644, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3054373910086496, \"count\": 1, \"min\": 1.3054373910086496, \"max\": 1.3054373910086496}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.410681, \"EndTime\": 1623173026.4106915, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3089824741908482, \"count\": 1, \"min\": 1.3089824741908482, \"max\": 1.3089824741908482}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4107242, \"EndTime\": 1623173026.4107351, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3054644499279204, \"count\": 1, \"min\": 1.3054644499279204, \"max\": 1.3054644499279204}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.410773, \"EndTime\": 1623173026.4107833, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3089905395507813, \"count\": 1, \"min\": 1.3089905395507813, \"max\": 1.3089905395507813}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4108167, \"EndTime\": 1623173026.4108276, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4429270440964472, \"count\": 1, \"min\": 1.4429270440964472, \"max\": 1.4429270440964472}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4108663, \"EndTime\": 1623173026.410877, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.485157210577102, \"count\": 1, \"min\": 1.485157210577102, \"max\": 1.485157210577102}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4109104, \"EndTime\": 1623173026.4109204, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4430187174479168, \"count\": 1, \"min\": 1.4430187174479168, \"max\": 1.4430187174479168}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4109573, \"EndTime\": 1623173026.4109669, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.48577346656436, \"count\": 1, \"min\": 1.48577346656436, \"max\": 1.48577346656436}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4110098, \"EndTime\": 1623173026.41102, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.34412157476516, \"count\": 1, \"min\": 1.34412157476516, \"max\": 1.34412157476516}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.411057, \"EndTime\": 1623173026.4110672, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3448065185546876, \"count\": 1, \"min\": 1.3448065185546876, \"max\": 1.3448065185546876}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4111092, \"EndTime\": 1623173026.4111197, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3438904709588915, \"count\": 1, \"min\": 1.3438904709588915, \"max\": 1.3438904709588915}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4111438, \"EndTime\": 1623173026.4111493, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3451830110095797, \"count\": 1, \"min\": 1.3451830110095797, \"max\": 1.3451830110095797}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4111753, \"EndTime\": 1623173026.4111848, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3889527544294085, \"count\": 1, \"min\": 1.3889527544294085, \"max\": 1.3889527544294085}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4112175, \"EndTime\": 1623173026.4112272, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4085464274088542, \"count\": 1, \"min\": 1.4085464274088542, \"max\": 1.4085464274088542}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4112675, \"EndTime\": 1623173026.4112773, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3891427176339286, \"count\": 1, \"min\": 1.3891427176339286, \"max\": 1.3891427176339286}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.411304, \"EndTime\": 1623173026.411314, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4092693365187872, \"count\": 1, \"min\": 1.4092693365187872, \"max\": 1.4092693365187872}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:46 INFO 140708987352896] #quality_metric: host=algo-1, epoch=5, train binary_classification_weighted_cross_entropy_objective <loss>=1.258294443766276\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:46 INFO 140708987352896] #early_stopping_criteria_metric: host=algo-1, epoch=5, criteria=binary_classification_weighted_cross_entropy_objective, value=1.2578019743419828\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:46 INFO 140708987352896] Epoch 5: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:46 INFO 140708987352896] Saving model for epoch: 5\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:46 INFO 140708987352896] Saved checkpoint to \"/tmp/tmpsjsdz_6x/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:46 INFO 140708987352896] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173025.2806773, \"EndTime\": 1623173026.4201276, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 269772.0, \"count\": 1, \"min\": 269772, \"max\": 269772}, \"Total Batches Seen\": {\"sum\": 270.0, \"count\": 1, \"min\": 270, \"max\": 270}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:46 INFO 140708987352896] #throughput_metric: host=algo-1, train throughput=37700.19311831574 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:23:47.373] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 15, \"duration\": 952, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3732615, \"EndTime\": 1623173027.3733165, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2571553504580544, \"count\": 1, \"min\": 1.2571553504580544, \"max\": 1.2571553504580544}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3733883, \"EndTime\": 1623173027.3734038, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.260514376685733, \"count\": 1, \"min\": 1.260514376685733, \"max\": 1.260514376685733}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3734472, \"EndTime\": 1623173027.373455, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.257224403018043, \"count\": 1, \"min\": 1.257224403018043, \"max\": 1.257224403018043}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3734894, \"EndTime\": 1623173027.3734999, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2602873796735492, \"count\": 1, \"min\": 1.2602873796735492, \"max\": 1.2602873796735492}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.373532, \"EndTime\": 1623173027.3735409, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5999225783575148, \"count\": 1, \"min\": 1.5999225783575148, \"max\": 1.5999225783575148}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3735745, \"EndTime\": 1623173027.373584, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7103995419456846, \"count\": 1, \"min\": 1.7103995419456846, \"max\": 1.7103995419456846}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3736217, \"EndTime\": 1623173027.373632, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.599707545689174, \"count\": 1, \"min\": 1.599707545689174, \"max\": 1.599707545689174}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.373669, \"EndTime\": 1623173027.3736787, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7114644368489584, \"count\": 1, \"min\": 1.7114644368489584, \"max\": 1.7114644368489584}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3737183, \"EndTime\": 1623173027.3737285, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2567794291178385, \"count\": 1, \"min\": 1.2567794291178385, \"max\": 1.2567794291178385}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.37377, \"EndTime\": 1623173027.3737793, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2610079171316964, \"count\": 1, \"min\": 1.2610079171316964, \"max\": 1.2610079171316964}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.373821, \"EndTime\": 1623173027.3738317, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2572959783644904, \"count\": 1, \"min\": 1.2572959783644904, \"max\": 1.2572959783644904}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3738723, \"EndTime\": 1623173027.3738823, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2612989516485305, \"count\": 1, \"min\": 1.2612989516485305, \"max\": 1.2612989516485305}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3739169, \"EndTime\": 1623173027.3739274, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5930078241257442, \"count\": 1, \"min\": 1.5930078241257442, \"max\": 1.5930078241257442}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3739595, \"EndTime\": 1623173027.3739705, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6972877429780506, \"count\": 1, \"min\": 1.6972877429780506, \"max\": 1.6972877429780506}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3740063, \"EndTime\": 1623173027.3740168, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5934226321265812, \"count\": 1, \"min\": 1.5934226321265812, \"max\": 1.5934226321265812}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3740501, \"EndTime\": 1623173027.3740597, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6977002912248884, \"count\": 1, \"min\": 1.6977002912248884, \"max\": 1.6977002912248884}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3740916, \"EndTime\": 1623173027.3741019, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3047998613630023, \"count\": 1, \"min\": 1.3047998613630023, \"max\": 1.3047998613630023}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3741393, \"EndTime\": 1623173027.3741498, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3090006481352308, \"count\": 1, \"min\": 1.3090006481352308, \"max\": 1.3090006481352308}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3741796, \"EndTime\": 1623173027.3741906, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.304821261451358, \"count\": 1, \"min\": 1.304821261451358, \"max\": 1.304821261451358}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.374227, \"EndTime\": 1623173027.374238, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3090069914318265, \"count\": 1, \"min\": 1.3090069914318265, \"max\": 1.3090069914318265}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3742743, \"EndTime\": 1623173027.3742845, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4351293538411458, \"count\": 1, \"min\": 1.4351293538411458, \"max\": 1.4351293538411458}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3743172, \"EndTime\": 1623173027.3743265, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4850612298874628, \"count\": 1, \"min\": 1.4850612298874628, \"max\": 1.4850612298874628}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3743615, \"EndTime\": 1623173027.3743682, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.435093979608445, \"count\": 1, \"min\": 1.435093979608445, \"max\": 1.435093979608445}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.374398, \"EndTime\": 1623173027.3744068, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4855237949916296, \"count\": 1, \"min\": 1.4855237949916296, \"max\": 1.4855237949916296}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3744497, \"EndTime\": 1623173027.3744602, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3440431329636346, \"count\": 1, \"min\": 1.3440431329636346, \"max\": 1.3440431329636346}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3745048, \"EndTime\": 1623173027.374515, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3448549586704799, \"count\": 1, \"min\": 1.3448549586704799, \"max\": 1.3448549586704799}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.374559, \"EndTime\": 1623173027.3745697, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3438201366606213, \"count\": 1, \"min\": 1.3438201366606213, \"max\": 1.3438201366606213}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3746014, \"EndTime\": 1623173027.3746078, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3452066010974701, \"count\": 1, \"min\": 1.3452066010974701, \"max\": 1.3452066010974701}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.374643, \"EndTime\": 1623173027.374653, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3868201933361235, \"count\": 1, \"min\": 1.3868201933361235, \"max\": 1.3868201933361235}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3746924, \"EndTime\": 1623173027.3747027, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.408904805501302, \"count\": 1, \"min\": 1.408904805501302, \"max\": 1.408904805501302}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3747473, \"EndTime\": 1623173027.374757, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3869866521926153, \"count\": 1, \"min\": 1.3869866521926153, \"max\": 1.3869866521926153}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3748076, \"EndTime\": 1623173027.374818, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.409896949404762, \"count\": 1, \"min\": 1.409896949404762, \"max\": 1.409896949404762}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:47 INFO 140708987352896] #quality_metric: host=algo-1, epoch=6, train binary_classification_weighted_cross_entropy_objective <loss>=1.2571553504580544\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:47 INFO 140708987352896] #early_stopping_criteria_metric: host=algo-1, epoch=6, criteria=binary_classification_weighted_cross_entropy_objective, value=1.2567794291178385\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:47 INFO 140708987352896] Saving model for epoch: 6\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:47 INFO 140708987352896] Saved checkpoint to \"/tmp/tmpo1zy2fqh/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:47 INFO 140708987352896] #progress_metric: host=algo-1, completed 23.333333333333332 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173026.4207714, \"EndTime\": 1623173027.383229, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 312734.0, \"count\": 1, \"min\": 312734, \"max\": 312734}, \"Total Batches Seen\": {\"sum\": 313.0, \"count\": 1, \"min\": 313, \"max\": 313}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:47 INFO 140708987352896] #throughput_metric: host=algo-1, train throughput=44633.28579634301 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:23:48.360] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 17, \"duration\": 976, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3606708, \"EndTime\": 1623173028.3607383, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2561972292945498, \"count\": 1, \"min\": 1.2561972292945498, \"max\": 1.2561972292945498}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3608084, \"EndTime\": 1623173028.3608212, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2601068667457218, \"count\": 1, \"min\": 1.2601068667457218, \"max\": 1.2601068667457218}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3608496, \"EndTime\": 1623173028.3608565, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2562613496326265, \"count\": 1, \"min\": 1.2562613496326265, \"max\": 1.2562613496326265}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3608818, \"EndTime\": 1623173028.3608882, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.259911131359282, \"count\": 1, \"min\": 1.259911131359282, \"max\": 1.259911131359282}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.360912, \"EndTime\": 1623173028.3609183, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5838551228841147, \"count\": 1, \"min\": 1.5838551228841147, \"max\": 1.5838551228841147}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.360942, \"EndTime\": 1623173028.3609476, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.707055430094401, \"count\": 1, \"min\": 1.707055430094401, \"max\": 1.707055430094401}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3609743, \"EndTime\": 1623173028.360981, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5837712881905692, \"count\": 1, \"min\": 1.5837712881905692, \"max\": 1.5837712881905692}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3610048, \"EndTime\": 1623173028.3610108, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7079332188197545, \"count\": 1, \"min\": 1.7079332188197545, \"max\": 1.7079332188197545}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3610353, \"EndTime\": 1623173028.3610413, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.255912110828218, \"count\": 1, \"min\": 1.255912110828218, \"max\": 1.255912110828218}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.361069, \"EndTime\": 1623173028.3610759, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2605332583472841, \"count\": 1, \"min\": 1.2605332583472841, \"max\": 1.2605332583472841}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.361103, \"EndTime\": 1623173028.3611095, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2563148513067337, \"count\": 1, \"min\": 1.2563148513067337, \"max\": 1.2563148513067337}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.361133, \"EndTime\": 1623173028.361139, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2607494361514138, \"count\": 1, \"min\": 1.2607494361514138, \"max\": 1.2607494361514138}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3611658, \"EndTime\": 1623173028.3611724, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.57803221929641, \"count\": 1, \"min\": 1.57803221929641, \"max\": 1.57803221929641}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3611975, \"EndTime\": 1623173028.3612037, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6939283432733445, \"count\": 1, \"min\": 1.6939283432733445, \"max\": 1.6939283432733445}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3612273, \"EndTime\": 1623173028.3612332, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5783917875744047, \"count\": 1, \"min\": 1.5783917875744047, \"max\": 1.5783917875744047}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3612592, \"EndTime\": 1623173028.3612652, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6942523251488095, \"count\": 1, \"min\": 1.6942523251488095, \"max\": 1.6942523251488095}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3612912, \"EndTime\": 1623173028.3612976, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.304182878766741, \"count\": 1, \"min\": 1.304182878766741, \"max\": 1.304182878766741}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3613238, \"EndTime\": 1623173028.3613303, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3088785109747023, \"count\": 1, \"min\": 1.3088785109747023, \"max\": 1.3088785109747023}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3613563, \"EndTime\": 1623173028.3613625, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.304200222923642, \"count\": 1, \"min\": 1.304200222923642, \"max\": 1.304200222923642}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3613887, \"EndTime\": 1623173028.361395, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3088837222144718, \"count\": 1, \"min\": 1.3088837222144718, \"max\": 1.3088837222144718}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3614206, \"EndTime\": 1623173028.3614268, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.427718792143322, \"count\": 1, \"min\": 1.427718792143322, \"max\": 1.427718792143322}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3614533, \"EndTime\": 1623173028.3614595, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4836591055733817, \"count\": 1, \"min\": 1.4836591055733817, \"max\": 1.4836591055733817}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.361483, \"EndTime\": 1623173028.3614888, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4275968250093005, \"count\": 1, \"min\": 1.4275968250093005, \"max\": 1.4275968250093005}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.361512, \"EndTime\": 1623173028.361518, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4840238414946056, \"count\": 1, \"min\": 1.4840238414946056, \"max\": 1.4840238414946056}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3615427, \"EndTime\": 1623173028.361549, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3439484122140066, \"count\": 1, \"min\": 1.3439484122140066, \"max\": 1.3439484122140066}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3615718, \"EndTime\": 1623173028.3615777, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3448612438383556, \"count\": 1, \"min\": 1.3448612438383556, \"max\": 1.3448612438383556}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3616035, \"EndTime\": 1623173028.3616097, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3437398608979725, \"count\": 1, \"min\": 1.3437398608979725, \"max\": 1.3437398608979725}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3616357, \"EndTime\": 1623173028.361642, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3451970825195312, \"count\": 1, \"min\": 1.3451970825195312, \"max\": 1.3451970825195312}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3616772, \"EndTime\": 1623173028.3616836, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3852002810523623, \"count\": 1, \"min\": 1.3852002810523623, \"max\": 1.3852002810523623}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3617072, \"EndTime\": 1623173028.3617132, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.408532499767485, \"count\": 1, \"min\": 1.408532499767485, \"max\": 1.408532499767485}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3617356, \"EndTime\": 1623173028.3617418, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3853890497116816, \"count\": 1, \"min\": 1.3853890497116816, \"max\": 1.3853890497116816}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.361765, \"EndTime\": 1623173028.3617709, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4097653532482328, \"count\": 1, \"min\": 1.4097653532482328, \"max\": 1.4097653532482328}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:48 INFO 140708987352896] #quality_metric: host=algo-1, epoch=7, train binary_classification_weighted_cross_entropy_objective <loss>=1.2561972292945498\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:48 INFO 140708987352896] #early_stopping_criteria_metric: host=algo-1, epoch=7, criteria=binary_classification_weighted_cross_entropy_objective, value=1.255912110828218\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:48 INFO 140708987352896] Saving model for epoch: 7\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:48 INFO 140708987352896] Saved checkpoint to \"/tmp/tmpws4bun6o/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:48 INFO 140708987352896] #progress_metric: host=algo-1, completed 26.666666666666668 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173027.3837905, \"EndTime\": 1623173028.3707368, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 355696.0, \"count\": 1, \"min\": 355696, \"max\": 355696}, \"Total Batches Seen\": {\"sum\": 356.0, \"count\": 1, \"min\": 356, \"max\": 356}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:48 INFO 140708987352896] #throughput_metric: host=algo-1, train throughput=43525.88606959574 records/second\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:23:49.230] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 19, \"duration\": 859, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2306778, \"EndTime\": 1623173029.230739, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2553646080380394, \"count\": 1, \"min\": 1.2553646080380394, \"max\": 1.2553646080380394}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2308095, \"EndTime\": 1623173029.2308245, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.259874283563523, \"count\": 1, \"min\": 1.259874283563523, \"max\": 1.259874283563523}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2308638, \"EndTime\": 1623173029.2308748, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.255423363095238, \"count\": 1, \"min\": 1.255423363095238, \"max\": 1.255423363095238}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.230915, \"EndTime\": 1623173029.2309244, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2597055533272878, \"count\": 1, \"min\": 1.2597055533272878, \"max\": 1.2597055533272878}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.230962, \"EndTime\": 1623173029.2309718, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5689780564081102, \"count\": 1, \"min\": 1.5689780564081102, \"max\": 1.5689780564081102}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2310154, \"EndTime\": 1623173029.231026, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7051744820731027, \"count\": 1, \"min\": 1.7051744820731027, \"max\": 1.7051744820731027}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2310612, \"EndTime\": 1623173029.2310724, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.568986580984933, \"count\": 1, \"min\": 1.568986580984933, \"max\": 1.568986580984933}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2311065, \"EndTime\": 1623173029.2311172, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7059116501581102, \"count\": 1, \"min\": 1.7059116501581102, \"max\": 1.7059116501581102}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2311513, \"EndTime\": 1623173029.2311609, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2551521446591332, \"count\": 1, \"min\": 1.2551521446591332, \"max\": 1.2551521446591332}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2311878, \"EndTime\": 1623173029.2311983, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2602562677292597, \"count\": 1, \"min\": 1.2602562677292597, \"max\": 1.2602562677292597}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2312355, \"EndTime\": 1623173029.231247, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2554771728515626, \"count\": 1, \"min\": 1.2554771728515626, \"max\": 1.2554771728515626}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2312841, \"EndTime\": 1623173029.2312949, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2604208911714099, \"count\": 1, \"min\": 1.2604208911714099, \"max\": 1.2604208911714099}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.231326, \"EndTime\": 1623173029.2313359, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5641036275227864, \"count\": 1, \"min\": 1.5641036275227864, \"max\": 1.5641036275227864}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.231371, \"EndTime\": 1623173029.2313776, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6921219773065477, \"count\": 1, \"min\": 1.6921219773065477, \"max\": 1.6921219773065477}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.231401, \"EndTime\": 1623173029.2314088, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.564419939313616, \"count\": 1, \"min\": 1.564419939313616, \"max\": 1.564419939313616}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2314487, \"EndTime\": 1623173029.231458, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6923800237746465, \"count\": 1, \"min\": 1.6923800237746465, \"max\": 1.6923800237746465}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.231503, \"EndTime\": 1623173029.2315135, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3035966477167038, \"count\": 1, \"min\": 1.3035966477167038, \"max\": 1.3035966477167038}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2315593, \"EndTime\": 1623173029.2315702, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3088277646019346, \"count\": 1, \"min\": 1.3088277646019346, \"max\": 1.3088277646019346}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2316136, \"EndTime\": 1623173029.231624, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3036109517415364, \"count\": 1, \"min\": 1.3036109517415364, \"max\": 1.3036109517415364}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2316577, \"EndTime\": 1623173029.2316644, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3088321896507626, \"count\": 1, \"min\": 1.3088321896507626, \"max\": 1.3088321896507626}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2316985, \"EndTime\": 1623173029.2317088, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4207203819638208, \"count\": 1, \"min\": 1.4207203819638208, \"max\": 1.4207203819638208}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2317524, \"EndTime\": 1623173029.2317636, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4827652297247025, \"count\": 1, \"min\": 1.4827652297247025, \"max\": 1.4827652297247025}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2318084, \"EndTime\": 1623173029.2318192, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4205500124976749, \"count\": 1, \"min\": 1.4205500124976749, \"max\": 1.4205500124976749}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2318485, \"EndTime\": 1623173029.2318556, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4830605788457962, \"count\": 1, \"min\": 1.4830605788457962, \"max\": 1.4830605788457962}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.231897, \"EndTime\": 1623173029.2319088, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3438521321614583, \"count\": 1, \"min\": 1.3438521321614583, \"max\": 1.3438521321614583}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2319536, \"EndTime\": 1623173029.2319643, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.344860089983259, \"count\": 1, \"min\": 1.344860089983259, \"max\": 1.344860089983259}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2319922, \"EndTime\": 1623173029.232, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3436537272135416, \"count\": 1, \"min\": 1.3436537272135416, \"max\": 1.3436537272135416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2320342, \"EndTime\": 1623173029.2320442, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3451976492745537, \"count\": 1, \"min\": 1.3451976492745537, \"max\": 1.3451976492745537}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.232084, \"EndTime\": 1623173029.2320945, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3841773042224703, \"count\": 1, \"min\": 1.3841773042224703, \"max\": 1.3841773042224703}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2321267, \"EndTime\": 1623173029.232138, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4075413353329613, \"count\": 1, \"min\": 1.4075413353329613, \"max\": 1.4075413353329613}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2321749, \"EndTime\": 1623173029.2321854, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.384324195498512, \"count\": 1, \"min\": 1.384324195498512, \"max\": 1.384324195498512}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2322173, \"EndTime\": 1623173029.2322285, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4092294980003721, \"count\": 1, \"min\": 1.4092294980003721, \"max\": 1.4092294980003721}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:49 INFO 140708987352896] #quality_metric: host=algo-1, epoch=8, train binary_classification_weighted_cross_entropy_objective <loss>=1.2553646080380394\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:49 INFO 140708987352896] #early_stopping_criteria_metric: host=algo-1, epoch=8, criteria=binary_classification_weighted_cross_entropy_objective, value=1.2551521446591332\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:49 INFO 140708987352896] Saving model for epoch: 8\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:49 INFO 140708987352896] Saved checkpoint to \"/tmp/tmplbu989xf/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:49 INFO 140708987352896] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173028.3713307, \"EndTime\": 1623173029.240722, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 398658.0, \"count\": 1, \"min\": 398658, \"max\": 398658}, \"Total Batches Seen\": {\"sum\": 399.0, \"count\": 1, \"min\": 399, \"max\": 399}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:49 INFO 140708987352896] #throughput_metric: host=algo-1, train throughput=49410.45729293315 records/second\u001b[0m\n",
      "\n",
      "2021-06-08 17:24:00 Uploading - Uploading generated training model\n",
      "2021-06-08 17:24:00 Completed - Training job completed\n",
      "\u001b[34m[2021-06-08 17:23:50.317] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 21, \"duration\": 1076, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.317209, \"EndTime\": 1623173030.3172705, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 0}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2546187627883185, \"count\": 1, \"min\": 1.2546187627883185, \"max\": 1.2546187627883185}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3173456, \"EndTime\": 1623173030.3173625, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 1}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2596591796875, \"count\": 1, \"min\": 1.2596591796875, \"max\": 1.2596591796875}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3174088, \"EndTime\": 1623173030.3174195, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 2}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2546720072428386, \"count\": 1, \"min\": 1.2546720072428386, \"max\": 1.2546720072428386}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3174574, \"EndTime\": 1623173030.3174663, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 3}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.259513947986421, \"count\": 1, \"min\": 1.259513947986421, \"max\": 1.259513947986421}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.317502, \"EndTime\": 1623173030.317511, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 4}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5548732270740326, \"count\": 1, \"min\": 1.5548732270740326, \"max\": 1.5548732270740326}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3175461, \"EndTime\": 1623173030.317555, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 5}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7042303699311756, \"count\": 1, \"min\": 1.7042303699311756, \"max\": 1.7042303699311756}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.317587, \"EndTime\": 1623173030.3175964, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 6}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5549391929989769, \"count\": 1, \"min\": 1.5549391929989769, \"max\": 1.5549391929989769}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3176343, \"EndTime\": 1623173030.3176444, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 7}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.7048635995047432, \"count\": 1, \"min\": 1.7048635995047432, \"max\": 1.7048635995047432}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.317683, \"EndTime\": 1623173030.3176937, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 8}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2544656749906995, \"count\": 1, \"min\": 1.2544656749906995, \"max\": 1.2544656749906995}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3177345, \"EndTime\": 1623173030.3177454, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 9}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2600114339192707, \"count\": 1, \"min\": 1.2600114339192707, \"max\": 1.2600114339192707}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3177853, \"EndTime\": 1623173030.317796, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 10}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2547350841703868, \"count\": 1, \"min\": 1.2547350841703868, \"max\": 1.2547350841703868}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3178365, \"EndTime\": 1623173030.317847, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 11}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.2601394478934151, \"count\": 1, \"min\": 1.2601394478934151, \"max\": 1.2601394478934151}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.317891, \"EndTime\": 1623173030.317902, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 12}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.5508021821521578, \"count\": 1, \"min\": 1.5508021821521578, \"max\": 1.5508021821521578}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3179405, \"EndTime\": 1623173030.3179517, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 13}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6911060064406622, \"count\": 1, \"min\": 1.6911060064406622, \"max\": 1.6911060064406622}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3179924, \"EndTime\": 1623173030.318003, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 14}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.551083754766555, \"count\": 1, \"min\": 1.551083754766555, \"max\": 1.551083754766555}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3180404, \"EndTime\": 1623173030.318051, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 15}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.6913211611793155, \"count\": 1, \"min\": 1.6913211611793155, \"max\": 1.6913211611793155}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3180902, \"EndTime\": 1623173030.3181021, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 16}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3030398908342633, \"count\": 1, \"min\": 1.3030398908342633, \"max\": 1.3030398908342633}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.318137, \"EndTime\": 1623173030.3181453, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 17}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3087754807245164, \"count\": 1, \"min\": 1.3087754807245164, \"max\": 1.3087754807245164}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3181775, \"EndTime\": 1623173030.3181872, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 18}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3030518464587983, \"count\": 1, \"min\": 1.3030518464587983, \"max\": 1.3030518464587983}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3182204, \"EndTime\": 1623173030.318229, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 19}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3087792547316779, \"count\": 1, \"min\": 1.3087792547316779, \"max\": 1.3087792547316779}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3182638, \"EndTime\": 1623173030.3182726, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 20}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4142587338402157, \"count\": 1, \"min\": 1.4142587338402157, \"max\": 1.4142587338402157}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.318306, \"EndTime\": 1623173030.318315, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 21}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4825999973842077, \"count\": 1, \"min\": 1.4825999973842077, \"max\": 1.4825999973842077}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3183494, \"EndTime\": 1623173030.3183582, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 22}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4140685163225446, \"count\": 1, \"min\": 1.4140685163225446, \"max\": 1.4140685163225446}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.318394, \"EndTime\": 1623173030.3184044, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 23}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4828478873116628, \"count\": 1, \"min\": 1.4828478873116628, \"max\": 1.4828478873116628}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.318441, \"EndTime\": 1623173030.31845, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 24}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3437565133231026, \"count\": 1, \"min\": 1.3437565133231026, \"max\": 1.3437565133231026}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3184903, \"EndTime\": 1623173030.3185003, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 25}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3448465183803013, \"count\": 1, \"min\": 1.3448465183803013, \"max\": 1.3448465183803013}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3185396, \"EndTime\": 1623173030.318549, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 26}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3435581635974703, \"count\": 1, \"min\": 1.3435581635974703, \"max\": 1.3435581635974703}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.3185863, \"EndTime\": 1623173030.318597, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 27}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3451863606770833, \"count\": 1, \"min\": 1.3451863606770833, \"max\": 1.3451863606770833}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.318635, \"EndTime\": 1623173030.3186457, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 28}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3836868533179874, \"count\": 1, \"min\": 1.3836868533179874, \"max\": 1.3836868533179874}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.318686, \"EndTime\": 1623173030.3186958, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 29}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4078705284481956, \"count\": 1, \"min\": 1.4078705284481956, \"max\": 1.4078705284481956}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.318735, \"EndTime\": 1623173030.3187447, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 30}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.3837635948544458, \"count\": 1, \"min\": 1.3837635948544458, \"max\": 1.3837635948544458}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173030.318784, \"EndTime\": 1623173030.318795, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"model\": 31}, \"Metrics\": {\"train_binary_classification_weighted_cross_entropy_objective\": {\"sum\": 1.4093355858212426, \"count\": 1, \"min\": 1.4093355858212426, \"max\": 1.4093355858212426}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #quality_metric: host=algo-1, epoch=9, train binary_classification_weighted_cross_entropy_objective <loss>=1.2546187627883185\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #early_stopping_criteria_metric: host=algo-1, epoch=9, criteria=binary_classification_weighted_cross_entropy_objective, value=1.2544656749906995\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] Saving model for epoch: 9\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] Saved checkpoint to \"/tmp/tmpa3dtwbu1/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173029.2409396, \"EndTime\": 1623173030.328283, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 441620.0, \"count\": 1, \"min\": 441620, \"max\": 441620}, \"Total Batches Seen\": {\"sum\": 442.0, \"count\": 1, \"min\": 442, \"max\": 442}, \"Max Records Seen Between Resets\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Max Batches Seen Between Resets\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}, \"Reset Count\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Number of Records Since Last Reset\": {\"sum\": 42962.0, \"count\": 1, \"min\": 42962, \"max\": 42962}, \"Number of Batches Since Last Reset\": {\"sum\": 43.0, \"count\": 1, \"min\": 43, \"max\": 43}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #throughput_metric: host=algo-1, train throughput=39506.72166344379 records/second\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 WARNING 140708987352896] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 WARNING 140708987352896] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:23:50.332] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 23, \"duration\": 3, \"num_examples\": 1, \"num_bytes\": 372000}\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:23:50.465] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 129, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m[2021-06-08 17:23:50.603] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 115, \"num_examples\": 43, \"num_bytes\": 15981864}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #train_score (algo-1) : ('binary_classification_weighted_cross_entropy_objective', 1.2516525976762531)\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #train_score (algo-1) : ('binary_classification_accuracy', 0.9875936874447185)\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #train_score (algo-1) : ('binary_f_1.000', 0.003738317757009346)\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #train_score (algo-1) : ('precision', 0.3333333333333333)\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #train_score (algo-1) : ('recall', 0.0018796992481203006)\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #train_score (algo-1) : ('roc_auc_score', 0.6831440639071164)\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #quality_metric: host=algo-1, train binary_classification_weighted_cross_entropy_objective <loss>=1.2516525976762531\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #quality_metric: host=algo-1, train binary_classification_accuracy <score>=0.9875936874447185\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #quality_metric: host=algo-1, train binary_f_1.000 <score>=0.003738317757009346\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #quality_metric: host=algo-1, train precision <score>=0.3333333333333333\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #quality_metric: host=algo-1, train recall <score>=0.0018796992481203006\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] #quality_metric: host=algo-1, train roc_auc_score <score>=0.6831440639071164\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] Best model found for hyperparameters: {\"optimizer\": \"adam\", \"learning_rate\": 0.005, \"wd\": 0.01, \"l1\": 0.0, \"lr_scheduler_step\": 10, \"lr_scheduler_factor\": 0.99, \"lr_scheduler_minimum_lr\": 1e-05}\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] Saved checkpoint to \"/tmp/tmpr9097ttf/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[06/08/2021 17:23:50 INFO 140708987352896] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623173019.6763008, \"EndTime\": 1623173030.6266181, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 240.64230918884277, \"count\": 1, \"min\": 240.64230918884277, \"max\": 240.64230918884277}, \"epochs\": {\"sum\": 30.0, \"count\": 1, \"min\": 30, \"max\": 30}, \"check_early_stopping.time\": {\"sum\": 5.465507507324219, \"count\": 10, \"min\": 0.1857280731201172, \"max\": 0.8451938629150391}, \"update.time\": {\"sum\": 10376.260757446289, \"count\": 10, \"min\": 866.9922351837158, \"max\": 1137.0728015899658}, \"finalize.time\": {\"sum\": 289.69717025756836, \"count\": 1, \"min\": 289.69717025756836, \"max\": 289.69717025756836}, \"setuptime\": {\"sum\": 18.98479461669922, \"count\": 1, \"min\": 18.98479461669922, \"max\": 18.98479461669922}, \"totaltime\": {\"sum\": 11151.829719543457, \"count\": 1, \"min\": 11151.829719543457, \"max\": 11151.829719543457}}}\n",
      "\u001b[0m\n",
      "Training seconds: 67\n",
      "Billable seconds: 67\n"
     ]
    }
   ],
   "source": [
    "LinearLearner_2.fit(formatted_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf43f9",
   "metadata": {},
   "source": [
    "The roc_auc_score is 0.6831. I decided to just go with the first model: LinearLearner_1 as the ROC_AUC_Score didn't improve much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b85dbc",
   "metadata": {},
   "source": [
    "## Custom Model - Pytorch Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fbed41",
   "metadata": {},
   "source": [
    "3.1 Compile model, train and predict documents for the Pytorch Neural Network model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "26037491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m## It lays the neural network structure: how many layers and how many nodes within each layer \u001b[39;49;00m\n",
      "\u001b[37m# In the Class SimpleNet, it enables input_dim and hidden_dim to be input information\u001b[39;49;00m\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mSimpleNet\u001b[39;49;00m(nn.Module):\n",
      "    \n",
      "    \u001b[37m## TODO: Define the init function\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, input_dim, hidden_dim, output_dim):\n",
      "        \u001b[33m'''Defines layers of a neural network.\u001b[39;49;00m\n",
      "\u001b[33m           :param input_dim: Number of input features\u001b[39;49;00m\n",
      "\u001b[33m           :param hidden_dim: Size of hidden layer(s)\u001b[39;49;00m\n",
      "\u001b[33m           :param output_dim: Number of outputs\u001b[39;49;00m\n",
      "\u001b[33m         '''\u001b[39;49;00m\n",
      "        \u001b[36msuper\u001b[39;49;00m(SimpleNet, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\n",
      "        \n",
      "        \u001b[37m# define all layers, here\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.fc1 = nn.Linear(input_dim, hidden_dim)\n",
      "        \u001b[36mself\u001b[39;49;00m.fc2 = nn.Linear(hidden_dim, output_dim)\n",
      "        \u001b[36mself\u001b[39;49;00m.drop = nn.Dropout(\u001b[34m0.3\u001b[39;49;00m) \u001b[37m#this is used to prevent overfitting, as nodes were dropped out randomly during the training\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.sig = nn.Sigmoid()\n",
      "        \n",
      "    \n",
      "    \u001b[37m## TODO: Define the feedforward behavior of the network\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\n",
      "        \u001b[33m'''Feedforward behavior of the net.\u001b[39;49;00m\n",
      "\u001b[33m           :param x: A batch of input features\u001b[39;49;00m\n",
      "\u001b[33m           :return: A single, sigmoid activated value\u001b[39;49;00m\n",
      "\u001b[33m         '''\u001b[39;49;00m\n",
      "        \u001b[37m# your code, here\u001b[39;49;00m\n",
      "        out = F.relu(\u001b[36mself\u001b[39;49;00m.fc1(x)) \n",
      "        \u001b[37m#F.relu is the function that Max(x,0)\u001b[39;49;00m\n",
      "        \u001b[37m#for example, input has two dimensions x1, x2\u001b[39;49;00m\n",
      "        \u001b[37m# in the hidden layer, node 1 = Sigmoid (w1x1+w2x2+c) \u001b[39;49;00m\n",
      "        \u001b[37m# here we use relu function instead\u001b[39;49;00m\n",
      "        \u001b[37m# node 1 = Max(w1x1+w2x2+c, 0)\u001b[39;49;00m\n",
      "        out = \u001b[36mself\u001b[39;49;00m.drop(out)\n",
      "        out = \u001b[36mself\u001b[39;49;00m.fc2(out)\n",
      "        \n",
      "        \u001b[37m#usually you only apply relu function to the hidden layer \u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.sig(out)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize Source/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a42332",
   "metadata": {},
   "source": [
    "3.2 Prepare and upload the data for Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "4053d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def make_csv(x, y, filename, data_dir):\n",
    "    '''Merges features and labels and converts them into one csv file with labels in the first column.\n",
    "       :param x: Data features\n",
    "       :param y: Data labels\n",
    "       :param file_name: Name of csv file, ex. 'train.csv'\n",
    "       :param data_dir: The directory where files will be saved\n",
    "       '''\n",
    "    # make data dir, if it does not exist\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    # your code here\n",
    "    file = pd.concat([pd.DataFrame(y), pd.DataFrame(x)], axis=1)\n",
    "    file.to_csv(os.path.join(data_dir, filename),header=False, index=False)\n",
    "    \n",
    "    # nothing is returned, but a print statement indicates that the function has run\n",
    "    print('Path created: '+str(data_dir)+'/'+str(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "476a9940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path created: ../data/Pytorch_train.csv\n"
     ]
    }
   ],
   "source": [
    "make_csv(train_features, train_labels, 'Pytorch_train.csv', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "4f59c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pytorch = os.path.join(data_dir, 'Pytorch_train.csv')\n",
    "Pytorch_train_location = session.upload_data(path=path_pytorch, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31af15fe",
   "metadata": {},
   "source": [
    "3.3 Instantiate a Pytorch model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "6fdc2295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a PyTorch wrapper\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "\n",
    "#the estimator is made of three components: normal SageMaker estimator components, Pytorch components and \n",
    "#hyperparameters that can be parsed into the model \n",
    "\n",
    "estimator = PyTorch(entry_point= 'train.py',\n",
    "                    source_dir = 'Source', #here we need to use not only train.py, but also model.py; so I specify the folder location \n",
    "                    framework_version ='1.0',\n",
    "                    py_version = 'py3',\n",
    "                    role = role,\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.m5.2xlarge',\n",
    "                    output_path = output_path,\n",
    "                    sagemaker_session=session,\n",
    "                    hyperparameters={\n",
    "                        'input_dim': 81,  # num of features\n",
    "                        'hidden_dim': 55,\n",
    "                        'output_dim': 1,\n",
    "                        'epochs': 150 # could change to higher\n",
    "                    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "aba9e2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-08 19:00:33 Starting - Starting the training job...\n",
      "2021-06-08 19:00:34 Starting - Launching requested ML instancesProfilerReport-1623178832: InProgress\n",
      "......\n",
      "2021-06-08 19:01:45 Starting - Preparing the instances for training......\n",
      "2021-06-08 19:03:03 Downloading - Downloading input data\n",
      "2021-06-08 19:03:03 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-06-08 19:03:16,057 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-06-08 19:03:16,060 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-06-08 19:03:16,072 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-06-08 19:03:17,484 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-06-08 19:03:17,715 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2021-06-08 19:03:17,715 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2021-06-08 19:03:17,715 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2021-06-08 19:03:17,715 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-m6og_hgc/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 21.1.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2021-06-08 19:03:19,533 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-06-08 19:03:19,544 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"input_dim\": 81,\n",
      "        \"hidden_dim\": 55,\n",
      "        \"epochs\": 150,\n",
      "        \"output_dim\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2021-06-08-19-00-32-805\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-1-178050996200/sagemaker-pytorch-2021-06-08-19-00-32-805/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":150,\"hidden_dim\":55,\"input_dim\":81,\"output_dim\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-1-178050996200/sagemaker-pytorch-2021-06-08-19-00-32-805/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":150,\"hidden_dim\":55,\"input_dim\":81,\"output_dim\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2021-06-08-19-00-32-805\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-1-178050996200/sagemaker-pytorch-2021-06-08-19-00-32-805/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"150\",\"--hidden_dim\",\"55\",\"--input_dim\",\"81\",\"--output_dim\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_DIM=81\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=55\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=150\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 150 --hidden_dim 55 --input_dim 81 --output_dim 1\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "2021-06-08 19:03:23 Training - Training image download completed. Training in progress.\u001b[34mGet data loader.\u001b[0m\n",
      "\u001b[34mEpoch: 1, Loss: 0.1266595368492528\u001b[0m\n",
      "\u001b[34mEpoch: 2, Loss: 0.0718487515904209\u001b[0m\n",
      "\u001b[34mEpoch: 3, Loss: 0.06787092815959893\u001b[0m\n",
      "\u001b[34mEpoch: 4, Loss: 0.06688677732295002\u001b[0m\n",
      "\u001b[34mEpoch: 5, Loss: 0.06565327700740281\u001b[0m\n",
      "\u001b[34mEpoch: 6, Loss: 0.0643979408660449\u001b[0m\n",
      "\u001b[34mEpoch: 7, Loss: 0.06400867494189047\u001b[0m\n",
      "\u001b[34mEpoch: 8, Loss: 0.0635447744439478\u001b[0m\n",
      "\u001b[34mEpoch: 9, Loss: 0.062228942055038976\u001b[0m\n",
      "\u001b[34mEpoch: 10, Loss: 0.0620295466887044\u001b[0m\n",
      "\u001b[34mEpoch: 11, Loss: 0.06083000283563576\u001b[0m\n",
      "\u001b[34mEpoch: 12, Loss: 0.060662712257388715\u001b[0m\n",
      "\u001b[34mEpoch: 13, Loss: 0.05978735765772095\u001b[0m\n",
      "\u001b[34mEpoch: 14, Loss: 0.05902719725799259\u001b[0m\n",
      "\u001b[34mEpoch: 15, Loss: 0.05773708869916542\u001b[0m\n",
      "\u001b[34mEpoch: 16, Loss: 0.057893822255816\u001b[0m\n",
      "\u001b[34mEpoch: 17, Loss: 0.0572269275241221\u001b[0m\n",
      "\u001b[34mEpoch: 18, Loss: 0.05644856079223765\u001b[0m\n",
      "\u001b[34mEpoch: 19, Loss: 0.05537673622547161\u001b[0m\n",
      "\u001b[34mEpoch: 20, Loss: 0.05516806559448707\u001b[0m\n",
      "\u001b[34mEpoch: 21, Loss: 0.05441421514981249\u001b[0m\n",
      "\u001b[34mEpoch: 22, Loss: 0.05401211517649548\u001b[0m\n",
      "\u001b[34mEpoch: 23, Loss: 0.053866797543984525\u001b[0m\n",
      "\u001b[34mEpoch: 24, Loss: 0.05272904706431464\u001b[0m\n",
      "\u001b[34mEpoch: 25, Loss: 0.05240915599902759\u001b[0m\n",
      "\u001b[34mEpoch: 26, Loss: 0.051892384100938216\u001b[0m\n",
      "\u001b[34mEpoch: 27, Loss: 0.052088930906999543\u001b[0m\n",
      "\u001b[34mEpoch: 28, Loss: 0.05129278187190981\u001b[0m\n",
      "\u001b[34mEpoch: 29, Loss: 0.050869928840603235\u001b[0m\n",
      "\u001b[34mEpoch: 30, Loss: 0.050207241504852264\u001b[0m\n",
      "\u001b[34mEpoch: 31, Loss: 0.04914840300348476\u001b[0m\n",
      "\u001b[34mEpoch: 32, Loss: 0.04835305735815339\u001b[0m\n",
      "\u001b[34mEpoch: 33, Loss: 0.049622214950865044\u001b[0m\n",
      "\u001b[34mEpoch: 34, Loss: 0.04836661930832114\u001b[0m\n",
      "\u001b[34mEpoch: 35, Loss: 0.04864138086226636\u001b[0m\n",
      "\u001b[34mEpoch: 36, Loss: 0.04848606587308625\u001b[0m\n",
      "\u001b[34mEpoch: 37, Loss: 0.04852012749220843\u001b[0m\n",
      "\u001b[34mEpoch: 38, Loss: 0.047081819049448574\u001b[0m\n",
      "\u001b[34mEpoch: 39, Loss: 0.04729441079931954\u001b[0m\n",
      "\u001b[34mEpoch: 40, Loss: 0.04678702283334652\u001b[0m\n",
      "\u001b[34mEpoch: 41, Loss: 0.046470102338865955\u001b[0m\n",
      "\u001b[34mEpoch: 42, Loss: 0.04676050198620595\u001b[0m\n",
      "\u001b[34mEpoch: 43, Loss: 0.04654133518107258\u001b[0m\n",
      "\u001b[34mEpoch: 44, Loss: 0.046084066100385304\u001b[0m\n",
      "\u001b[34mEpoch: 45, Loss: 0.046212394656668904\u001b[0m\n",
      "\u001b[34mEpoch: 46, Loss: 0.0437795588839522\u001b[0m\n",
      "\u001b[34mEpoch: 47, Loss: 0.0452949250899283\u001b[0m\n",
      "\u001b[34mEpoch: 48, Loss: 0.04352352528976986\u001b[0m\n",
      "\u001b[34mEpoch: 49, Loss: 0.044174345383778145\u001b[0m\n",
      "\u001b[34mEpoch: 50, Loss: 0.04308508544532482\u001b[0m\n",
      "\u001b[34mEpoch: 51, Loss: 0.04274112595504405\u001b[0m\n",
      "\u001b[34mEpoch: 52, Loss: 0.0436578451938528\u001b[0m\n",
      "\u001b[34mEpoch: 53, Loss: 0.04282068033284131\u001b[0m\n",
      "\u001b[34mEpoch: 54, Loss: 0.041968419534983\u001b[0m\n",
      "\u001b[34mEpoch: 55, Loss: 0.042443840124871623\u001b[0m\n",
      "\u001b[34mEpoch: 56, Loss: 0.04263257141498061\u001b[0m\n",
      "\u001b[34mEpoch: 57, Loss: 0.04208727342380111\u001b[0m\n",
      "\u001b[34mEpoch: 58, Loss: 0.041836260825567434\u001b[0m\n",
      "\u001b[34mEpoch: 59, Loss: 0.04115726886153598\u001b[0m\n",
      "\u001b[34mEpoch: 60, Loss: 0.042408626829759065\u001b[0m\n",
      "\u001b[34mEpoch: 61, Loss: 0.04022312718596021\u001b[0m\n",
      "\u001b[34mEpoch: 62, Loss: 0.041041820789576466\u001b[0m\n",
      "\u001b[34mEpoch: 63, Loss: 0.04115999755664407\u001b[0m\n",
      "\u001b[34mEpoch: 64, Loss: 0.04071802710192666\u001b[0m\n",
      "\u001b[34mEpoch: 65, Loss: 0.040373167161652374\u001b[0m\n",
      "\u001b[34mEpoch: 66, Loss: 0.03922100539161225\u001b[0m\n",
      "\u001b[34mEpoch: 67, Loss: 0.039227766659418455\u001b[0m\n",
      "\u001b[34mEpoch: 68, Loss: 0.03910102709847879\u001b[0m\n",
      "\u001b[34mEpoch: 69, Loss: 0.03933431290906377\u001b[0m\n",
      "\u001b[34mEpoch: 70, Loss: 0.03939457723234747\u001b[0m\n",
      "\u001b[34mEpoch: 71, Loss: 0.038689920306967995\u001b[0m\n",
      "\u001b[34mEpoch: 72, Loss: 0.0385103775413535\u001b[0m\n",
      "\u001b[34mEpoch: 73, Loss: 0.037587481897692974\u001b[0m\n",
      "\u001b[34mEpoch: 74, Loss: 0.03793005465073899\u001b[0m\n",
      "\u001b[34mEpoch: 75, Loss: 0.03693311500908402\u001b[0m\n",
      "\u001b[34mEpoch: 76, Loss: 0.037355355279162596\u001b[0m\n",
      "\u001b[34mEpoch: 77, Loss: 0.037578916565377894\u001b[0m\n",
      "\u001b[34mEpoch: 78, Loss: 0.03781692129234129\u001b[0m\n",
      "\u001b[34mEpoch: 79, Loss: 0.036379361920851463\u001b[0m\n",
      "\u001b[34mEpoch: 80, Loss: 0.03599142811279827\u001b[0m\n",
      "\u001b[34mEpoch: 81, Loss: 0.03664128902718879\u001b[0m\n",
      "\u001b[34mEpoch: 82, Loss: 0.03637591788442694\u001b[0m\n",
      "\u001b[34mEpoch: 83, Loss: 0.03635890538654556\u001b[0m\n",
      "\u001b[34mEpoch: 84, Loss: 0.03481966371535756\u001b[0m\n",
      "\u001b[34mEpoch: 85, Loss: 0.036660290864736975\u001b[0m\n",
      "\u001b[34mEpoch: 86, Loss: 0.03568026759690145\u001b[0m\n",
      "\u001b[34mEpoch: 87, Loss: 0.035349120924885416\u001b[0m\n",
      "\u001b[34mEpoch: 88, Loss: 0.03392493203985699\u001b[0m\n",
      "\u001b[34mEpoch: 89, Loss: 0.034650742355595524\u001b[0m\n",
      "\u001b[34mEpoch: 90, Loss: 0.03499374846866149\u001b[0m\n",
      "\u001b[34mEpoch: 91, Loss: 0.03472687567790715\u001b[0m\n",
      "\u001b[34mEpoch: 92, Loss: 0.03399079447297568\u001b[0m\n",
      "\u001b[34mEpoch: 93, Loss: 0.034648891168260545\u001b[0m\n",
      "\u001b[34mEpoch: 94, Loss: 0.035008949027715494\u001b[0m\n",
      "\u001b[34mEpoch: 95, Loss: 0.03367640390379598\u001b[0m\n",
      "\u001b[34mEpoch: 96, Loss: 0.03298445966538566\u001b[0m\n",
      "\u001b[34mEpoch: 97, Loss: 0.03350554745425359\u001b[0m\n",
      "\u001b[34mEpoch: 98, Loss: 0.033633398976754894\u001b[0m\n",
      "\u001b[34mEpoch: 99, Loss: 0.03261190166068402\u001b[0m\n",
      "\u001b[34mEpoch: 100, Loss: 0.0328033105605365\u001b[0m\n",
      "\u001b[34mEpoch: 101, Loss: 0.03220697955389153\u001b[0m\n",
      "\u001b[34mEpoch: 102, Loss: 0.03193888700722406\u001b[0m\n",
      "\u001b[34mEpoch: 103, Loss: 0.032769941093560885\u001b[0m\n",
      "\u001b[34mEpoch: 104, Loss: 0.03245393182649942\u001b[0m\n",
      "\u001b[34mEpoch: 105, Loss: 0.03245149402270423\u001b[0m\n",
      "\u001b[34mEpoch: 106, Loss: 0.032643753303827475\u001b[0m\n",
      "\u001b[34mEpoch: 107, Loss: 0.03205034828126719\u001b[0m\n",
      "\u001b[34mEpoch: 108, Loss: 0.032175157440633484\u001b[0m\n",
      "\u001b[34mEpoch: 109, Loss: 0.03192984102324339\u001b[0m\n",
      "\u001b[34mEpoch: 110, Loss: 0.032264201717702064\u001b[0m\n",
      "\u001b[34mEpoch: 111, Loss: 0.03133001467349892\u001b[0m\n",
      "\u001b[34mEpoch: 112, Loss: 0.030003932118104006\u001b[0m\n",
      "\u001b[34mEpoch: 113, Loss: 0.03088494837997825\u001b[0m\n",
      "\u001b[34mEpoch: 114, Loss: 0.03030151626496393\u001b[0m\n",
      "\u001b[34mEpoch: 115, Loss: 0.03003079117609429\u001b[0m\n",
      "\u001b[34mEpoch: 116, Loss: 0.03034039536840369\u001b[0m\n",
      "\u001b[34mEpoch: 117, Loss: 0.03072172536043841\u001b[0m\n",
      "\u001b[34mEpoch: 118, Loss: 0.029811471367360183\u001b[0m\n",
      "\u001b[34mEpoch: 119, Loss: 0.030126482549045857\u001b[0m\n",
      "\u001b[34mEpoch: 120, Loss: 0.029782322941693046\u001b[0m\n",
      "\u001b[34mEpoch: 121, Loss: 0.029103225469000227\u001b[0m\n",
      "\u001b[34mEpoch: 122, Loss: 0.03053256213873586\u001b[0m\n",
      "\u001b[34mEpoch: 123, Loss: 0.02998721242537223\u001b[0m\n",
      "\u001b[34mEpoch: 124, Loss: 0.0291469705759179\u001b[0m\n",
      "\u001b[34mEpoch: 125, Loss: 0.028707225857769594\u001b[0m\n",
      "\u001b[34mEpoch: 126, Loss: 0.02974769044664884\u001b[0m\n",
      "\u001b[34mEpoch: 127, Loss: 0.02774236715465252\u001b[0m\n",
      "\u001b[34mEpoch: 128, Loss: 0.029969896087398713\u001b[0m\n",
      "\u001b[34mEpoch: 129, Loss: 0.028713325855625\u001b[0m\n",
      "\u001b[34mEpoch: 130, Loss: 0.02894451952401834\u001b[0m\n",
      "\u001b[34mEpoch: 131, Loss: 0.028500334447363412\u001b[0m\n",
      "\u001b[34mEpoch: 132, Loss: 0.029772863647026714\u001b[0m\n",
      "\u001b[34mEpoch: 133, Loss: 0.028104546977244484\u001b[0m\n",
      "\u001b[34mEpoch: 134, Loss: 0.028146776764818544\u001b[0m\n",
      "\u001b[34mEpoch: 135, Loss: 0.028251561836982762\u001b[0m\n",
      "\u001b[34mEpoch: 136, Loss: 0.028433650174390226\u001b[0m\n",
      "\u001b[34mEpoch: 137, Loss: 0.02823996089626321\u001b[0m\n",
      "\u001b[34mEpoch: 138, Loss: 0.027636183399798547\u001b[0m\n",
      "\n",
      "2021-06-08 19:05:34 Uploading - Uploading generated training model\u001b[34mEpoch: 139, Loss: 0.0272425467463195\u001b[0m\n",
      "\u001b[34mEpoch: 140, Loss: 0.027352305731515765\u001b[0m\n",
      "\u001b[34mEpoch: 141, Loss: 0.027240092166851224\u001b[0m\n",
      "\u001b[34mEpoch: 142, Loss: 0.027960183027105467\u001b[0m\n",
      "\u001b[34mEpoch: 143, Loss: 0.02705176976546465\u001b[0m\n",
      "\u001b[34mEpoch: 144, Loss: 0.027161007079744844\u001b[0m\n",
      "\u001b[34mEpoch: 145, Loss: 0.026786627077291042\u001b[0m\n",
      "\u001b[34mEpoch: 146, Loss: 0.027090407855645197\u001b[0m\n",
      "\u001b[34mEpoch: 147, Loss: 0.026523510257816053\u001b[0m\n",
      "\u001b[34mEpoch: 148, Loss: 0.027020335183329906\u001b[0m\n",
      "\u001b[34mEpoch: 149, Loss: 0.027532225320794083\u001b[0m\n",
      "\u001b[34mEpoch: 150, Loss: 0.026663855423445664\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34m2021-06-08 19:05:30,090 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-06-08 19:06:04 Completed - Training job completed\n",
      "ProfilerReport-1623178832: NoIssuesFound\n",
      "Training seconds: 174\n",
      "Billable seconds: 174\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': Pytorch_train_location})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6683054",
   "metadata": {},
   "source": [
    "## Part 3: Kaggle Competition\n",
    "\n",
    "Now that you've created a model to predict which individuals are most likely to respond to a mailout campaign, it's time to test that model in competition through Kaggle. If you click on the link [here](http://www.kaggle.com/t/21e6d45d4c574c7fa2d868f0e8c83140), you'll be taken to the competition page where, if you have a Kaggle account, you can enter.\n",
    "\n",
    "Your entry to the competition should be a CSV file with two columns. The first column should be a copy of \"LNR\", which acts as an ID number for each individual in the \"TEST\" partition. The second column, \"RESPONSE\", should be some measure of how likely each individual became a customer – this might not be a straightforward probability. As you should have found in Part 2, there is a large output class imbalance, where most individuals did not respond to the mailout. Thus, predicting individual classes and using accuracy does not seem to be an appropriate performance evaluation method. Instead, the competition will be using AUC to evaluate performance. The exact values of the \"RESPONSE\" column do not matter as much: only that the higher values try to capture as many of the actual customers as possible, early in the ROC curve sweep."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaf6bcf",
   "metadata": {},
   "source": [
    "## Prepare the data for both LinearLearner Model and Pytorch Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee1c541",
   "metadata": {},
   "source": [
    "1.1 Prepare data for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "df4cf8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test = pd.read_csv('Data/Udacity_MAILOUT_052018_TEST.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "061fdaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = azdias.columns.tolist()\n",
    "mailout_test = mailout_test[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "25088101",
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_processed = data_process_2(mailout_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "4b71830c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_test_processed.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "9e70c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "identification_info = mailout_test_processed['LNR']\n",
    "mailout_test_processed.drop(axis=1, columns = ['LNR'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "359c30c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42833, 277)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_test_processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "541d855a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>ARBEIT</th>\n",
       "      <th>BALLRAUM</th>\n",
       "      <th>CAMEO_DEUG_2015</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "      <th>CAMEO_INTL_FAM_Wealth</th>\n",
       "      <th>CAMEO_INTL_FAM_COMPOSITION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.052770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AKT_DAT_KL  ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  ANZ_KINDER  ANZ_PERSONEN  \\\n",
       "0        0.00             0.005277           0.0         0.0      0.142857   \n",
       "1        0.00             0.052770           0.0         0.0      0.071429   \n",
       "2        1.00             0.005277           0.0         0.0      0.285714   \n",
       "3        0.75             0.002639           0.0         0.0      0.000000   \n",
       "4        0.00             0.002639           0.0         0.0      0.285714   \n",
       "\n",
       "   ANZ_STATISTISCHE_HAUSHALTE  ANZ_TITEL  ARBEIT  BALLRAUM  CAMEO_DEUG_2015  \\\n",
       "0                    0.005333        0.0   0.250  0.833333            0.125   \n",
       "1                    0.056000        0.0   0.375  1.000000            0.500   \n",
       "2                    0.005333        0.0   0.375  0.000000            0.750   \n",
       "3                    0.002667        0.0   0.375  0.000000            0.125   \n",
       "4                    0.002667        0.0   0.250  0.833333            0.500   \n",
       "\n",
       "   ...  VK_DHT4A  VK_DISTANZ  VK_ZG11  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  \\\n",
       "0  ...       0.4    0.416667      0.2             1.0     0.375       0.4   \n",
       "1  ...       0.4    0.083333      0.0             1.0     0.625       0.4   \n",
       "2  ...       0.8    0.416667      0.2             1.0     0.500       0.4   \n",
       "3  ...       0.5    0.416667      0.2             1.0     0.250       0.4   \n",
       "4  ...       0.1    0.250000      0.2             1.0     0.875       0.6   \n",
       "\n",
       "   ANREDE_KZ  ALTERSKATEGORIE_GROB  CAMEO_INTL_FAM_Wealth  \\\n",
       "0        0.0                 0.375                   0.00   \n",
       "1        0.0                 0.375                   0.50   \n",
       "2        1.0                 0.375                   0.75   \n",
       "3        1.0                 0.375                   0.00   \n",
       "4        1.0                 0.375                   0.50   \n",
       "\n",
       "   CAMEO_INTL_FAM_COMPOSITION  \n",
       "0                         0.5  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         0.5  \n",
       "4                         0.0  \n",
       "\n",
       "[5 rows x 277 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_4 = MinMaxScaler(feature_range= (0, 1))\n",
    "\n",
    "mailout_test_scaled= pd.DataFrame(scaler_4.fit_transform(mailout_test_processed.astype(float)))\n",
    "mailout_test_scaled.columns = mailout_test_processed.columns\n",
    "mailout_test_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "de5dbe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_scaled.to_csv(os.path.join(data_dir, 'mail_test.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "b4f13534",
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_location = session.upload_data(os.path.join(data_dir, 'mail_test.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "270d794e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[35mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] nvidia-smi: took 0.033 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] loading entry points\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] Number of server workers: 4\u001b[0m\n",
      "\u001b[34m[2021-06-08 19:22:50 +0000] [1] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-06-08 19:22:50 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-06-08 19:22:50 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2021-06-08 19:22:50 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-08 19:22:50 +0000] [66] [INFO] Booting worker with pid: 66\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-08 19:22:50 +0000] [77] [INFO] Booting worker with pid: 77\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-08 19:22:50 +0000] [88] [INFO] Booting worker with pid: 88\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:50 INFO 140180668028736] ...model loaded.\u001b[0m\n",
      "\u001b[35mRunning default environment configuration script\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] nvidia-smi: took 0.033 seconds to run.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] loading entry points\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] loaded request iterator application/json\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] loaded response encoder application/json\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] Number of server workers: 4\u001b[0m\n",
      "\u001b[35m[2021-06-08 19:22:50 +0000] [1] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2021-06-08 19:22:50 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2021-06-08 19:22:50 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[35m[2021-06-08 19:22:50 +0000] [55] [INFO] Booting worker with pid: 55\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] loading model...\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2021-06-08 19:22:50 +0000] [66] [INFO] Booting worker with pid: 66\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] loading model...\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2021-06-08 19:22:50 +0000] [77] [INFO] Booting worker with pid: 77\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] loading model...\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] ...model loaded.\u001b[0m\n",
      "\u001b[35m[2021-06-08 19:22:50 +0000] [88] [INFO] Booting worker with pid: 88\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] loading model...\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:50 INFO 140180668028736] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180170.6724188, \"EndTime\": 1623180172.2047157, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180170.6724188, \"EndTime\": 1623180172.2047157, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2580.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2591.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2593.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:53 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2563.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2580.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2591.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2593.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:53 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2563.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180172.2051506, \"EndTime\": 1623180175.2161117, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180170.642399, \"EndTime\": 1623180175.2881901, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180170.5738504, \"EndTime\": 1623180175.3521647, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180170.7755907, \"EndTime\": 1623180175.3923264, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180172.2051506, \"EndTime\": 1623180175.2161117, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180170.642399, \"EndTime\": 1623180175.2881901, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180170.5738504, \"EndTime\": 1623180175.3521647, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180170.7755907, \"EndTime\": 1623180175.3923264, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2612.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2569.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2612.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2569.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2589.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:55 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2596.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2589.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:55 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2596.\u001b[0m\n",
      "\u001b[32m2021-06-08T19:22:52.211:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180175.216216, \"EndTime\": 1623180177.4041314, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180175.288325, \"EndTime\": 1623180177.4295104, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180175.3523157, \"EndTime\": 1623180177.4356368, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180175.216216, \"EndTime\": 1623180177.4041314, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180175.288325, \"EndTime\": 1623180177.4295104, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180175.3523157, \"EndTime\": 1623180177.4356368, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180175.3924737, \"EndTime\": 1623180177.531113, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:57 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:57 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:57 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:57 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2595.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:58 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:58 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:58 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:58 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2555.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:58 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:58 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:58 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:58 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2624.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180175.3924737, \"EndTime\": 1623180177.531113, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:57 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:57 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:57 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:57 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2595.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:58 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:58 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:58 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:58 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2555.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:58 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:58 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:58 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:58 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2624.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:59 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:59 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:59 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:59 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2557.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180177.4042323, \"EndTime\": 1623180179.431342, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:59 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:59 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:59 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:59 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2557.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180177.4042323, \"EndTime\": 1623180179.431342, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180177.5311942, \"EndTime\": 1623180179.627085, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180177.436173, \"EndTime\": 1623180179.96354, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:59 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:59 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:59 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:22:59 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2567.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:00 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180177.5311942, \"EndTime\": 1623180179.627085, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180177.436173, \"EndTime\": 1623180179.96354, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:59 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:59 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:59 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:22:59 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2567.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:00 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:00 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:00 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:00 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2587.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:00 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:00 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:00 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2587.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180177.4296105, \"EndTime\": 1623180180.7128263, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:01 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:01 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:01 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:01 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2575.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180177.4296105, \"EndTime\": 1623180180.7128263, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:01 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:01 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:01 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:01 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2575.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:01 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:01 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:01 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:01 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2588.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:01 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:01 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:01 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:01 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 2588.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180179.4317777, \"EndTime\": 1623180181.546306, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180179.6271725, \"EndTime\": 1623180181.8796437, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:02 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:02 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:02 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:23:02 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1475.\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180179.4317777, \"EndTime\": 1623180181.546306, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180179.6271725, \"EndTime\": 1623180181.8796437, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:02 WARNING 140180668028736] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:02 INFO 140180668028736] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:02 INFO 140180668028736] The default executor is <PCAModel on cpu(0)>.\u001b[0m\n",
      "\u001b[35m[06/08/2021 19:23:02 INFO 140180668028736] <PCAModel on cpu(0)> is assigned to batch slice from 0 to 1475.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180179.9636357, \"EndTime\": 1623180182.6463094, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180181.546441, \"EndTime\": 1623180182.9886835, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180180.712989, \"EndTime\": 1623180183.019462, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180179.9636357, \"EndTime\": 1623180182.6463094, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180181.546441, \"EndTime\": 1623180182.9886835, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180180.712989, \"EndTime\": 1623180183.019462, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca_transformer.transform(mailout_test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "a83effb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-1-178050996200/pca-2021-06-08-19-17-54-294/mail_test.csv.out to ../data/mail_test.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $pca_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "71747ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_mailout_test= pd.read_csv(os.path.join(data_dir, 'mail_test.csv.out'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "d5aea767",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_out(pca_mailout_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "4246bbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 80 \n",
    "transformed_pca_mailout_test = create_transformed_df(pca_mailout_test, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "c35d89a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>c_9</th>\n",
       "      <th>c_10</th>\n",
       "      <th>...</th>\n",
       "      <th>c_71</th>\n",
       "      <th>c_72</th>\n",
       "      <th>c_73</th>\n",
       "      <th>c_74</th>\n",
       "      <th>c_75</th>\n",
       "      <th>c_76</th>\n",
       "      <th>c_77</th>\n",
       "      <th>c_78</th>\n",
       "      <th>c_79</th>\n",
       "      <th>c_80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.543800</td>\n",
       "      <td>1.400662</td>\n",
       "      <td>-1.666795</td>\n",
       "      <td>-1.081734</td>\n",
       "      <td>-1.011073</td>\n",
       "      <td>-0.949689</td>\n",
       "      <td>0.662075</td>\n",
       "      <td>-0.067560</td>\n",
       "      <td>-0.347799</td>\n",
       "      <td>-0.603502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158677</td>\n",
       "      <td>0.075576</td>\n",
       "      <td>0.229689</td>\n",
       "      <td>-0.086758</td>\n",
       "      <td>0.202016</td>\n",
       "      <td>-0.006913</td>\n",
       "      <td>-0.306524</td>\n",
       "      <td>-0.229235</td>\n",
       "      <td>-0.185732</td>\n",
       "      <td>-0.517027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.256624</td>\n",
       "      <td>1.593392</td>\n",
       "      <td>-0.817794</td>\n",
       "      <td>0.230621</td>\n",
       "      <td>-0.590630</td>\n",
       "      <td>-0.100754</td>\n",
       "      <td>0.873446</td>\n",
       "      <td>-0.434377</td>\n",
       "      <td>0.335984</td>\n",
       "      <td>0.891219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>-0.078358</td>\n",
       "      <td>0.040518</td>\n",
       "      <td>-0.161276</td>\n",
       "      <td>-0.071263</td>\n",
       "      <td>-0.335096</td>\n",
       "      <td>-0.173424</td>\n",
       "      <td>0.100908</td>\n",
       "      <td>0.433059</td>\n",
       "      <td>-0.563600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.864506</td>\n",
       "      <td>1.721451</td>\n",
       "      <td>-0.658591</td>\n",
       "      <td>-0.312438</td>\n",
       "      <td>0.660538</td>\n",
       "      <td>0.331321</td>\n",
       "      <td>-0.998032</td>\n",
       "      <td>0.980327</td>\n",
       "      <td>-1.140898</td>\n",
       "      <td>0.707565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.470539</td>\n",
       "      <td>-0.063139</td>\n",
       "      <td>-0.159207</td>\n",
       "      <td>0.161077</td>\n",
       "      <td>-0.192976</td>\n",
       "      <td>0.253821</td>\n",
       "      <td>-0.119096</td>\n",
       "      <td>-0.229712</td>\n",
       "      <td>-0.185274</td>\n",
       "      <td>0.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.370743</td>\n",
       "      <td>1.989629</td>\n",
       "      <td>0.121335</td>\n",
       "      <td>0.897753</td>\n",
       "      <td>1.075825</td>\n",
       "      <td>0.022024</td>\n",
       "      <td>-1.188638</td>\n",
       "      <td>-0.460623</td>\n",
       "      <td>-0.022873</td>\n",
       "      <td>-0.280394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184332</td>\n",
       "      <td>0.150099</td>\n",
       "      <td>0.467827</td>\n",
       "      <td>-0.462807</td>\n",
       "      <td>-0.017165</td>\n",
       "      <td>0.063159</td>\n",
       "      <td>-0.216610</td>\n",
       "      <td>0.010917</td>\n",
       "      <td>0.088971</td>\n",
       "      <td>0.338340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.513388</td>\n",
       "      <td>-1.049300</td>\n",
       "      <td>-1.106830</td>\n",
       "      <td>1.220684</td>\n",
       "      <td>0.950794</td>\n",
       "      <td>0.017198</td>\n",
       "      <td>0.914590</td>\n",
       "      <td>1.116144</td>\n",
       "      <td>1.937798</td>\n",
       "      <td>0.843823</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128742</td>\n",
       "      <td>-0.236225</td>\n",
       "      <td>-0.057347</td>\n",
       "      <td>-0.276576</td>\n",
       "      <td>0.483695</td>\n",
       "      <td>-0.094855</td>\n",
       "      <td>-0.238647</td>\n",
       "      <td>-0.090327</td>\n",
       "      <td>0.153859</td>\n",
       "      <td>0.415749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        c_1       c_2       c_3       c_4       c_5       c_6       c_7  \\\n",
       "0 -1.543800  1.400662 -1.666795 -1.081734 -1.011073 -0.949689  0.662075   \n",
       "1  0.256624  1.593392 -0.817794  0.230621 -0.590630 -0.100754  0.873446   \n",
       "2 -0.864506  1.721451 -0.658591 -0.312438  0.660538  0.331321 -0.998032   \n",
       "3 -0.370743  1.989629  0.121335  0.897753  1.075825  0.022024 -1.188638   \n",
       "4 -3.513388 -1.049300 -1.106830  1.220684  0.950794  0.017198  0.914590   \n",
       "\n",
       "        c_8       c_9      c_10  ...      c_71      c_72      c_73      c_74  \\\n",
       "0 -0.067560 -0.347799 -0.603502  ...  0.158677  0.075576  0.229689 -0.086758   \n",
       "1 -0.434377  0.335984  0.891219  ...  0.456400 -0.078358  0.040518 -0.161276   \n",
       "2  0.980327 -1.140898  0.707565  ... -0.470539 -0.063139 -0.159207  0.161077   \n",
       "3 -0.460623 -0.022873 -0.280394  ...  0.184332  0.150099  0.467827 -0.462807   \n",
       "4  1.116144  1.937798  0.843823  ... -0.128742 -0.236225 -0.057347 -0.276576   \n",
       "\n",
       "       c_75      c_76      c_77      c_78      c_79      c_80  \n",
       "0  0.202016 -0.006913 -0.306524 -0.229235 -0.185732 -0.517027  \n",
       "1 -0.071263 -0.335096 -0.173424  0.100908  0.433059 -0.563600  \n",
       "2 -0.192976  0.253821 -0.119096 -0.229712 -0.185274  0.162400  \n",
       "3 -0.017165  0.063159 -0.216610  0.010917  0.088971  0.338340  \n",
       "4  0.483695 -0.094855 -0.238647 -0.090327  0.153859  0.415749  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = []\n",
    "for i in range(1, n+1):\n",
    "    column_names.append('c_'+str(i)) \n",
    "\n",
    "transformed_pca_mailout_test.columns = column_names\n",
    "\n",
    "transformed_pca_mailout_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "f9130760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42833, 80)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_pca_mailout_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4510954f",
   "metadata": {},
   "source": [
    "Transformed_pca_train_features will be used as the input information, due to its reduced dimensionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "b6b05b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_pca_mailout_test.to_csv(os.path.join(data_dir, 'pca_mailout_test.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "3dcb0f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_mailout_test_location = session.upload_data(os.path.join(data_dir, 'pca_mailout_test.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "3939fa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] loading entry points\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] loaded request iterator text/csv\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] loaded response encoder text/csv\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] Number of server workers: 4\u001b[0m\n",
      "\u001b[34m[2021-06-08 19:34:46 +0000] [1] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-06-08 19:34:46 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-06-08 19:34:46 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2021-06-08 19:34:46 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 WARNING 140473528604480] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] nvidia-smi: took 0.032 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-08 19:34:46 +0000] [63] [INFO] Booting worker with pid: 63\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 WARNING 140473528604480] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[2021-06-08 19:34:46 +0000] [84] [INFO] Booting worker with pid: 84\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 WARNING 140473528604480] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] nvidia-smi: took 0.034 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] ...model loaded.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] nvidia-smi: took 0.038 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] ...model loaded.\u001b[0m\n",
      "\u001b[34m[2021-06-08 19:34:46 +0000] [105] [INFO] Booting worker with pid: 105\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] loading model...\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 WARNING 140473528604480] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] nvidia-smi: took 0.032 seconds to run.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[06/08/2021 19:34:46 INFO 140473528604480] ...model loaded.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180886.522951, \"EndTime\": 1623180888.2954295, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180886.6154165, \"EndTime\": 1623180889.3485103, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.028133392333984375, \"count\": 1, \"min\": 0.028133392333984375, \"max\": 0.028133392333984375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180886.70381, \"EndTime\": 1623180889.4763017, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.025272369384765625, \"count\": 1, \"min\": 0.025272369384765625, \"max\": 0.025272369384765625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180886.637406, \"EndTime\": 1623180889.4989038, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.054836273193359375, \"count\": 1, \"min\": 0.054836273193359375, \"max\": 0.054836273193359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180888.2956688, \"EndTime\": 1623180889.5595827, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.05364418029785156, \"count\": 1, \"min\": 0.05364418029785156, \"max\": 0.05364418029785156}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180886.6154165, \"EndTime\": 1623180889.3485103, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.028133392333984375, \"count\": 1, \"min\": 0.028133392333984375, \"max\": 0.028133392333984375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180886.70381, \"EndTime\": 1623180889.4763017, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.025272369384765625, \"count\": 1, \"min\": 0.025272369384765625, \"max\": 0.025272369384765625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180886.637406, \"EndTime\": 1623180889.4989038, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.054836273193359375, \"count\": 1, \"min\": 0.054836273193359375, \"max\": 0.054836273193359375}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180888.2956688, \"EndTime\": 1623180889.5595827, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.05364418029785156, \"count\": 1, \"min\": 0.05364418029785156, \"max\": 0.05364418029785156}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[32m2021-06-08T19:34:48.304:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180889.3486357, \"EndTime\": 1623180889.866083, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180889.3486357, \"EndTime\": 1623180889.866083, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021219253540039062, \"count\": 1, \"min\": 0.021219253540039062, \"max\": 0.021219253540039062}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180889.4767337, \"EndTime\": 1623180889.8964145, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180889.5596733, \"EndTime\": 1623180889.913907, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180889.4991243, \"EndTime\": 1623180889.963805, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.015974044799804688, \"count\": 1, \"min\": 0.015974044799804688, \"max\": 0.015974044799804688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180889.9139955, \"EndTime\": 1623180890.0917394, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.014543533325195312, \"count\": 1, \"min\": 0.014543533325195312, \"max\": 0.014543533325195312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180889.8661654, \"EndTime\": 1623180890.1835532, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.01621246337890625, \"count\": 1, \"min\": 0.01621246337890625, \"max\": 0.01621246337890625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1623180889.9638736, \"EndTime\": 1623180890.2119865, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.014543533325195312, \"count\": 1, \"min\": 0.014543533325195312, \"max\": 0.014543533325195312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180889.4767337, \"EndTime\": 1623180889.8964145, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021457672119140625, \"count\": 1, \"min\": 0.021457672119140625, \"max\": 0.021457672119140625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180889.5596733, \"EndTime\": 1623180889.913907, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.021696090698242188, \"count\": 1, \"min\": 0.021696090698242188, \"max\": 0.021696090698242188}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180889.4991243, \"EndTime\": 1623180889.963805, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.015974044799804688, \"count\": 1, \"min\": 0.015974044799804688, \"max\": 0.015974044799804688}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180889.9139955, \"EndTime\": 1623180890.0917394, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.014543533325195312, \"count\": 1, \"min\": 0.014543533325195312, \"max\": 0.014543533325195312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180889.8661654, \"EndTime\": 1623180890.1835532, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.01621246337890625, \"count\": 1, \"min\": 0.01621246337890625, \"max\": 0.01621246337890625}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1623180889.9638736, \"EndTime\": 1623180890.2119865, \"Dimensions\": {\"Algorithm\": \"KMeansModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.014543533325195312, \"count\": 1, \"min\": 0.014543533325195312, \"max\": 0.014543533325195312}, \"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kmeans_transformer.transform(pca_mailout_test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "9076dc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-1-178050996200/kmeans-2021-06-08-19-30-10-544/pca_mailout_test.csv.out to ../data/pca_mailout_test.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $kmeans_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "8caf4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mailout_test_kmeans = pd.read_csv(os.path.join(data_dir, 'pca_mailout_test.csv.out'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "7312be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_cluster = clean_kmeans_output(df_mailout_test_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "24f24fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    7\n",
       "3    7\n",
       "4    3\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_test_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "9323ebce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mailout_test_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "191d5b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_cluster_mapped = mailout_test_cluster.map(category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "ad1587a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.893646\n",
       "1    0.893646\n",
       "2    0.412094\n",
       "3    0.412094\n",
       "4    1.000000\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_test_cluster_mapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "624c928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test_finalized = pd.concat([transformed_pca_mailout_test, mailout_test_cluster_mapped], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "3332fd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42833, 81)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_test_finalized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f89f14",
   "metadata": {},
   "source": [
    "## Use LinearLearner to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "a57f340d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "linear_predictor = LinearLearner_1.deploy(initial_instance_count=1, instance_type='ml.t2.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "15842cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mailout_test = mailout_test_finalized.astype('float32')\n",
    "mailout_test_np = mailout_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "70f71dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_batches = [linear_predictor.predict(batch) for batch in np.array_split(mailout_test_np, 100)]\n",
    "test_preds = np.concatenate([np.array([x.label['predicted_label'].float32_tensor.values[0] for x in batch]) for batch in prediction_batches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "0beed41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_df = pd.DataFrame(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "0cead0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  0.0\n",
       "1  1.0\n",
       "2  0.0\n",
       "3  1.0\n",
       "4  0.0"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "f002747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_prediction = pd.concat([identification_info, test_preds_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "77b5ad88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>RESPONSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1754</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1770</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1465</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1470</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1478</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LNR  RESPONSE\n",
       "0  1754       0.0\n",
       "1  1770       1.0\n",
       "2  1465       0.0\n",
       "3  1470       1.0\n",
       "4  1478       0.0"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalized_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "7a3e7ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_prediction.columns = ['LNR', 'RESPONSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "9a4b8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_prediction.to_csv(os.path.join(data_dir, 'finalized_prediction_benchmark'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797c25f0",
   "metadata": {},
   "source": [
    "Benchmark Model get a score of 0.5984"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2460c5a7",
   "metadata": {},
   "source": [
    "## Use Custom Pytorch Model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "29094693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "pytorch_predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.t2.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "f6345095",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.squeeze(pytorch_predictor.predict(mailout_test_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "9eac272f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "a7f7612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_df = pd.DataFrame(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "c370f8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_prediction = pd.concat([identification_info, test_preds_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "8d3a6b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1754</td>\n",
       "      <td>4.032807e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1770</td>\n",
       "      <td>1.765097e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1465</td>\n",
       "      <td>9.861202e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1470</td>\n",
       "      <td>2.503072e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1478</td>\n",
       "      <td>7.089400e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LNR             0\n",
       "0  1754  4.032807e-03\n",
       "1  1770  1.765097e-04\n",
       "2  1465  9.861202e-16\n",
       "3  1470  2.503072e-07\n",
       "4  1478  7.089400e-03"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalized_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "619ffae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_prediction.columns = ['LNR', 'RESPONSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "d4a35714",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_prediction.to_csv(os.path.join(data_dir, 'finalized_prediction_Pytorch'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692416e7",
   "metadata": {},
   "source": [
    "## Pytorch models gets a score of 0.533. Two places to improve the model: imbalanced data; add more weight to the final category information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa899ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
